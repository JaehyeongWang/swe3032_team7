{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call library\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, StratifiedKFold, KFold\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from preprocesslib import preprocessEach, makeY, splitData, splitDataCrossVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xGrowths = preprocessEach('growth')\n",
    "xValues = preprocessEach('value')\n",
    "xOverlaps = preprocessEach('overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap\n",
    "n_samples = len(xValues)-len(xGrowths)\n",
    "xGrowths_b = xGrowths[np.random.choice(len(xGrowths), size=n_samples, replace=True)]\n",
    "xGrowths = np.concatenate((xGrowths, xGrowths_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(xValues)-len(xOverlaps)\n",
    "xOverlaps_b = xOverlaps[np.random.choice(len(xOverlaps), size=n_samples, replace=True)]\n",
    "xOverlaps = np.concatenate((xOverlaps, xOverlaps_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make y values\n",
    "yGrowths = makeY('growth', len(xGrowths))\n",
    "yValues = makeY('value', len(xValues))\n",
    "yOverlaps = makeY('overlap', len(xOverlaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((xGrowths, xValues, xOverlaps), axis=0)\n",
    "y = np.concatenate((yGrowths, yValues, yOverlaps), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmax scaling by element\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(6):\n",
    "    x[:,:,i] = scaler.fit_transform(x[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS=1\n",
    "def make_gru(u,d):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(u, input_shape=(1248, 6)))\n",
    "    # model.add(GRU(u, input_shape=(1248, 6), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "    # model.add(GRU(int(u/2)))\n",
    "    # model.add(Dropout(d))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units =  [8]\n",
    "dropouts = [0]\n",
    "epochs = [2000]\n",
    "batchs = [64]\n",
    "p = 100\n",
    "# gru_hist = pd.DataFrame(columns=['epochs', 'units', 'dropouts', 'layers','batchs','patience', 'acc', 'wholeacc'])\n",
    "gru_hist = pd.read_csv('./GRU/GRU_result_2.csv')\n",
    "kf = KFold(3, shuffle=True)\n",
    "\n",
    "for b in batchs:\n",
    "    for e in epochs:\n",
    "        for u in units:\n",
    "            for d in dropouts:\n",
    "                print(\"======================================================================================\")\n",
    "                print(f\"units: {u}, dropout: {d}, epoch: {e}\")\n",
    "                accuracy_cross_val = []\n",
    "                for id, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "                    x_train, x_test = x[train_index], x[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "                    model = make_gru(u,d)\n",
    "                    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=p)\n",
    "                    # reduce_lr = ReduceLROnPlateau()\n",
    "                    mc = ModelCheckpoint(f'./GRU/GRU__units_{u} dropout_{d} epoch_{e}_b_{b}_model.h5', monitor='val_acc', mode='max', save_best_only=True, )\n",
    "                    history=model.fit(x_train, y_train, epochs=e, batch_size=b, validation_split=0.3, callbacks=[es, mc])\n",
    "                    model=load_model(f'./GRU/GRU__units_{u} dropout_{d} epoch_{e}_b_{b}_model.h5')\n",
    "                    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "                    accuracy_cross_val.append(accuracy)\n",
    "                    # history=model.fit(x_train, y_train, epochs=e, batch_size=b, validation_data = (x_test, y_test),callbacks= [es,mc])\n",
    "                    # accuracy_cross_val.append(mc.best)\n",
    "                # bestid = np.argmax(accuracy_cross_val)\n",
    "                epochs = range(1, len(history.history['acc']) + 1)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(epochs, history.history['loss'])\n",
    "                plt.plot(epochs, history.history['val_loss'])\n",
    "                plt.title('model loss')\n",
    "                plt.ylabel('loss')\n",
    "                plt.xlabel('epoch')\n",
    "                plt.legend(['train', 'val'], loc='upper left')\n",
    "                plt.savefig(f\"GRU/1_units_{u} dropout_{d} epoch_{e}_cv{len(accuracy_cross_val)}_layer{LAYERS}_b_{b}_p_{p}.png\")\n",
    "                plt.close()\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(epochs, history.history['acc'])\n",
    "                plt.plot(epochs, history.history['val_acc'])\n",
    "                plt.title('model acc')\n",
    "                plt.ylabel('acc')\n",
    "                plt.xlabel('epoch')\n",
    "                plt.legend(['train', 'val'], loc='upper left')\n",
    "                plt.savefig(f\"GRU/2_units_{u} dropout_{d} epoch_{e}_cv{len(accuracy_cross_val)}_layer{LAYERS}_b_{b}_p_{p}.png\")\n",
    "                plt.close()\n",
    "                gru_hist.loc[gru_hist.shape[0]] = [e,u,d,LAYERS, b,p,np.mean(accuracy_cross_val), accuracy_cross_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_hist.to_csv('./GRU/GRU_result_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_hist = pd.DataFrame(columns=['epochs', 'units', 'dropouts', 'layers','batchs','patience', 'acc', 'wholeacc'])\n",
    "gru_hist.loc[gru_hist.shape[0]] = [e,u,d,LAYERS, b,p,np.mean(accuracy_cross_val), accuracy_cross_val]\n",
    "gru_hist.to_csv('./GRU/GRU_result_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
