{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaehyeongWang/swe3032_team7/blob/yuha/models/LSTM/main_final_growth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daCFN4jeN5MQ",
        "outputId": "4655c743-9571-4c22-efe5-6d205ca182dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/23_1_인지프/models/LSTM')"
      ],
      "metadata": {
        "id": "i8H697lVBKSw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p1Bo6jHYN5Md"
      },
      "outputs": [],
      "source": [
        "#call library\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from preprocesslib import preprocessEach, makeY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEEAjHRLN5Mf",
        "outputId": "c563ae02-49a2-4375-900f-70d7509e6b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/23_1_인지프/models/LSTM/preprocesslib.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "xGrowths = preprocessEach('growth')\n",
        "xValues = preprocessEach('value')\n",
        "xOverlaps = preprocessEach('overlap')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KvFiG5NwN5Mh"
      },
      "outputs": [],
      "source": [
        "#bootstrap\n",
        "n_samples = len(xValues)\n",
        "diff = len(xValues) - len(xGrowths)\n",
        "xGrowths_bootstrapped = xGrowths[np.random.choice(len(xGrowths), size=diff, replace=True)]\n",
        "xGrowths = np.concatenate((xGrowths, xGrowths_bootstrapped), axis=0)\n",
        "\n",
        "diff = len(xValues) - len(xOverlaps)\n",
        "xOverlaps_bootstrapped = xOverlaps[np.random.choice(len(xOverlaps), size=diff, replace=True)]\n",
        "xOverlaps = np.concatenate((xOverlaps, xOverlaps_bootstrapped), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Twi0vvTaN5Mi"
      },
      "outputs": [],
      "source": [
        "#make y values\n",
        "yGrowths = makeY('growth', n_samples)\n",
        "yValues = makeY('value', n_samples)\n",
        "yOverlaps = makeY('overlap', n_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H-c7H1b8N5Mj"
      },
      "outputs": [],
      "source": [
        "x = np.concatenate((xGrowths, xValues, xOverlaps), axis=0)\n",
        "y = np.concatenate((yGrowths, yValues, yOverlaps), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BOQkiijK1M6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4345c1a6-a1f2-4154-e1a7-25cfea4c5299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3213, 1248, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWyBxaT2kjt5",
        "outputId": "9eab1630-9f36-484b-b048-c6a262904b7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3213, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K9Ly7XHjN5Mk"
      },
      "outputs": [],
      "source": [
        "#minmax scaling by element\n",
        "scaler = MinMaxScaler()\n",
        "for i in range(6):\n",
        "    x[:,:,i] = scaler.fit_transform(x[:,:,i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YKrIXSuCN5Ml"
      },
      "outputs": [],
      "source": [
        "def splitData(x, y, train_ratio=0.8):\n",
        "    # shuffle data\n",
        "    np.random.seed(2023)\n",
        "    permutation = np.random.permutation(len(x))\n",
        "    x = x[permutation]\n",
        "    y = y[permutation]\n",
        "\n",
        "    # split data\n",
        "    n_train_samples = int(train_ratio * len(x))\n",
        "    x_train, x_test = x[:n_train_samples], x[n_train_samples:]\n",
        "    y_train, y_test = y[:n_train_samples], y[n_train_samples:]\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D5rIjBzoacqv"
      },
      "outputs": [],
      "source": [
        "#split data for cross validation\n",
        "def splitDataCrossVal(x, y, fold=3):\n",
        "    # shuffle data\n",
        "    permutation = np.random.permutation(len(x))\n",
        "    x = x[permutation]\n",
        "    y = y[permutation]\n",
        "\n",
        "    x_split = []\n",
        "    y_split = []\n",
        "    # split data\n",
        "    n_samples = int(len(x)/fold)\n",
        "    for i in range(fold-1):\n",
        "      x_split.append(x[i*n_samples:(i+1)*n_samples])\n",
        "      y_split.append(y[i*n_samples:(i+1)*n_samples])\n",
        "    x_split.append(x[(fold-1)*n_samples:])\n",
        "    y_split.append(y[(fold-1)*n_samples:])\n",
        "\n",
        "    return x_split, y_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f6BfL3-c3qeq"
      },
      "outputs": [],
      "source": [
        "def cvsplitData(x,y, ind):\n",
        "  x_test = x[ind]\n",
        "  y_test = y[ind]\n",
        "  cnt = 0\n",
        "  for i in range(len(x)):\n",
        "    if i!=ind:\n",
        "      if cnt == 0:\n",
        "        x_train = x[i]\n",
        "        y_train = y[i]\n",
        "        cnt += 1\n",
        "      else:\n",
        "        x_train = np.concatenate((x_train, x[i]))\n",
        "        y_train = np.concatenate((y_train, y[i]))\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lsWtsdCoN5Ms"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "def makeModel(class_name, units, dropout, output_unit, activation):\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  if class_name == 'LSTM':\n",
        "    for i, unit in enumerate(units):\n",
        "      if i == 0:\n",
        "        if len(units)==1:\n",
        "          model.add(LSTM(unit, input_shape=(1248,6), return_sequences=False))\n",
        "        else:\n",
        "          model.add(LSTM(unit, input_shape=(1248,6), return_sequences=True))\n",
        "      else:\n",
        "        model.add(LSTM(unit))\n",
        "      model.add(Dropout(dropout))\n",
        "  elif class_name == 'GRU':\n",
        "    for i, unit in enumerate(units):\n",
        "      if i == 0:\n",
        "        if len(units)==1:\n",
        "          model.add(GRU(unit, input_shape=(1248,6), return_sequences=False))\n",
        "        else:\n",
        "          model.add(GRU(unit, input_shape=(1248,6), return_sequences=True))\n",
        "      else:\n",
        "        model.add(GRU(unit))\n",
        "      model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(output_unit, activation=activation))\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "  mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model, es, mc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfWe-kRjarpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7f5909-6736-4697-b725-066c7aa13d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5931 - acc: 0.6815 - val_loss: 0.6026 - val_acc: 0.6676\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5956 - acc: 0.6625 - val_loss: 0.6061 - val_acc: 0.6764\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5961 - acc: 0.6728 - val_loss: 0.6001 - val_acc: 0.6764\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6017 - acc: 0.6654 - val_loss: 0.6051 - val_acc: 0.6764\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6112 - acc: 0.6589 - val_loss: 0.6061 - val_acc: 0.6618\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6042 - acc: 0.6581 - val_loss: 0.6055 - val_acc: 0.6589\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.6018 - acc: 0.6625 - val_loss: 0.6049 - val_acc: 0.6793\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5992 - acc: 0.6538 - val_loss: 0.6062 - val_acc: 0.6793\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5988 - acc: 0.6611 - val_loss: 0.6044 - val_acc: 0.6764\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5966 - acc: 0.6589 - val_loss: 0.6050 - val_acc: 0.6647\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5963 - acc: 0.6523 - val_loss: 0.6057 - val_acc: 0.6735\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5947 - acc: 0.6574 - val_loss: 0.6045 - val_acc: 0.6822\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5968 - acc: 0.6676 - val_loss: 0.6122 - val_acc: 0.6676\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6050 - acc: 0.6647 - val_loss: 0.6043 - val_acc: 0.6735\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5988 - acc: 0.6684 - val_loss: 0.6042 - val_acc: 0.6531\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.5964 - acc: 0.6662 - val_loss: 0.6019 - val_acc: 0.6764\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5957 - acc: 0.6698 - val_loss: 0.6051 - val_acc: 0.6676\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5966 - acc: 0.6720 - val_loss: 0.6022 - val_acc: 0.6822\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5927 - acc: 0.6633 - val_loss: 0.6048 - val_acc: 0.6735\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.5967 - acc: 0.6647 - val_loss: 0.6057 - val_acc: 0.6706\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5938 - acc: 0.6611 - val_loss: 0.6235 - val_acc: 0.6647\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5970 - acc: 0.6808 - val_loss: 0.6118 - val_acc: 0.6764\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5915 - acc: 0.6779 - val_loss: 0.6063 - val_acc: 0.6793\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5923 - acc: 0.6822 - val_loss: 0.6066 - val_acc: 0.6735\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5890 - acc: 0.6779 - val_loss: 0.6017 - val_acc: 0.6735\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5905 - acc: 0.6801 - val_loss: 0.6030 - val_acc: 0.6735\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5976 - acc: 0.6844 - val_loss: 0.6092 - val_acc: 0.6764\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5926 - acc: 0.6881 - val_loss: 0.6175 - val_acc: 0.6443\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5987 - acc: 0.6633 - val_loss: 0.6061 - val_acc: 0.6764\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5945 - acc: 0.6625 - val_loss: 0.6095 - val_acc: 0.6676\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5969 - acc: 0.6698 - val_loss: 0.6031 - val_acc: 0.6764\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5932 - acc: 0.6669 - val_loss: 0.6079 - val_acc: 0.6706\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5891 - acc: 0.6779 - val_loss: 0.6056 - val_acc: 0.6706\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.5911 - acc: 0.6852 - val_loss: 0.6104 - val_acc: 0.6647\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5871 - acc: 0.6822 - val_loss: 0.6047 - val_acc: 0.6764\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5810 - acc: 0.6801 - val_loss: 0.6071 - val_acc: 0.6676\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5803 - acc: 0.6830 - val_loss: 0.6081 - val_acc: 0.6531\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5858 - acc: 0.6808 - val_loss: 0.6044 - val_acc: 0.6676\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5847 - acc: 0.6866 - val_loss: 0.6041 - val_acc: 0.6647\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5828 - acc: 0.6684 - val_loss: 0.6045 - val_acc: 0.6618\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5835 - acc: 0.6764 - val_loss: 0.6052 - val_acc: 0.6706\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5801 - acc: 0.6771 - val_loss: 0.6064 - val_acc: 0.6560\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5749 - acc: 0.6874 - val_loss: 0.6073 - val_acc: 0.6501\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5738 - acc: 0.6903 - val_loss: 0.6073 - val_acc: 0.6501\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5739 - acc: 0.6874 - val_loss: 0.6094 - val_acc: 0.6560\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5709 - acc: 0.6925 - val_loss: 0.6129 - val_acc: 0.6560\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5906 - acc: 0.6837 - val_loss: 0.6096 - val_acc: 0.6618\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5914 - acc: 0.6706 - val_loss: 0.5979 - val_acc: 0.6910\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.6016 - acc: 0.6662 - val_loss: 0.6350 - val_acc: 0.6443\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6071 - acc: 0.6552 - val_loss: 0.6137 - val_acc: 0.6560\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5970 - acc: 0.6691 - val_loss: 0.6065 - val_acc: 0.6706\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5905 - acc: 0.6728 - val_loss: 0.6025 - val_acc: 0.6647\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5891 - acc: 0.6742 - val_loss: 0.5998 - val_acc: 0.6647\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5896 - acc: 0.6830 - val_loss: 0.6015 - val_acc: 0.6706\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5869 - acc: 0.6691 - val_loss: 0.6055 - val_acc: 0.6501\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5862 - acc: 0.6735 - val_loss: 0.6046 - val_acc: 0.6647\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5857 - acc: 0.6728 - val_loss: 0.6046 - val_acc: 0.6647\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5884 - acc: 0.6808 - val_loss: 0.6027 - val_acc: 0.6676\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5884 - acc: 0.6742 - val_loss: 0.6033 - val_acc: 0.6764\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5809 - acc: 0.6830 - val_loss: 0.5955 - val_acc: 0.6910\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5833 - acc: 0.6859 - val_loss: 0.5947 - val_acc: 0.6706\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5735 - acc: 0.6932 - val_loss: 0.5892 - val_acc: 0.6676\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5866 - acc: 0.6815 - val_loss: 0.6134 - val_acc: 0.6647\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5905 - acc: 0.6793 - val_loss: 0.6052 - val_acc: 0.6764\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5846 - acc: 0.6852 - val_loss: 0.6034 - val_acc: 0.6793\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5773 - acc: 0.6808 - val_loss: 0.6012 - val_acc: 0.6793\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5746 - acc: 0.6969 - val_loss: 0.6098 - val_acc: 0.6968\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5712 - acc: 0.7027 - val_loss: 0.6014 - val_acc: 0.6735\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5663 - acc: 0.7129 - val_loss: 0.5984 - val_acc: 0.6618\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5647 - acc: 0.7071 - val_loss: 0.6012 - val_acc: 0.6764\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5713 - acc: 0.7049 - val_loss: 0.5991 - val_acc: 0.6764\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5638 - acc: 0.7027 - val_loss: 0.6007 - val_acc: 0.6939\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5596 - acc: 0.7137 - val_loss: 0.5905 - val_acc: 0.6968\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5538 - acc: 0.7188 - val_loss: 0.5876 - val_acc: 0.6910\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5541 - acc: 0.7246 - val_loss: 0.5863 - val_acc: 0.6939\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5525 - acc: 0.7217 - val_loss: 0.5838 - val_acc: 0.6997\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5542 - acc: 0.7137 - val_loss: 0.5970 - val_acc: 0.6939\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5458 - acc: 0.7312 - val_loss: 0.5905 - val_acc: 0.6735\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5604 - acc: 0.7056 - val_loss: 0.5881 - val_acc: 0.6910\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5591 - acc: 0.7020 - val_loss: 0.5970 - val_acc: 0.7026\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5545 - acc: 0.7275 - val_loss: 0.5900 - val_acc: 0.6910\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5456 - acc: 0.7239 - val_loss: 0.5893 - val_acc: 0.7085\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5472 - acc: 0.7246 - val_loss: 0.6017 - val_acc: 0.6968\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5467 - acc: 0.7246 - val_loss: 0.5920 - val_acc: 0.6997\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5425 - acc: 0.7392 - val_loss: 0.5954 - val_acc: 0.6968\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5468 - acc: 0.7202 - val_loss: 0.6068 - val_acc: 0.6793\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5403 - acc: 0.7305 - val_loss: 0.5940 - val_acc: 0.6939\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5401 - acc: 0.7224 - val_loss: 0.5866 - val_acc: 0.6822\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5458 - acc: 0.7305 - val_loss: 0.5907 - val_acc: 0.6910\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5485 - acc: 0.7246 - val_loss: 0.5985 - val_acc: 0.6880\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5464 - acc: 0.7246 - val_loss: 0.5875 - val_acc: 0.6997\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5481 - acc: 0.7312 - val_loss: 0.5945 - val_acc: 0.6910\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5387 - acc: 0.7268 - val_loss: 0.5995 - val_acc: 0.6939\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5454 - acc: 0.7290 - val_loss: 0.5933 - val_acc: 0.6910\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5323 - acc: 0.7458 - val_loss: 0.6041 - val_acc: 0.6968\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5380 - acc: 0.7312 - val_loss: 0.6068 - val_acc: 0.6764\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5328 - acc: 0.7370 - val_loss: 0.6005 - val_acc: 0.6851\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5354 - acc: 0.7312 - val_loss: 0.6076 - val_acc: 0.6851\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5381 - acc: 0.7319 - val_loss: 0.6018 - val_acc: 0.6822\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5360 - acc: 0.7232 - val_loss: 0.6129 - val_acc: 0.6735\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5359 - acc: 0.7348 - val_loss: 0.6063 - val_acc: 0.6822\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5299 - acc: 0.7319 - val_loss: 0.6201 - val_acc: 0.6851\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5301 - acc: 0.7429 - val_loss: 0.6146 - val_acc: 0.6968\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5364 - acc: 0.7100 - val_loss: 0.6189 - val_acc: 0.6706\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5290 - acc: 0.7305 - val_loss: 0.6097 - val_acc: 0.6939\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5424 - acc: 0.7370 - val_loss: 0.6103 - val_acc: 0.6968\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5483 - acc: 0.7232 - val_loss: 0.6217 - val_acc: 0.6997\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5499 - acc: 0.7166 - val_loss: 0.6097 - val_acc: 0.6910\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 0.5335 - acc: 0.7334 - val_loss: 0.6109 - val_acc: 0.6880\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5293 - acc: 0.7385 - val_loss: 0.6101 - val_acc: 0.6851\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5285 - acc: 0.7341 - val_loss: 0.6172 - val_acc: 0.6939\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5227 - acc: 0.7341 - val_loss: 0.6223 - val_acc: 0.6822\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5258 - acc: 0.7378 - val_loss: 0.6261 - val_acc: 0.7114\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5230 - acc: 0.7480 - val_loss: 0.6236 - val_acc: 0.6706\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5188 - acc: 0.7429 - val_loss: 0.6182 - val_acc: 0.6939\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5251 - acc: 0.7524 - val_loss: 0.6188 - val_acc: 0.7026\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5283 - acc: 0.7385 - val_loss: 0.6177 - val_acc: 0.6968\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5230 - acc: 0.7458 - val_loss: 0.6223 - val_acc: 0.7026\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5153 - acc: 0.7495 - val_loss: 0.6186 - val_acc: 0.6968\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5163 - acc: 0.7465 - val_loss: 0.6246 - val_acc: 0.6735\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5155 - acc: 0.7473 - val_loss: 0.6245 - val_acc: 0.6880\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.5271 - acc: 0.7400 - val_loss: 0.6177 - val_acc: 0.6997\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5107 - acc: 0.7538 - val_loss: 0.6172 - val_acc: 0.6880\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5161 - acc: 0.7480 - val_loss: 0.6142 - val_acc: 0.7026\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5113 - acc: 0.7531 - val_loss: 0.6164 - val_acc: 0.6822\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5178 - acc: 0.7465 - val_loss: 0.6295 - val_acc: 0.6968\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5189 - acc: 0.7429 - val_loss: 0.6198 - val_acc: 0.7026\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5161 - acc: 0.7487 - val_loss: 0.6147 - val_acc: 0.6968\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5176 - acc: 0.7495 - val_loss: 0.6180 - val_acc: 0.6968\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5050 - acc: 0.7524 - val_loss: 0.6174 - val_acc: 0.6968\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5081 - acc: 0.7516 - val_loss: 0.6151 - val_acc: 0.6793\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5079 - acc: 0.7538 - val_loss: 0.6163 - val_acc: 0.6997\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5106 - acc: 0.7502 - val_loss: 0.6194 - val_acc: 0.6939\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5025 - acc: 0.7495 - val_loss: 0.6288 - val_acc: 0.6910\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.5303 - acc: 0.7370 - val_loss: 0.6252 - val_acc: 0.6793\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5113 - acc: 0.7465 - val_loss: 0.6212 - val_acc: 0.6851\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5068 - acc: 0.7575 - val_loss: 0.6285 - val_acc: 0.6997\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.5067 - acc: 0.7531 - val_loss: 0.6346 - val_acc: 0.6880\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.4996 - acc: 0.7619 - val_loss: 0.6228 - val_acc: 0.6939\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.4988 - acc: 0.7546 - val_loss: 0.6405 - val_acc: 0.6618\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5119 - acc: 0.7473 - val_loss: 0.6319 - val_acc: 0.6822\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5278 - acc: 0.7319 - val_loss: 0.6282 - val_acc: 0.6618\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5073 - acc: 0.7458 - val_loss: 0.6313 - val_acc: 0.6997\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5078 - acc: 0.7495 - val_loss: 0.6153 - val_acc: 0.7114\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5055 - acc: 0.7495 - val_loss: 0.6210 - val_acc: 0.6851\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.4990 - acc: 0.7677 - val_loss: 0.6227 - val_acc: 0.7055\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5013 - acc: 0.7575 - val_loss: 0.6165 - val_acc: 0.7026\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.4942 - acc: 0.7633 - val_loss: 0.6566 - val_acc: 0.6676\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5077 - acc: 0.7451 - val_loss: 0.6215 - val_acc: 0.6997\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.4927 - acc: 0.7611 - val_loss: 0.6075 - val_acc: 0.6968\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.4887 - acc: 0.7619 - val_loss: 0.6265 - val_acc: 0.7055\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5061 - acc: 0.7421 - val_loss: 0.6159 - val_acc: 0.6910\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.4972 - acc: 0.7684 - val_loss: 0.6156 - val_acc: 0.7055\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5131 - acc: 0.7531 - val_loss: 0.6051 - val_acc: 0.6997\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.4944 - acc: 0.7597 - val_loss: 0.6197 - val_acc: 0.6880\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.4941 - acc: 0.7633 - val_loss: 0.6253 - val_acc: 0.6997\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.4984 - acc: 0.7582 - val_loss: 0.6098 - val_acc: 0.6880\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.4914 - acc: 0.7655 - val_loss: 0.6308 - val_acc: 0.6735\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.4913 - acc: 0.7589 - val_loss: 0.6371 - val_acc: 0.6793\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.4864 - acc: 0.7677 - val_loss: 0.6092 - val_acc: 0.6939\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.4881 - acc: 0.7714 - val_loss: 0.6271 - val_acc: 0.6880\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5059 - acc: 0.7516 - val_loss: 0.6209 - val_acc: 0.6880\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5125 - acc: 0.7553 - val_loss: 0.6407 - val_acc: 0.6822\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.4943 - acc: 0.7516 - val_loss: 0.6420 - val_acc: 0.6997\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5016 - acc: 0.7502 - val_loss: 0.6250 - val_acc: 0.6880\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5051 - acc: 0.7568 - val_loss: 0.6357 - val_acc: 0.6997\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.4957 - acc: 0.7597 - val_loss: 0.6159 - val_acc: 0.7026\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.4977 - acc: 0.7728 - val_loss: 0.6188 - val_acc: 0.6968\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.4972 - acc: 0.7546 - val_loss: 0.6223 - val_acc: 0.6880\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.4881 - acc: 0.7670 - val_loss: 0.6270 - val_acc: 0.6910\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.4836 - acc: 0.7750 - val_loss: 0.6284 - val_acc: 0.7055\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.4881 - acc: 0.7706 - val_loss: 0.6707 - val_acc: 0.6385\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.4894 - acc: 0.7736 - val_loss: 0.6459 - val_acc: 0.6793\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.4841 - acc: 0.7633 - val_loss: 0.6515 - val_acc: 0.6910\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.4803 - acc: 0.7765 - val_loss: 0.6292 - val_acc: 0.7026\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.4763 - acc: 0.7663 - val_loss: 0.6398 - val_acc: 0.7026\n",
            "Epoch 211: early stopping\n",
            "27/27 [==============================] - 2s 37ms/step - loss: 0.5570 - acc: 0.7354\n",
            "batch : 128, unit: [64, 32], dropout: 0.2, avg_accuracy: 0.7108758290608724, activation: sigmoid\n",
            "Epoch 1/1000\n",
            "11/11 [==============================] - 6s 179ms/step - loss: 0.6514 - acc: 0.4887 - val_loss: 0.6211 - val_acc: 0.6735\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6308 - acc: 0.6441 - val_loss: 0.6211 - val_acc: 0.4665\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6281 - acc: 0.5390 - val_loss: 0.6091 - val_acc: 0.6122\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6244 - acc: 0.5179 - val_loss: 0.6056 - val_acc: 0.6093\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6186 - acc: 0.6455 - val_loss: 0.6099 - val_acc: 0.5773\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6173 - acc: 0.5317 - val_loss: 0.6001 - val_acc: 0.6122\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6148 - acc: 0.5646 - val_loss: 0.6034 - val_acc: 0.5889\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6117 - acc: 0.5806 - val_loss: 0.6030 - val_acc: 0.5598\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6100 - acc: 0.5799 - val_loss: 0.5986 - val_acc: 0.5743\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.6087 - acc: 0.5886 - val_loss: 0.6009 - val_acc: 0.5510\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6070 - acc: 0.5872 - val_loss: 0.5912 - val_acc: 0.5860\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6080 - acc: 0.5945 - val_loss: 0.5976 - val_acc: 0.5773\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6084 - acc: 0.5857 - val_loss: 0.5922 - val_acc: 0.5948\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6021 - acc: 0.5945 - val_loss: 0.5894 - val_acc: 0.6531\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6114 - acc: 0.5813 - val_loss: 0.5948 - val_acc: 0.5918\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6044 - acc: 0.6025 - val_loss: 0.5925 - val_acc: 0.5860\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6023 - acc: 0.5981 - val_loss: 0.5864 - val_acc: 0.6356\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6023 - acc: 0.6156 - val_loss: 0.5896 - val_acc: 0.6035\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6096 - acc: 0.6127 - val_loss: 0.5912 - val_acc: 0.6210\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6039 - acc: 0.5966 - val_loss: 0.5866 - val_acc: 0.5948\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6003 - acc: 0.5966 - val_loss: 0.5864 - val_acc: 0.6064\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6039 - acc: 0.6083 - val_loss: 0.5862 - val_acc: 0.5977\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.6012 - acc: 0.6112 - val_loss: 0.5864 - val_acc: 0.5948\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5974 - acc: 0.6236 - val_loss: 0.6029 - val_acc: 0.5073\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.6041 - acc: 0.6047 - val_loss: 0.5886 - val_acc: 0.5831\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6045 - acc: 0.6083 - val_loss: 0.5869 - val_acc: 0.6210\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6052 - acc: 0.5996 - val_loss: 0.5823 - val_acc: 0.6443\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6052 - acc: 0.5718 - val_loss: 0.5913 - val_acc: 0.6122\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6053 - acc: 0.6280 - val_loss: 0.5998 - val_acc: 0.5277\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5985 - acc: 0.6112 - val_loss: 0.5797 - val_acc: 0.6647\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6044 - acc: 0.5974 - val_loss: 0.5828 - val_acc: 0.6735\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6019 - acc: 0.6236 - val_loss: 0.5882 - val_acc: 0.5889\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5991 - acc: 0.6112 - val_loss: 0.5833 - val_acc: 0.5918\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6021 - acc: 0.6214 - val_loss: 0.5879 - val_acc: 0.6880\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6047 - acc: 0.5609 - val_loss: 0.5946 - val_acc: 0.5685\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6009 - acc: 0.5988 - val_loss: 0.5837 - val_acc: 0.5860\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5971 - acc: 0.6083 - val_loss: 0.5854 - val_acc: 0.6035\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5990 - acc: 0.6207 - val_loss: 0.5879 - val_acc: 0.5743\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5956 - acc: 0.6397 - val_loss: 0.5782 - val_acc: 0.6122\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.6019 - acc: 0.6353 - val_loss: 0.5908 - val_acc: 0.5743\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.6004 - acc: 0.6302 - val_loss: 0.5734 - val_acc: 0.6239\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6197 - acc: 0.6207 - val_loss: 0.6048 - val_acc: 0.6589\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6269 - acc: 0.4953 - val_loss: 0.6110 - val_acc: 0.5598\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6198 - acc: 0.6280 - val_loss: 0.6020 - val_acc: 0.6181\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6134 - acc: 0.5616 - val_loss: 0.5989 - val_acc: 0.5860\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6085 - acc: 0.5646 - val_loss: 0.6038 - val_acc: 0.5423\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6066 - acc: 0.5755 - val_loss: 0.5920 - val_acc: 0.5948\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6050 - acc: 0.5872 - val_loss: 0.5915 - val_acc: 0.5977\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6013 - acc: 0.5886 - val_loss: 0.5929 - val_acc: 0.5743\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6028 - acc: 0.5850 - val_loss: 0.5776 - val_acc: 0.6327\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6048 - acc: 0.6032 - val_loss: 0.5971 - val_acc: 0.5539\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6007 - acc: 0.5974 - val_loss: 0.5884 - val_acc: 0.5743\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6014 - acc: 0.5981 - val_loss: 0.5926 - val_acc: 0.5685\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.6028 - acc: 0.5915 - val_loss: 0.5882 - val_acc: 0.5773\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5975 - acc: 0.5923 - val_loss: 0.5792 - val_acc: 0.6472\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6083 - acc: 0.5908 - val_loss: 0.6667 - val_acc: 0.4402\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6204 - acc: 0.5536 - val_loss: 0.5996 - val_acc: 0.6472\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6040 - acc: 0.6586 - val_loss: 0.5790 - val_acc: 0.6939\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6084 - acc: 0.6849 - val_loss: 0.5951 - val_acc: 0.6531\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6102 - acc: 0.5930 - val_loss: 0.6024 - val_acc: 0.6501\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6160 - acc: 0.6346 - val_loss: 0.6028 - val_acc: 0.5598\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6133 - acc: 0.5157 - val_loss: 0.5922 - val_acc: 0.5831\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6102 - acc: 0.5660 - val_loss: 0.5936 - val_acc: 0.5743\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5997 - acc: 0.5791 - val_loss: 0.5758 - val_acc: 0.6152\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6021 - acc: 0.6098 - val_loss: 0.5939 - val_acc: 0.5714\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.6367 - acc: 0.5018 - val_loss: 0.6202 - val_acc: 0.4461\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6133 - acc: 0.5179 - val_loss: 0.6023 - val_acc: 0.4781\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.6090 - acc: 0.5915 - val_loss: 0.5848 - val_acc: 0.6239\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6039 - acc: 0.6346 - val_loss: 0.5850 - val_acc: 0.6239\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5988 - acc: 0.6280 - val_loss: 0.5832 - val_acc: 0.6968\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6237 - acc: 0.5033 - val_loss: 0.6398 - val_acc: 0.3382\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6392 - acc: 0.3982 - val_loss: 0.6149 - val_acc: 0.5743\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6238 - acc: 0.6032 - val_loss: 0.6127 - val_acc: 0.6297\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6145 - acc: 0.6156 - val_loss: 0.6007 - val_acc: 0.5948\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6058 - acc: 0.5974 - val_loss: 0.5906 - val_acc: 0.5802\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6043 - acc: 0.5638 - val_loss: 0.6203 - val_acc: 0.4198\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6100 - acc: 0.6433 - val_loss: 0.6009 - val_acc: 0.6706\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6100 - acc: 0.6317 - val_loss: 0.6012 - val_acc: 0.5831\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6066 - acc: 0.5697 - val_loss: 0.5962 - val_acc: 0.5714\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6025 - acc: 0.5966 - val_loss: 0.5910 - val_acc: 0.6035\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.6032 - acc: 0.6003 - val_loss: 0.5911 - val_acc: 0.5918\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5997 - acc: 0.5996 - val_loss: 0.5888 - val_acc: 0.5918\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5987 - acc: 0.6061 - val_loss: 0.5856 - val_acc: 0.6385\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5992 - acc: 0.6360 - val_loss: 0.5849 - val_acc: 0.6297\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5953 - acc: 0.6039 - val_loss: 0.5846 - val_acc: 0.6064\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5974 - acc: 0.6142 - val_loss: 0.5831 - val_acc: 0.6064\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 0.5954 - acc: 0.6112 - val_loss: 0.5766 - val_acc: 0.6531\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6138 - acc: 0.5930 - val_loss: 0.6551 - val_acc: 0.4111\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6388 - acc: 0.4318 - val_loss: 0.6113 - val_acc: 0.3819\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6286 - acc: 0.4172 - val_loss: 0.6197 - val_acc: 0.3528\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6312 - acc: 0.4799 - val_loss: 0.6200 - val_acc: 0.3615\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6303 - acc: 0.4333 - val_loss: 0.6209 - val_acc: 0.3673\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6273 - acc: 0.4063 - val_loss: 0.6155 - val_acc: 0.4023\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6213 - acc: 0.4522 - val_loss: 0.6133 - val_acc: 0.4373\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6186 - acc: 0.4748 - val_loss: 0.6107 - val_acc: 0.4519\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.6186 - acc: 0.4763 - val_loss: 0.6103 - val_acc: 0.4519\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.6206 - acc: 0.4697 - val_loss: 0.6109 - val_acc: 0.4373\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.6184 - acc: 0.4646 - val_loss: 0.6103 - val_acc: 0.4373\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.6177 - acc: 0.4741 - val_loss: 0.6085 - val_acc: 0.4402\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6142 - acc: 0.4967 - val_loss: 0.6116 - val_acc: 0.4402\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6155 - acc: 0.4770 - val_loss: 0.6077 - val_acc: 0.6035\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6144 - acc: 0.5222 - val_loss: 0.6053 - val_acc: 0.5569\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6140 - acc: 0.5573 - val_loss: 0.6142 - val_acc: 0.4431\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6092 - acc: 0.5368 - val_loss: 0.6040 - val_acc: 0.6181\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6143 - acc: 0.5201 - val_loss: 0.6021 - val_acc: 0.5889\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6100 - acc: 0.5733 - val_loss: 0.6102 - val_acc: 0.4956\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6106 - acc: 0.5062 - val_loss: 0.5989 - val_acc: 0.5714\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6126 - acc: 0.5478 - val_loss: 0.6095 - val_acc: 0.5131\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6114 - acc: 0.5624 - val_loss: 0.6059 - val_acc: 0.4694\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6094 - acc: 0.5463 - val_loss: 0.5979 - val_acc: 0.5918\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.6069 - acc: 0.5653 - val_loss: 0.6020 - val_acc: 0.5335\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.6063 - acc: 0.5646 - val_loss: 0.5952 - val_acc: 0.5918\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6059 - acc: 0.5529 - val_loss: 0.5982 - val_acc: 0.5918\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.6069 - acc: 0.5791 - val_loss: 0.5943 - val_acc: 0.5773\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6051 - acc: 0.5806 - val_loss: 0.6128 - val_acc: 0.4694\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 0.6087 - acc: 0.5441 - val_loss: 0.5977 - val_acc: 0.6152\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6042 - acc: 0.5718 - val_loss: 0.6071 - val_acc: 0.5160\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6025 - acc: 0.5587 - val_loss: 0.5951 - val_acc: 0.6006\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6077 - acc: 0.5609 - val_loss: 0.6001 - val_acc: 0.5977\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6047 - acc: 0.5565 - val_loss: 0.5938 - val_acc: 0.5802\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6054 - acc: 0.5463 - val_loss: 0.5977 - val_acc: 0.5627\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6034 - acc: 0.5704 - val_loss: 0.6005 - val_acc: 0.5219\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6090 - acc: 0.5631 - val_loss: 0.6063 - val_acc: 0.6706\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6197 - acc: 0.6521 - val_loss: 0.5999 - val_acc: 0.6035\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.6125 - acc: 0.5667 - val_loss: 0.5980 - val_acc: 0.6560\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.6238 - acc: 0.5522 - val_loss: 0.6039 - val_acc: 0.5394\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6139 - acc: 0.6404 - val_loss: 0.6022 - val_acc: 0.6589\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6008 - acc: 0.6236 - val_loss: 0.6046 - val_acc: 0.6210\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6011 - acc: 0.6120 - val_loss: 0.5981 - val_acc: 0.6093\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5999 - acc: 0.6010 - val_loss: 0.6023 - val_acc: 0.5948\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6007 - acc: 0.5704 - val_loss: 0.6006 - val_acc: 0.6531\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6075 - acc: 0.6178 - val_loss: 0.5940 - val_acc: 0.6472\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6012 - acc: 0.6630 - val_loss: 0.5879 - val_acc: 0.6706\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5952 - acc: 0.6462 - val_loss: 0.5929 - val_acc: 0.6122\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5998 - acc: 0.6090 - val_loss: 0.5972 - val_acc: 0.6939\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6023 - acc: 0.6689 - val_loss: 0.5981 - val_acc: 0.5918\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5958 - acc: 0.6149 - val_loss: 0.5898 - val_acc: 0.6764\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5946 - acc: 0.6411 - val_loss: 0.5851 - val_acc: 0.6618\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5977 - acc: 0.6659 - val_loss: 0.5972 - val_acc: 0.7172\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6046 - acc: 0.6069 - val_loss: 0.5875 - val_acc: 0.6122\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6061 - acc: 0.5463 - val_loss: 0.5894 - val_acc: 0.6706\n",
            "Epoch 141: early stopping\n",
            "27/27 [==============================] - 2s 31ms/step - loss: 0.6155 - acc: 0.6811\n",
            "Epoch 1/1000\n",
            "11/11 [==============================] - 5s 170ms/step - loss: 0.6436 - acc: 0.4201 - val_loss: 0.6292 - val_acc: 0.4665\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6298 - acc: 0.5923 - val_loss: 0.6214 - val_acc: 0.6472\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6259 - acc: 0.6032 - val_loss: 0.6139 - val_acc: 0.5510\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6199 - acc: 0.5332 - val_loss: 0.6215 - val_acc: 0.4169\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.6145 - acc: 0.5616 - val_loss: 0.6000 - val_acc: 0.5948\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.6151 - acc: 0.5208 - val_loss: 0.5966 - val_acc: 0.5802\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6100 - acc: 0.5646 - val_loss: 0.6072 - val_acc: 0.4956\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6111 - acc: 0.5485 - val_loss: 0.5989 - val_acc: 0.5773\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6110 - acc: 0.5201 - val_loss: 0.5938 - val_acc: 0.6443\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6141 - acc: 0.5412 - val_loss: 0.6038 - val_acc: 0.5102\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6066 - acc: 0.5762 - val_loss: 0.5915 - val_acc: 0.5656\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6082 - acc: 0.5478 - val_loss: 0.5918 - val_acc: 0.5802\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6037 - acc: 0.5894 - val_loss: 0.5821 - val_acc: 0.6589\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6034 - acc: 0.6149 - val_loss: 0.5916 - val_acc: 0.6706\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6137 - acc: 0.6280 - val_loss: 0.5880 - val_acc: 0.7289\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6055 - acc: 0.6557 - val_loss: 0.6045 - val_acc: 0.6093\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6081 - acc: 0.6149 - val_loss: 0.5904 - val_acc: 0.5714\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6090 - acc: 0.5952 - val_loss: 0.6033 - val_acc: 0.5423\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6090 - acc: 0.5529 - val_loss: 0.5968 - val_acc: 0.6122\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6039 - acc: 0.5791 - val_loss: 0.5944 - val_acc: 0.5627\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6061 - acc: 0.5419 - val_loss: 0.5914 - val_acc: 0.6064\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.6053 - acc: 0.5500 - val_loss: 0.5901 - val_acc: 0.5977\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6003 - acc: 0.5857 - val_loss: 0.5862 - val_acc: 0.5743\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5973 - acc: 0.6047 - val_loss: 0.5829 - val_acc: 0.5773\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5950 - acc: 0.6236 - val_loss: 0.5843 - val_acc: 0.5714\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6034 - acc: 0.6039 - val_loss: 0.5994 - val_acc: 0.6385\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6075 - acc: 0.6185 - val_loss: 0.5995 - val_acc: 0.5743\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6025 - acc: 0.5784 - val_loss: 0.5891 - val_acc: 0.6181\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5971 - acc: 0.6047 - val_loss: 0.5927 - val_acc: 0.5481\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5974 - acc: 0.5609 - val_loss: 0.5892 - val_acc: 0.6647\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5988 - acc: 0.6302 - val_loss: 0.5877 - val_acc: 0.5627\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5992 - acc: 0.6018 - val_loss: 0.5831 - val_acc: 0.6152\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5951 - acc: 0.5799 - val_loss: 0.5804 - val_acc: 0.6064\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5936 - acc: 0.6127 - val_loss: 0.5779 - val_acc: 0.6122\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.5922 - acc: 0.5996 - val_loss: 0.5760 - val_acc: 0.6589\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5938 - acc: 0.6105 - val_loss: 0.5788 - val_acc: 0.5977\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5985 - acc: 0.6528 - val_loss: 0.5940 - val_acc: 0.5977\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5963 - acc: 0.5580 - val_loss: 0.5766 - val_acc: 0.6152\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6025 - acc: 0.6105 - val_loss: 0.6456 - val_acc: 0.5481\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6248 - acc: 0.6521 - val_loss: 0.6045 - val_acc: 0.7114\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6147 - acc: 0.5419 - val_loss: 0.6172 - val_acc: 0.4140\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6171 - acc: 0.4938 - val_loss: 0.6014 - val_acc: 0.5510\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6103 - acc: 0.6375 - val_loss: 0.6038 - val_acc: 0.6297\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6102 - acc: 0.5908 - val_loss: 0.6037 - val_acc: 0.5598\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6090 - acc: 0.5573 - val_loss: 0.5990 - val_acc: 0.5685\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6029 - acc: 0.5726 - val_loss: 0.5916 - val_acc: 0.5889\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6005 - acc: 0.5740 - val_loss: 0.5916 - val_acc: 0.5539\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5956 - acc: 0.5923 - val_loss: 0.5817 - val_acc: 0.5889\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.5946 - acc: 0.6025 - val_loss: 0.5825 - val_acc: 0.5685\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5915 - acc: 0.6258 - val_loss: 0.5821 - val_acc: 0.6297\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5904 - acc: 0.5930 - val_loss: 0.5851 - val_acc: 0.5743\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5932 - acc: 0.6105 - val_loss: 0.5793 - val_acc: 0.6618\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5873 - acc: 0.6200 - val_loss: 0.5820 - val_acc: 0.5714\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5870 - acc: 0.6171 - val_loss: 0.5728 - val_acc: 0.6239\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6153 - acc: 0.6856 - val_loss: 0.6047 - val_acc: 0.6093\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6141 - acc: 0.5208 - val_loss: 0.6055 - val_acc: 0.5481\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6089 - acc: 0.6003 - val_loss: 0.5986 - val_acc: 0.5889\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6070 - acc: 0.5624 - val_loss: 0.5974 - val_acc: 0.5743\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6062 - acc: 0.5777 - val_loss: 0.5979 - val_acc: 0.5685\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6070 - acc: 0.5755 - val_loss: 0.5952 - val_acc: 0.5598\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6056 - acc: 0.6025 - val_loss: 0.5961 - val_acc: 0.5743\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6042 - acc: 0.5580 - val_loss: 0.5909 - val_acc: 0.6122\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6052 - acc: 0.5755 - val_loss: 0.5915 - val_acc: 0.5714\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.6061 - acc: 0.6236 - val_loss: 0.5990 - val_acc: 0.5394\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.6065 - acc: 0.5478 - val_loss: 0.5939 - val_acc: 0.6560\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6064 - acc: 0.6054 - val_loss: 0.5941 - val_acc: 0.5656\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.6058 - acc: 0.5594 - val_loss: 0.5877 - val_acc: 0.6443\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6035 - acc: 0.5500 - val_loss: 0.5917 - val_acc: 0.5714\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5985 - acc: 0.6054 - val_loss: 0.5872 - val_acc: 0.5948\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5991 - acc: 0.6302 - val_loss: 0.5832 - val_acc: 0.6327\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5965 - acc: 0.6003 - val_loss: 0.5818 - val_acc: 0.6472\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5957 - acc: 0.6214 - val_loss: 0.5811 - val_acc: 0.6647\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6130 - acc: 0.6805 - val_loss: 0.6005 - val_acc: 0.6239\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6020 - acc: 0.5587 - val_loss: 0.5918 - val_acc: 0.5714\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6014 - acc: 0.5930 - val_loss: 0.5909 - val_acc: 0.5656\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5984 - acc: 0.5689 - val_loss: 0.5898 - val_acc: 0.6501\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.6004 - acc: 0.6258 - val_loss: 0.5836 - val_acc: 0.5831\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.6019 - acc: 0.5522 - val_loss: 0.5909 - val_acc: 0.5831\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.5988 - acc: 0.6309 - val_loss: 0.5872 - val_acc: 0.5918\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5914 - acc: 0.6120 - val_loss: 0.5851 - val_acc: 0.6968\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5994 - acc: 0.6317 - val_loss: 0.5944 - val_acc: 0.5539\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6040 - acc: 0.5704 - val_loss: 0.5839 - val_acc: 0.6472\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5987 - acc: 0.6849 - val_loss: 0.5890 - val_acc: 0.6414\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5902 - acc: 0.5784 - val_loss: 0.5853 - val_acc: 0.5656\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5982 - acc: 0.6244 - val_loss: 0.5962 - val_acc: 0.7085\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6087 - acc: 0.6484 - val_loss: 0.5990 - val_acc: 0.5918\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6028 - acc: 0.5974 - val_loss: 0.5908 - val_acc: 0.6152\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6106 - acc: 0.6426 - val_loss: 0.6052 - val_acc: 0.6531\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6099 - acc: 0.6163 - val_loss: 0.6064 - val_acc: 0.5423\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6079 - acc: 0.5463 - val_loss: 0.6020 - val_acc: 0.5423\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6062 - acc: 0.5485 - val_loss: 0.5932 - val_acc: 0.5831\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5994 - acc: 0.5602 - val_loss: 0.5954 - val_acc: 0.5452\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5967 - acc: 0.5558 - val_loss: 0.5909 - val_acc: 0.5510\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5964 - acc: 0.5434 - val_loss: 0.5913 - val_acc: 0.6035\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5983 - acc: 0.5616 - val_loss: 0.5928 - val_acc: 0.5685\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5909 - acc: 0.5609 - val_loss: 0.5844 - val_acc: 0.6385\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5933 - acc: 0.5937 - val_loss: 0.5780 - val_acc: 0.6268\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5920 - acc: 0.6142 - val_loss: 0.5875 - val_acc: 0.5860\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5916 - acc: 0.5945 - val_loss: 0.5811 - val_acc: 0.6297\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5891 - acc: 0.5915 - val_loss: 0.5865 - val_acc: 0.5627\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5875 - acc: 0.5996 - val_loss: 0.5799 - val_acc: 0.5977\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5830 - acc: 0.6018 - val_loss: 0.5806 - val_acc: 0.6560\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5908 - acc: 0.6375 - val_loss: 0.5826 - val_acc: 0.5743\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5878 - acc: 0.5923 - val_loss: 0.5869 - val_acc: 0.6618\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5894 - acc: 0.5835 - val_loss: 0.5790 - val_acc: 0.6181\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5863 - acc: 0.6506 - val_loss: 0.5909 - val_acc: 0.6472\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5906 - acc: 0.6039 - val_loss: 0.5805 - val_acc: 0.6385\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5891 - acc: 0.6543 - val_loss: 0.5786 - val_acc: 0.6385\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5852 - acc: 0.5886 - val_loss: 0.5768 - val_acc: 0.5948\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5874 - acc: 0.5966 - val_loss: 0.5765 - val_acc: 0.6239\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5810 - acc: 0.6207 - val_loss: 0.5734 - val_acc: 0.6589\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5803 - acc: 0.6324 - val_loss: 0.5732 - val_acc: 0.6647\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5838 - acc: 0.6674 - val_loss: 0.5738 - val_acc: 0.6356\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5778 - acc: 0.6258 - val_loss: 0.5775 - val_acc: 0.6560\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5846 - acc: 0.6513 - val_loss: 0.5890 - val_acc: 0.6676\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5902 - acc: 0.5959 - val_loss: 0.5888 - val_acc: 0.5948\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5849 - acc: 0.6229 - val_loss: 0.5808 - val_acc: 0.6064\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5816 - acc: 0.6200 - val_loss: 0.5855 - val_acc: 0.6472\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5807 - acc: 0.6222 - val_loss: 0.5773 - val_acc: 0.6093\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5811 - acc: 0.6404 - val_loss: 0.5826 - val_acc: 0.6006\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5866 - acc: 0.6105 - val_loss: 0.5774 - val_acc: 0.6560\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5858 - acc: 0.6265 - val_loss: 0.5728 - val_acc: 0.6531\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5857 - acc: 0.6076 - val_loss: 0.5762 - val_acc: 0.6152\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.5839 - acc: 0.6455 - val_loss: 0.5869 - val_acc: 0.5918\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5807 - acc: 0.6280 - val_loss: 0.5719 - val_acc: 0.7143\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5849 - acc: 0.6900 - val_loss: 0.5792 - val_acc: 0.6414\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5813 - acc: 0.6251 - val_loss: 0.5758 - val_acc: 0.6822\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5783 - acc: 0.6506 - val_loss: 0.5789 - val_acc: 0.6531\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5747 - acc: 0.6966 - val_loss: 0.5664 - val_acc: 0.6152\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5768 - acc: 0.5850 - val_loss: 0.5720 - val_acc: 0.6297\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6097 - acc: 0.6134 - val_loss: 0.5956 - val_acc: 0.6297\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6073 - acc: 0.6681 - val_loss: 0.6029 - val_acc: 0.5569\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6081 - acc: 0.5762 - val_loss: 0.5932 - val_acc: 0.6327\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5984 - acc: 0.6470 - val_loss: 0.5925 - val_acc: 0.5948\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5962 - acc: 0.6054 - val_loss: 0.5925 - val_acc: 0.6327\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.5918 - acc: 0.6382 - val_loss: 0.5887 - val_acc: 0.6035\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5921 - acc: 0.6083 - val_loss: 0.5864 - val_acc: 0.6443\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5869 - acc: 0.6346 - val_loss: 0.5845 - val_acc: 0.6414\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5878 - acc: 0.6477 - val_loss: 0.5874 - val_acc: 0.6064\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5846 - acc: 0.6112 - val_loss: 0.5831 - val_acc: 0.6210\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5947 - acc: 0.5886 - val_loss: 0.6128 - val_acc: 0.6239\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6386 - acc: 0.5755 - val_loss: 0.6140 - val_acc: 0.6268\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6132 - acc: 0.6047 - val_loss: 0.6040 - val_acc: 0.6035\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6093 - acc: 0.5872 - val_loss: 0.5976 - val_acc: 0.5364\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.6049 - acc: 0.5828 - val_loss: 0.5927 - val_acc: 0.6093\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.6033 - acc: 0.5821 - val_loss: 0.5964 - val_acc: 0.5423\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.6026 - acc: 0.5777 - val_loss: 0.5932 - val_acc: 0.5831\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.6112 - acc: 0.6171 - val_loss: 0.6056 - val_acc: 0.6618\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.6146 - acc: 0.5193 - val_loss: 0.6101 - val_acc: 0.4956\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.6127 - acc: 0.5740 - val_loss: 0.6026 - val_acc: 0.6006\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6110 - acc: 0.5799 - val_loss: 0.6074 - val_acc: 0.5219\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6087 - acc: 0.5470 - val_loss: 0.6052 - val_acc: 0.5219\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.6059 - acc: 0.5507 - val_loss: 0.6017 - val_acc: 0.5481\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.6083 - acc: 0.5288 - val_loss: 0.6039 - val_acc: 0.5160\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.6070 - acc: 0.5675 - val_loss: 0.6002 - val_acc: 0.5627\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6074 - acc: 0.5449 - val_loss: 0.6017 - val_acc: 0.5248\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6070 - acc: 0.5543 - val_loss: 0.6005 - val_acc: 0.5510\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6077 - acc: 0.5354 - val_loss: 0.6022 - val_acc: 0.5190\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6061 - acc: 0.5507 - val_loss: 0.5973 - val_acc: 0.5685\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6022 - acc: 0.5704 - val_loss: 0.5989 - val_acc: 0.5423\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6003 - acc: 0.5755 - val_loss: 0.5982 - val_acc: 0.5481\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5996 - acc: 0.5573 - val_loss: 0.5949 - val_acc: 0.5831\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5990 - acc: 0.5616 - val_loss: 0.5959 - val_acc: 0.5656\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5991 - acc: 0.5894 - val_loss: 0.5981 - val_acc: 0.5510\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.5989 - acc: 0.5733 - val_loss: 0.5946 - val_acc: 0.6297\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.6016 - acc: 0.5718 - val_loss: 0.5968 - val_acc: 0.5510\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5978 - acc: 0.5894 - val_loss: 0.5870 - val_acc: 0.6239\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5937 - acc: 0.5915 - val_loss: 0.5889 - val_acc: 0.5831\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5948 - acc: 0.5828 - val_loss: 0.5904 - val_acc: 0.5889\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5929 - acc: 0.6032 - val_loss: 0.5914 - val_acc: 0.5831\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5929 - acc: 0.6142 - val_loss: 0.6020 - val_acc: 0.5743\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5905 - acc: 0.6054 - val_loss: 0.5978 - val_acc: 0.6239\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5919 - acc: 0.6149 - val_loss: 0.5951 - val_acc: 0.5948\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5935 - acc: 0.6083 - val_loss: 0.5959 - val_acc: 0.6297\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5901 - acc: 0.6229 - val_loss: 0.5948 - val_acc: 0.5889\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5893 - acc: 0.6229 - val_loss: 0.6016 - val_acc: 0.5510\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5993 - acc: 0.5908 - val_loss: 0.5991 - val_acc: 0.6239\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.5975 - acc: 0.5718 - val_loss: 0.5984 - val_acc: 0.5889\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.5939 - acc: 0.6083 - val_loss: 0.6004 - val_acc: 0.5335\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5961 - acc: 0.5850 - val_loss: 0.5972 - val_acc: 0.5627\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6094 - acc: 0.6112 - val_loss: 0.6197 - val_acc: 0.5773\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6232 - acc: 0.4916 - val_loss: 0.6131 - val_acc: 0.5452\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6138 - acc: 0.5784 - val_loss: 0.5935 - val_acc: 0.5685\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6022 - acc: 0.5697 - val_loss: 0.5848 - val_acc: 0.6414\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5992 - acc: 0.5945 - val_loss: 0.5906 - val_acc: 0.5656\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5916 - acc: 0.5981 - val_loss: 0.5901 - val_acc: 0.5889\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5925 - acc: 0.6171 - val_loss: 0.5914 - val_acc: 0.5948\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5912 - acc: 0.6003 - val_loss: 0.5884 - val_acc: 0.6356\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5964 - acc: 0.6295 - val_loss: 0.5992 - val_acc: 0.5452\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5910 - acc: 0.6061 - val_loss: 0.5917 - val_acc: 0.5773\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5886 - acc: 0.6003 - val_loss: 0.5885 - val_acc: 0.6618\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5945 - acc: 0.6105 - val_loss: 0.5803 - val_acc: 0.6035\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5933 - acc: 0.6411 - val_loss: 0.5951 - val_acc: 0.5627\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6065 - acc: 0.5441 - val_loss: 0.6037 - val_acc: 0.5627\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6118 - acc: 0.5456 - val_loss: 0.6048 - val_acc: 0.5510\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6107 - acc: 0.5646 - val_loss: 0.6021 - val_acc: 0.5627\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6069 - acc: 0.5419 - val_loss: 0.6019 - val_acc: 0.5743\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6084 - acc: 0.5937 - val_loss: 0.6036 - val_acc: 0.6064\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6008 - acc: 0.5966 - val_loss: 0.6000 - val_acc: 0.6210\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5968 - acc: 0.6163 - val_loss: 0.5979 - val_acc: 0.5831\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5934 - acc: 0.6214 - val_loss: 0.5976 - val_acc: 0.5743\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5912 - acc: 0.6069 - val_loss: 0.6026 - val_acc: 0.5773\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5949 - acc: 0.5966 - val_loss: 0.6006 - val_acc: 0.5918\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5939 - acc: 0.6076 - val_loss: 0.5993 - val_acc: 0.5948\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.5962 - acc: 0.6171 - val_loss: 0.6012 - val_acc: 0.5510\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.5940 - acc: 0.5988 - val_loss: 0.6005 - val_acc: 0.6443\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.5929 - acc: 0.5959 - val_loss: 0.6008 - val_acc: 0.5656\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5940 - acc: 0.6142 - val_loss: 0.5990 - val_acc: 0.5656\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5957 - acc: 0.5733 - val_loss: 0.5980 - val_acc: 0.6122\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5942 - acc: 0.6171 - val_loss: 0.5977 - val_acc: 0.5190\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5956 - acc: 0.5740 - val_loss: 0.5947 - val_acc: 0.6152\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5955 - acc: 0.5653 - val_loss: 0.5907 - val_acc: 0.5977\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5929 - acc: 0.6018 - val_loss: 0.5888 - val_acc: 0.6006\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5916 - acc: 0.6047 - val_loss: 0.5887 - val_acc: 0.5860\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5891 - acc: 0.5988 - val_loss: 0.5896 - val_acc: 0.6356\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5911 - acc: 0.6112 - val_loss: 0.5887 - val_acc: 0.6152\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5918 - acc: 0.6105 - val_loss: 0.5873 - val_acc: 0.6122\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5897 - acc: 0.5988 - val_loss: 0.5851 - val_acc: 0.6268\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5831 - acc: 0.6134 - val_loss: 0.5851 - val_acc: 0.6501\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5867 - acc: 0.6317 - val_loss: 0.5896 - val_acc: 0.6210\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5905 - acc: 0.6018 - val_loss: 0.5868 - val_acc: 0.6356\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5862 - acc: 0.6229 - val_loss: 0.5960 - val_acc: 0.5394\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5922 - acc: 0.6214 - val_loss: 0.5852 - val_acc: 0.6035\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5892 - acc: 0.5828 - val_loss: 0.5809 - val_acc: 0.6093\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5884 - acc: 0.6112 - val_loss: 0.5905 - val_acc: 0.5860\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5875 - acc: 0.6309 - val_loss: 0.5820 - val_acc: 0.6735\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5886 - acc: 0.6003 - val_loss: 0.5760 - val_acc: 0.6676\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5924 - acc: 0.6302 - val_loss: 0.6111 - val_acc: 0.5452\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5968 - acc: 0.5733 - val_loss: 0.6003 - val_acc: 0.5831\n",
            "Epoch 229: early stopping\n",
            "27/27 [==============================] - 2s 37ms/step - loss: 0.6196 - acc: 0.6811\n",
            "Epoch 1/1000\n",
            "11/11 [==============================] - 6s 179ms/step - loss: 0.6564 - acc: 0.4120 - val_loss: 0.6388 - val_acc: 0.6181\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6402 - acc: 0.5588 - val_loss: 0.6325 - val_acc: 0.6006\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6311 - acc: 0.5793 - val_loss: 0.6271 - val_acc: 0.4956\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6189 - acc: 0.5508 - val_loss: 0.6208 - val_acc: 0.5685\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6087 - acc: 0.5917 - val_loss: 0.6243 - val_acc: 0.5073\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6120 - acc: 0.5559 - val_loss: 0.6167 - val_acc: 0.5714\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6139 - acc: 0.5347 - val_loss: 0.6208 - val_acc: 0.6006\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6079 - acc: 0.5617 - val_loss: 0.6162 - val_acc: 0.5714\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6042 - acc: 0.5551 - val_loss: 0.6158 - val_acc: 0.5510\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.6042 - acc: 0.5551 - val_loss: 0.6142 - val_acc: 0.5860\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.6017 - acc: 0.5654 - val_loss: 0.6143 - val_acc: 0.5569\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6010 - acc: 0.6041 - val_loss: 0.6165 - val_acc: 0.5248\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.6027 - acc: 0.5603 - val_loss: 0.6136 - val_acc: 0.5569\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6001 - acc: 0.5705 - val_loss: 0.6136 - val_acc: 0.5860\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6041 - acc: 0.5625 - val_loss: 0.6205 - val_acc: 0.4985\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6035 - acc: 0.5844 - val_loss: 0.6152 - val_acc: 0.5539\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.6107 - acc: 0.6034 - val_loss: 0.6133 - val_acc: 0.5598\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6121 - acc: 0.5362 - val_loss: 0.6164 - val_acc: 0.6122\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5993 - acc: 0.6077 - val_loss: 0.6188 - val_acc: 0.5452\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6015 - acc: 0.5537 - val_loss: 0.6132 - val_acc: 0.5714\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5994 - acc: 0.5749 - val_loss: 0.6141 - val_acc: 0.5918\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5967 - acc: 0.5793 - val_loss: 0.6128 - val_acc: 0.5860\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5971 - acc: 0.5939 - val_loss: 0.6161 - val_acc: 0.5977\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5965 - acc: 0.6077 - val_loss: 0.6149 - val_acc: 0.5510\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.5979 - acc: 0.5676 - val_loss: 0.6182 - val_acc: 0.5773\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5898 - acc: 0.6056 - val_loss: 0.6171 - val_acc: 0.6414\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5986 - acc: 0.6348 - val_loss: 0.6198 - val_acc: 0.6356\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6112 - acc: 0.5566 - val_loss: 0.6185 - val_acc: 0.5569\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.6025 - acc: 0.5771 - val_loss: 0.6194 - val_acc: 0.5685\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5977 - acc: 0.5895 - val_loss: 0.6168 - val_acc: 0.5598\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6002 - acc: 0.5530 - val_loss: 0.6200 - val_acc: 0.5977\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5988 - acc: 0.5661 - val_loss: 0.6155 - val_acc: 0.6122\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5959 - acc: 0.5763 - val_loss: 0.6189 - val_acc: 0.5598\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5935 - acc: 0.5793 - val_loss: 0.6188 - val_acc: 0.5248\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5948 - acc: 0.5771 - val_loss: 0.6126 - val_acc: 0.5831\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5952 - acc: 0.5866 - val_loss: 0.6258 - val_acc: 0.4927\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.6026 - acc: 0.5646 - val_loss: 0.6190 - val_acc: 0.5015\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6078 - acc: 0.5486 - val_loss: 0.6125 - val_acc: 0.5918\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.6000 - acc: 0.6012 - val_loss: 0.6193 - val_acc: 0.5598\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5952 - acc: 0.6063 - val_loss: 0.6110 - val_acc: 0.5977\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5957 - acc: 0.5873 - val_loss: 0.6140 - val_acc: 0.5773\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5963 - acc: 0.6063 - val_loss: 0.6170 - val_acc: 0.5481\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5932 - acc: 0.6012 - val_loss: 0.6110 - val_acc: 0.5802\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5941 - acc: 0.5968 - val_loss: 0.6145 - val_acc: 0.5598\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5918 - acc: 0.5924 - val_loss: 0.6175 - val_acc: 0.5714\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5900 - acc: 0.6056 - val_loss: 0.6407 - val_acc: 0.6181\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5889 - acc: 0.6567 - val_loss: 0.6104 - val_acc: 0.5948\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5971 - acc: 0.6757 - val_loss: 0.6142 - val_acc: 0.5714\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5830 - acc: 0.6056 - val_loss: 0.6220 - val_acc: 0.5860\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5926 - acc: 0.5997 - val_loss: 0.6154 - val_acc: 0.5452\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5843 - acc: 0.6034 - val_loss: 0.6198 - val_acc: 0.5948\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5981 - acc: 0.6194 - val_loss: 0.6156 - val_acc: 0.5394\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5968 - acc: 0.5734 - val_loss: 0.6161 - val_acc: 0.5394\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5956 - acc: 0.5939 - val_loss: 0.6139 - val_acc: 0.5685\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5956 - acc: 0.5164 - val_loss: 0.6155 - val_acc: 0.5860\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5901 - acc: 0.6289 - val_loss: 0.6205 - val_acc: 0.6472\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5939 - acc: 0.6574 - val_loss: 0.6095 - val_acc: 0.5569\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5822 - acc: 0.5902 - val_loss: 0.6155 - val_acc: 0.6414\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 0.5876 - acc: 0.6370 - val_loss: 0.6084 - val_acc: 0.5685\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5849 - acc: 0.6114 - val_loss: 0.6104 - val_acc: 0.5831\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5780 - acc: 0.6260 - val_loss: 0.6112 - val_acc: 0.5889\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5909 - acc: 0.6129 - val_loss: 0.6243 - val_acc: 0.6647\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6061 - acc: 0.5807 - val_loss: 0.6185 - val_acc: 0.5481\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6022 - acc: 0.5763 - val_loss: 0.6188 - val_acc: 0.5394\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5979 - acc: 0.5435 - val_loss: 0.6153 - val_acc: 0.5743\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5917 - acc: 0.5668 - val_loss: 0.6210 - val_acc: 0.5889\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5886 - acc: 0.5814 - val_loss: 0.6208 - val_acc: 0.5714\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.5847 - acc: 0.6070 - val_loss: 0.6150 - val_acc: 0.5452\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5785 - acc: 0.5982 - val_loss: 0.6092 - val_acc: 0.5948\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.5994 - acc: 0.5946 - val_loss: 0.6238 - val_acc: 0.6472\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.6014 - acc: 0.6640 - val_loss: 0.6182 - val_acc: 0.5802\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.6106 - acc: 0.5595 - val_loss: 0.6176 - val_acc: 0.5860\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.5952 - acc: 0.6012 - val_loss: 0.6148 - val_acc: 0.5510\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.5883 - acc: 0.5924 - val_loss: 0.6107 - val_acc: 0.5773\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.5871 - acc: 0.5603 - val_loss: 0.6120 - val_acc: 0.6239\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.5862 - acc: 0.6333 - val_loss: 0.6177 - val_acc: 0.5452\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5827 - acc: 0.6326 - val_loss: 0.6027 - val_acc: 0.6122\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.6049 - acc: 0.5595 - val_loss: 0.6259 - val_acc: 0.5627\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.6022 - acc: 0.6523 - val_loss: 0.6131 - val_acc: 0.6152\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5944 - acc: 0.5946 - val_loss: 0.6095 - val_acc: 0.5656\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5933 - acc: 0.6523 - val_loss: 0.6087 - val_acc: 0.6181\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5826 - acc: 0.6136 - val_loss: 0.6088 - val_acc: 0.6239\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5791 - acc: 0.6486 - val_loss: 0.6169 - val_acc: 0.6239\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5872 - acc: 0.6253 - val_loss: 0.6099 - val_acc: 0.5539\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5918 - acc: 0.5939 - val_loss: 0.6079 - val_acc: 0.5685\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5967 - acc: 0.6085 - val_loss: 0.6275 - val_acc: 0.6676\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6095 - acc: 0.5763 - val_loss: 0.6196 - val_acc: 0.5160\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6046 - acc: 0.5478 - val_loss: 0.6197 - val_acc: 0.5831\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5985 - acc: 0.5727 - val_loss: 0.6202 - val_acc: 0.5394\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5981 - acc: 0.5566 - val_loss: 0.6189 - val_acc: 0.5773\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5956 - acc: 0.5654 - val_loss: 0.6189 - val_acc: 0.5481\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5964 - acc: 0.5522 - val_loss: 0.6238 - val_acc: 0.4985\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5953 - acc: 0.5625 - val_loss: 0.6160 - val_acc: 0.5569\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5926 - acc: 0.5573 - val_loss: 0.6174 - val_acc: 0.5539\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5942 - acc: 0.5522 - val_loss: 0.6133 - val_acc: 0.5714\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5957 - acc: 0.5668 - val_loss: 0.6160 - val_acc: 0.5598\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.5917 - acc: 0.5836 - val_loss: 0.6146 - val_acc: 0.5510\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5896 - acc: 0.5785 - val_loss: 0.6160 - val_acc: 0.5452\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.5895 - acc: 0.5632 - val_loss: 0.6136 - val_acc: 0.5481\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5898 - acc: 0.5668 - val_loss: 0.6188 - val_acc: 0.5364\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5922 - acc: 0.5807 - val_loss: 0.6189 - val_acc: 0.5335\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5893 - acc: 0.5625 - val_loss: 0.6265 - val_acc: 0.5102\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5938 - acc: 0.5800 - val_loss: 0.6150 - val_acc: 0.6035\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5929 - acc: 0.5683 - val_loss: 0.6149 - val_acc: 0.5656\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5914 - acc: 0.5376 - val_loss: 0.6192 - val_acc: 0.5481\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5955 - acc: 0.5435 - val_loss: 0.6186 - val_acc: 0.5306\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5999 - acc: 0.5654 - val_loss: 0.6187 - val_acc: 0.4985\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5970 - acc: 0.5530 - val_loss: 0.6157 - val_acc: 0.5860\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5919 - acc: 0.5573 - val_loss: 0.6191 - val_acc: 0.5306\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5923 - acc: 0.5639 - val_loss: 0.6151 - val_acc: 0.5423\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5877 - acc: 0.5625 - val_loss: 0.6167 - val_acc: 0.5190\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.5886 - acc: 0.5683 - val_loss: 0.6145 - val_acc: 0.5743\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5899 - acc: 0.5676 - val_loss: 0.6154 - val_acc: 0.5831\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5865 - acc: 0.5858 - val_loss: 0.6139 - val_acc: 0.5685\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5874 - acc: 0.5829 - val_loss: 0.6166 - val_acc: 0.5364\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5906 - acc: 0.5997 - val_loss: 0.6123 - val_acc: 0.5977\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5879 - acc: 0.5822 - val_loss: 0.6101 - val_acc: 0.6239\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5858 - acc: 0.5975 - val_loss: 0.6092 - val_acc: 0.5743\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5877 - acc: 0.5880 - val_loss: 0.6175 - val_acc: 0.5248\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6066 - acc: 0.4960 - val_loss: 0.6137 - val_acc: 0.5481\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6035 - acc: 0.6136 - val_loss: 0.6144 - val_acc: 0.5685\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6006 - acc: 0.5683 - val_loss: 0.6163 - val_acc: 0.5569\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 0.5993 - acc: 0.5515 - val_loss: 0.6128 - val_acc: 0.6152\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5987 - acc: 0.5990 - val_loss: 0.6081 - val_acc: 0.5685\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5950 - acc: 0.6406 - val_loss: 0.6129 - val_acc: 0.6385\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5918 - acc: 0.6355 - val_loss: 0.6101 - val_acc: 0.6181\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5920 - acc: 0.6370 - val_loss: 0.6070 - val_acc: 0.5977\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.5907 - acc: 0.6077 - val_loss: 0.6090 - val_acc: 0.6327\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.5864 - acc: 0.6457 - val_loss: 0.6075 - val_acc: 0.5860\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5894 - acc: 0.5895 - val_loss: 0.6137 - val_acc: 0.6239\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5841 - acc: 0.5939 - val_loss: 0.6113 - val_acc: 0.6210\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5868 - acc: 0.6063 - val_loss: 0.6064 - val_acc: 0.5627\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5865 - acc: 0.5814 - val_loss: 0.6025 - val_acc: 0.5685\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5909 - acc: 0.5508 - val_loss: 0.6045 - val_acc: 0.5656\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5918 - acc: 0.5873 - val_loss: 0.6049 - val_acc: 0.5598\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5869 - acc: 0.5712 - val_loss: 0.6176 - val_acc: 0.6064\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5874 - acc: 0.5756 - val_loss: 0.6061 - val_acc: 0.5860\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5906 - acc: 0.6304 - val_loss: 0.6103 - val_acc: 0.5802\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5903 - acc: 0.6245 - val_loss: 0.6081 - val_acc: 0.6297\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5878 - acc: 0.6012 - val_loss: 0.6090 - val_acc: 0.6122\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.5887 - acc: 0.5749 - val_loss: 0.6214 - val_acc: 0.5423\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5914 - acc: 0.5442 - val_loss: 0.6104 - val_acc: 0.5481\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5881 - acc: 0.5727 - val_loss: 0.6194 - val_acc: 0.5510\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5855 - acc: 0.5785 - val_loss: 0.6195 - val_acc: 0.6210\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5855 - acc: 0.5800 - val_loss: 0.6153 - val_acc: 0.5539\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5821 - acc: 0.5924 - val_loss: 0.6117 - val_acc: 0.5685\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5848 - acc: 0.5822 - val_loss: 0.6164 - val_acc: 0.5802\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5827 - acc: 0.6077 - val_loss: 0.6105 - val_acc: 0.5831\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5810 - acc: 0.5946 - val_loss: 0.6150 - val_acc: 0.5831\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5872 - acc: 0.6143 - val_loss: 0.6108 - val_acc: 0.5773\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5878 - acc: 0.6187 - val_loss: 0.6810 - val_acc: 0.4431\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6083 - acc: 0.5690 - val_loss: 0.6165 - val_acc: 0.6064\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5991 - acc: 0.5296 - val_loss: 0.6151 - val_acc: 0.5044\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5889 - acc: 0.5559 - val_loss: 0.6068 - val_acc: 0.5452\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5904 - acc: 0.5500 - val_loss: 0.6079 - val_acc: 0.5598\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5921 - acc: 0.5588 - val_loss: 0.6083 - val_acc: 0.5569\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.5923 - acc: 0.5727 - val_loss: 0.6358 - val_acc: 0.5452\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.5930 - acc: 0.5931 - val_loss: 0.6041 - val_acc: 0.5452\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5904 - acc: 0.5376 - val_loss: 0.6019 - val_acc: 0.5627\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5792 - acc: 0.6172 - val_loss: 0.6124 - val_acc: 0.6385\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5811 - acc: 0.5961 - val_loss: 0.6101 - val_acc: 0.5743\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5755 - acc: 0.6056 - val_loss: 0.6067 - val_acc: 0.5481\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5826 - acc: 0.5420 - val_loss: 0.6090 - val_acc: 0.6268\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5793 - acc: 0.6056 - val_loss: 0.6097 - val_acc: 0.6093\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5817 - acc: 0.5917 - val_loss: 0.6087 - val_acc: 0.6327\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5891 - acc: 0.6362 - val_loss: 0.6067 - val_acc: 0.5685\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5779 - acc: 0.5968 - val_loss: 0.6334 - val_acc: 0.6239\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.6091 - acc: 0.6187 - val_loss: 0.6281 - val_acc: 0.6735\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.6321 - acc: 0.6581 - val_loss: 0.6271 - val_acc: 0.6356\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.6164 - acc: 0.5690 - val_loss: 0.6279 - val_acc: 0.5773\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.6108 - acc: 0.5391 - val_loss: 0.6223 - val_acc: 0.5248\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.5984 - acc: 0.5676 - val_loss: 0.6199 - val_acc: 0.5335\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5985 - acc: 0.5683 - val_loss: 0.6287 - val_acc: 0.4694\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6015 - acc: 0.5610 - val_loss: 0.6199 - val_acc: 0.6327\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6011 - acc: 0.5354 - val_loss: 0.6181 - val_acc: 0.6122\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5972 - acc: 0.5654 - val_loss: 0.6161 - val_acc: 0.5510\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5938 - acc: 0.5639 - val_loss: 0.6175 - val_acc: 0.5627\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5948 - acc: 0.5756 - val_loss: 0.6201 - val_acc: 0.5248\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5928 - acc: 0.5763 - val_loss: 0.6204 - val_acc: 0.5306\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5910 - acc: 0.5654 - val_loss: 0.6199 - val_acc: 0.5335\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5906 - acc: 0.5632 - val_loss: 0.6338 - val_acc: 0.6501\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6010 - acc: 0.5515 - val_loss: 0.6155 - val_acc: 0.5539\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5922 - acc: 0.5924 - val_loss: 0.6160 - val_acc: 0.5510\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5871 - acc: 0.5661 - val_loss: 0.6265 - val_acc: 0.6268\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.5917 - acc: 0.5822 - val_loss: 0.6121 - val_acc: 0.5656\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 0.5819 - acc: 0.5668 - val_loss: 0.6119 - val_acc: 0.5889\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.5836 - acc: 0.5953 - val_loss: 0.6073 - val_acc: 0.6268\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5905 - acc: 0.5924 - val_loss: 0.6174 - val_acc: 0.6443\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5871 - acc: 0.6289 - val_loss: 0.6346 - val_acc: 0.5277\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5823 - acc: 0.5880 - val_loss: 0.6135 - val_acc: 0.5743\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5847 - acc: 0.6165 - val_loss: 0.6129 - val_acc: 0.5423\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5837 - acc: 0.5610 - val_loss: 0.6101 - val_acc: 0.5948\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5779 - acc: 0.5946 - val_loss: 0.6137 - val_acc: 0.6239\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5888 - acc: 0.6136 - val_loss: 0.6196 - val_acc: 0.5510\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5941 - acc: 0.6362 - val_loss: 0.6043 - val_acc: 0.6268\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.5839 - acc: 0.6304 - val_loss: 0.6089 - val_acc: 0.6064\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5849 - acc: 0.6136 - val_loss: 0.6104 - val_acc: 0.6239\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.5896 - acc: 0.6019 - val_loss: 0.6097 - val_acc: 0.5598\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5832 - acc: 0.5603 - val_loss: 0.6123 - val_acc: 0.5510\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5798 - acc: 0.5778 - val_loss: 0.6042 - val_acc: 0.5364\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.5970 - acc: 0.6194 - val_loss: 0.6101 - val_acc: 0.5481\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5902 - acc: 0.5829 - val_loss: 0.6128 - val_acc: 0.5714\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5852 - acc: 0.5741 - val_loss: 0.6145 - val_acc: 0.5714\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5866 - acc: 0.5639 - val_loss: 0.6121 - val_acc: 0.5889\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5789 - acc: 0.5873 - val_loss: 0.6165 - val_acc: 0.5685\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5803 - acc: 0.5858 - val_loss: 0.6104 - val_acc: 0.5714\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5869 - acc: 0.5756 - val_loss: 0.6115 - val_acc: 0.5743\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5728 - acc: 0.6216 - val_loss: 0.6184 - val_acc: 0.5539\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6117 - acc: 0.6143 - val_loss: 0.6513 - val_acc: 0.6647\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6411 - acc: 0.4543 - val_loss: 0.6451 - val_acc: 0.3411\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6355 - acc: 0.4018 - val_loss: 0.6319 - val_acc: 0.5306\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 0.6301 - acc: 0.5741 - val_loss: 0.6305 - val_acc: 0.6414\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.6281 - acc: 0.6099 - val_loss: 0.6281 - val_acc: 0.5948\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.6249 - acc: 0.5551 - val_loss: 0.6264 - val_acc: 0.5335\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.6207 - acc: 0.5661 - val_loss: 0.6226 - val_acc: 0.5860\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6163 - acc: 0.5814 - val_loss: 0.6222 - val_acc: 0.5481\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.6140 - acc: 0.5668 - val_loss: 0.6205 - val_acc: 0.5831\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.6096 - acc: 0.5902 - val_loss: 0.6214 - val_acc: 0.5510\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.6082 - acc: 0.5953 - val_loss: 0.6233 - val_acc: 0.5248\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6085 - acc: 0.5712 - val_loss: 0.6194 - val_acc: 0.6122\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6028 - acc: 0.5909 - val_loss: 0.6192 - val_acc: 0.5685\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6014 - acc: 0.5793 - val_loss: 0.6190 - val_acc: 0.5569\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 0.6034 - acc: 0.5749 - val_loss: 0.6211 - val_acc: 0.5539\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.6008 - acc: 0.5851 - val_loss: 0.6161 - val_acc: 0.5656\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.6004 - acc: 0.5610 - val_loss: 0.6161 - val_acc: 0.5656\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.5980 - acc: 0.5727 - val_loss: 0.6148 - val_acc: 0.5685\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5974 - acc: 0.5654 - val_loss: 0.6155 - val_acc: 0.5685\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5965 - acc: 0.5756 - val_loss: 0.6148 - val_acc: 0.5977\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5971 - acc: 0.5939 - val_loss: 0.6160 - val_acc: 0.5977\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 0.5971 - acc: 0.5756 - val_loss: 0.6139 - val_acc: 0.5656\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.5953 - acc: 0.5493 - val_loss: 0.6215 - val_acc: 0.6152\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 0.6085 - acc: 0.5749 - val_loss: 0.6138 - val_acc: 0.5569\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.6020 - acc: 0.6275 - val_loss: 0.6137 - val_acc: 0.5598\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5966 - acc: 0.5508 - val_loss: 0.6180 - val_acc: 0.6093\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5999 - acc: 0.5807 - val_loss: 0.6143 - val_acc: 0.5685\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5911 - acc: 0.5953 - val_loss: 0.6171 - val_acc: 0.5685\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5926 - acc: 0.5785 - val_loss: 0.6132 - val_acc: 0.5860\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5945 - acc: 0.6092 - val_loss: 0.6254 - val_acc: 0.5015\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 0.5887 - acc: 0.5668 - val_loss: 0.6279 - val_acc: 0.6297\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.5896 - acc: 0.5880 - val_loss: 0.6230 - val_acc: 0.5306\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5926 - acc: 0.5814 - val_loss: 0.6125 - val_acc: 0.6035\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5891 - acc: 0.5866 - val_loss: 0.6191 - val_acc: 0.6239\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5920 - acc: 0.5924 - val_loss: 0.6163 - val_acc: 0.6239\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5946 - acc: 0.5807 - val_loss: 0.6129 - val_acc: 0.5773\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.5904 - acc: 0.5990 - val_loss: 0.6170 - val_acc: 0.5685\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5853 - acc: 0.5997 - val_loss: 0.6151 - val_acc: 0.5656\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 0.5867 - acc: 0.5654 - val_loss: 0.6176 - val_acc: 0.6327\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 0.5862 - acc: 0.6136 - val_loss: 0.6185 - val_acc: 0.5714\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5880 - acc: 0.6209 - val_loss: 0.6246 - val_acc: 0.5248\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5952 - acc: 0.5902 - val_loss: 0.6112 - val_acc: 0.5918\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5886 - acc: 0.5617 - val_loss: 0.6155 - val_acc: 0.5948\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.5871 - acc: 0.5997 - val_loss: 0.6202 - val_acc: 0.5423\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5877 - acc: 0.5836 - val_loss: 0.6089 - val_acc: 0.5948\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 0.5875 - acc: 0.5734 - val_loss: 0.6114 - val_acc: 0.6152\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 0.5852 - acc: 0.6297 - val_loss: 0.6310 - val_acc: 0.5102\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 0.5918 - acc: 0.5953 - val_loss: 0.6084 - val_acc: 0.5510\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.5868 - acc: 0.5537 - val_loss: 0.6114 - val_acc: 0.5889\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5838 - acc: 0.5909 - val_loss: 0.6116 - val_acc: 0.5685\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.5842 - acc: 0.5975 - val_loss: 0.6084 - val_acc: 0.6210\n",
            "Epoch 259: early stopping\n",
            "27/27 [==============================] - 2s 38ms/step - loss: 0.6148 - acc: 0.7086\n",
            "batch : 128, unit: [64, 32], dropout: 0.2, avg_accuracy: 0.6902580658594767, activation: softmax\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 7s 127ms/step - loss: 0.6424 - acc: 0.6572 - val_loss: 0.6065 - val_acc: 0.6997\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6182 - acc: 0.6630 - val_loss: 0.6479 - val_acc: 0.5948\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6345 - acc: 0.6419 - val_loss: 0.5899 - val_acc: 0.6997\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6114 - acc: 0.6681 - val_loss: 0.5798 - val_acc: 0.7026\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6037 - acc: 0.6667 - val_loss: 0.5761 - val_acc: 0.7055\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6036 - acc: 0.6579 - val_loss: 0.5905 - val_acc: 0.7114\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6066 - acc: 0.6689 - val_loss: 0.6135 - val_acc: 0.6997\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6076 - acc: 0.6674 - val_loss: 0.5863 - val_acc: 0.7085\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6061 - acc: 0.6718 - val_loss: 0.5736 - val_acc: 0.7085\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5955 - acc: 0.6703 - val_loss: 0.5772 - val_acc: 0.7085\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6062 - acc: 0.6630 - val_loss: 0.5703 - val_acc: 0.7026\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5963 - acc: 0.6674 - val_loss: 0.5673 - val_acc: 0.7085\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5928 - acc: 0.6710 - val_loss: 0.5975 - val_acc: 0.6968\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5958 - acc: 0.6703 - val_loss: 0.5762 - val_acc: 0.7114\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5971 - acc: 0.6798 - val_loss: 0.5679 - val_acc: 0.6997\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6074 - acc: 0.6623 - val_loss: 0.5689 - val_acc: 0.6997\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5966 - acc: 0.6754 - val_loss: 0.5670 - val_acc: 0.7055\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5916 - acc: 0.6732 - val_loss: 0.5776 - val_acc: 0.6880\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5925 - acc: 0.6798 - val_loss: 0.5802 - val_acc: 0.6968\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5998 - acc: 0.6747 - val_loss: 0.5702 - val_acc: 0.7114\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5922 - acc: 0.6696 - val_loss: 0.5607 - val_acc: 0.6939\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5965 - acc: 0.6740 - val_loss: 0.5680 - val_acc: 0.6997\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5933 - acc: 0.6776 - val_loss: 0.5653 - val_acc: 0.7143\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5913 - acc: 0.6798 - val_loss: 0.5683 - val_acc: 0.7143\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5919 - acc: 0.6791 - val_loss: 0.5941 - val_acc: 0.6910\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5950 - acc: 0.6798 - val_loss: 0.5742 - val_acc: 0.7143\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5908 - acc: 0.6703 - val_loss: 0.5594 - val_acc: 0.7143\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5903 - acc: 0.6834 - val_loss: 0.5607 - val_acc: 0.7114\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5926 - acc: 0.6820 - val_loss: 0.5586 - val_acc: 0.7114\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5979 - acc: 0.6747 - val_loss: 0.5618 - val_acc: 0.7026\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5923 - acc: 0.6725 - val_loss: 0.5645 - val_acc: 0.7143\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5888 - acc: 0.6820 - val_loss: 0.5580 - val_acc: 0.7114\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5996 - acc: 0.6827 - val_loss: 0.5614 - val_acc: 0.7114\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5923 - acc: 0.6827 - val_loss: 0.5616 - val_acc: 0.7085\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5909 - acc: 0.6776 - val_loss: 0.5616 - val_acc: 0.7055\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5886 - acc: 0.6849 - val_loss: 0.5696 - val_acc: 0.6851\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5977 - acc: 0.6732 - val_loss: 0.5731 - val_acc: 0.7114\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5882 - acc: 0.6798 - val_loss: 0.5675 - val_acc: 0.6968\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5895 - acc: 0.6849 - val_loss: 0.5659 - val_acc: 0.7085\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5898 - acc: 0.6769 - val_loss: 0.5599 - val_acc: 0.7055\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5912 - acc: 0.6827 - val_loss: 0.5827 - val_acc: 0.7172\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5935 - acc: 0.6769 - val_loss: 0.5657 - val_acc: 0.7055\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5876 - acc: 0.6783 - val_loss: 0.5604 - val_acc: 0.7172\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5875 - acc: 0.6798 - val_loss: 0.5582 - val_acc: 0.7055\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6012 - acc: 0.6667 - val_loss: 0.5673 - val_acc: 0.6968\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5929 - acc: 0.6798 - val_loss: 0.5692 - val_acc: 0.7201\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5911 - acc: 0.6783 - val_loss: 0.5725 - val_acc: 0.6939\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5892 - acc: 0.6805 - val_loss: 0.5673 - val_acc: 0.7055\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5847 - acc: 0.6667 - val_loss: 0.5667 - val_acc: 0.7085\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5910 - acc: 0.6791 - val_loss: 0.5659 - val_acc: 0.7085\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5848 - acc: 0.6834 - val_loss: 0.5597 - val_acc: 0.7201\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5882 - acc: 0.6725 - val_loss: 0.5639 - val_acc: 0.7114\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5869 - acc: 0.6871 - val_loss: 0.5606 - val_acc: 0.7085\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5826 - acc: 0.6856 - val_loss: 0.5630 - val_acc: 0.7143\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5908 - acc: 0.6834 - val_loss: 0.5626 - val_acc: 0.6997\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5957 - acc: 0.6783 - val_loss: 0.5631 - val_acc: 0.7114\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5920 - acc: 0.6776 - val_loss: 0.5603 - val_acc: 0.7143\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5858 - acc: 0.6893 - val_loss: 0.5758 - val_acc: 0.6880\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5900 - acc: 0.6681 - val_loss: 0.5678 - val_acc: 0.6997\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5833 - acc: 0.6864 - val_loss: 0.5656 - val_acc: 0.7114\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5874 - acc: 0.6820 - val_loss: 0.5624 - val_acc: 0.7172\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5819 - acc: 0.6864 - val_loss: 0.5728 - val_acc: 0.7055\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5821 - acc: 0.6783 - val_loss: 0.5592 - val_acc: 0.7085\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5917 - acc: 0.6842 - val_loss: 0.5616 - val_acc: 0.7055\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5844 - acc: 0.6805 - val_loss: 0.5597 - val_acc: 0.7172\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5902 - acc: 0.6871 - val_loss: 0.5697 - val_acc: 0.7055\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5996 - acc: 0.6864 - val_loss: 0.5680 - val_acc: 0.7085\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5917 - acc: 0.6827 - val_loss: 0.5658 - val_acc: 0.7201\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5853 - acc: 0.6893 - val_loss: 0.5546 - val_acc: 0.7085\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.5776 - acc: 0.6937 - val_loss: 0.5556 - val_acc: 0.7318\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5756 - acc: 0.6973 - val_loss: 0.5571 - val_acc: 0.7114\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5818 - acc: 0.6791 - val_loss: 0.5677 - val_acc: 0.7201\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5804 - acc: 0.7031 - val_loss: 0.5714 - val_acc: 0.7114\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5891 - acc: 0.6783 - val_loss: 0.5630 - val_acc: 0.6968\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6020 - acc: 0.6718 - val_loss: 0.5918 - val_acc: 0.6997\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5926 - acc: 0.6535 - val_loss: 0.5682 - val_acc: 0.6997\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6076 - acc: 0.6696 - val_loss: 0.5838 - val_acc: 0.7055\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5972 - acc: 0.6681 - val_loss: 0.5738 - val_acc: 0.7114\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5999 - acc: 0.6674 - val_loss: 0.5830 - val_acc: 0.6939\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5959 - acc: 0.6740 - val_loss: 0.5732 - val_acc: 0.7055\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5920 - acc: 0.6827 - val_loss: 0.5798 - val_acc: 0.6939\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5892 - acc: 0.6820 - val_loss: 0.5701 - val_acc: 0.7026\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5881 - acc: 0.6827 - val_loss: 0.5804 - val_acc: 0.6997\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5916 - acc: 0.6900 - val_loss: 0.5648 - val_acc: 0.6997\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5863 - acc: 0.6791 - val_loss: 0.5601 - val_acc: 0.7055\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5901 - acc: 0.6856 - val_loss: 0.5654 - val_acc: 0.7114\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.5937 - acc: 0.6783 - val_loss: 0.5586 - val_acc: 0.7143\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5839 - acc: 0.6783 - val_loss: 0.5571 - val_acc: 0.7114\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5819 - acc: 0.6849 - val_loss: 0.5712 - val_acc: 0.7085\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5855 - acc: 0.6849 - val_loss: 0.5590 - val_acc: 0.7026\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5820 - acc: 0.6769 - val_loss: 0.5630 - val_acc: 0.7085\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5854 - acc: 0.6885 - val_loss: 0.5569 - val_acc: 0.7026\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5878 - acc: 0.6849 - val_loss: 0.5589 - val_acc: 0.7085\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5869 - acc: 0.6827 - val_loss: 0.5833 - val_acc: 0.7085\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5950 - acc: 0.6747 - val_loss: 0.5628 - val_acc: 0.7026\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5905 - acc: 0.6783 - val_loss: 0.5585 - val_acc: 0.7085\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5853 - acc: 0.6681 - val_loss: 0.5657 - val_acc: 0.7055\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5804 - acc: 0.6834 - val_loss: 0.5546 - val_acc: 0.7085\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5800 - acc: 0.6820 - val_loss: 0.5591 - val_acc: 0.7026\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5876 - acc: 0.6885 - val_loss: 0.5692 - val_acc: 0.7026\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5856 - acc: 0.6813 - val_loss: 0.5557 - val_acc: 0.7055\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5849 - acc: 0.6776 - val_loss: 0.5614 - val_acc: 0.7055\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5819 - acc: 0.6834 - val_loss: 0.5569 - val_acc: 0.7114\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5863 - acc: 0.6791 - val_loss: 0.5649 - val_acc: 0.7114\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5845 - acc: 0.6856 - val_loss: 0.5507 - val_acc: 0.7259\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5801 - acc: 0.6842 - val_loss: 0.5540 - val_acc: 0.7230\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5799 - acc: 0.6937 - val_loss: 0.5623 - val_acc: 0.7318\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6276 - acc: 0.6754 - val_loss: 0.6155 - val_acc: 0.7114\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6400 - acc: 0.6761 - val_loss: 0.6156 - val_acc: 0.7114\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6296 - acc: 0.6761 - val_loss: 0.5985 - val_acc: 0.7143\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6326 - acc: 0.6747 - val_loss: 0.6003 - val_acc: 0.7143\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6349 - acc: 0.6740 - val_loss: 0.5988 - val_acc: 0.7143\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6302 - acc: 0.6747 - val_loss: 0.5990 - val_acc: 0.7143\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6210 - acc: 0.6754 - val_loss: 0.5891 - val_acc: 0.7143\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6201 - acc: 0.6732 - val_loss: 0.5805 - val_acc: 0.7143\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6139 - acc: 0.6718 - val_loss: 0.5837 - val_acc: 0.7143\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6045 - acc: 0.6747 - val_loss: 0.6185 - val_acc: 0.7143\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6280 - acc: 0.6754 - val_loss: 0.5890 - val_acc: 0.7143\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6138 - acc: 0.6754 - val_loss: 0.5838 - val_acc: 0.7114\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.6196 - acc: 0.6718 - val_loss: 0.5732 - val_acc: 0.7114\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6067 - acc: 0.6754 - val_loss: 0.5639 - val_acc: 0.7114\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6115 - acc: 0.6718 - val_loss: 0.5779 - val_acc: 0.7143\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6138 - acc: 0.6827 - val_loss: 0.5744 - val_acc: 0.7143\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6069 - acc: 0.6805 - val_loss: 0.5818 - val_acc: 0.7172\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6048 - acc: 0.6820 - val_loss: 0.5608 - val_acc: 0.7172\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6027 - acc: 0.6805 - val_loss: 0.5585 - val_acc: 0.7172\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5949 - acc: 0.6820 - val_loss: 0.5593 - val_acc: 0.7172\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5940 - acc: 0.6791 - val_loss: 0.5664 - val_acc: 0.7143\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5913 - acc: 0.6791 - val_loss: 0.5521 - val_acc: 0.7172\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5913 - acc: 0.6813 - val_loss: 0.5684 - val_acc: 0.6968\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5983 - acc: 0.6740 - val_loss: 0.5864 - val_acc: 0.7143\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6014 - acc: 0.6747 - val_loss: 0.5687 - val_acc: 0.7114\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5955 - acc: 0.6769 - val_loss: 0.5526 - val_acc: 0.7172\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5954 - acc: 0.6864 - val_loss: 0.5897 - val_acc: 0.7114\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6006 - acc: 0.6813 - val_loss: 0.5764 - val_acc: 0.7055\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5873 - acc: 0.6929 - val_loss: 0.5585 - val_acc: 0.7143\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5908 - acc: 0.6856 - val_loss: 0.5538 - val_acc: 0.7172\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5962 - acc: 0.6864 - val_loss: 0.5660 - val_acc: 0.7114\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5883 - acc: 0.6907 - val_loss: 0.5605 - val_acc: 0.7114\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5834 - acc: 0.6885 - val_loss: 0.5587 - val_acc: 0.7143\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5911 - acc: 0.6966 - val_loss: 0.5739 - val_acc: 0.7143\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5854 - acc: 0.6988 - val_loss: 0.5770 - val_acc: 0.7172\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5911 - acc: 0.6907 - val_loss: 0.5728 - val_acc: 0.7114\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5933 - acc: 0.6878 - val_loss: 0.5713 - val_acc: 0.7114\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5784 - acc: 0.6973 - val_loss: 0.5552 - val_acc: 0.7143\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5864 - acc: 0.6834 - val_loss: 0.5634 - val_acc: 0.7230\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5824 - acc: 0.6980 - val_loss: 0.5469 - val_acc: 0.7230\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5747 - acc: 0.7119 - val_loss: 0.5599 - val_acc: 0.7201\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5864 - acc: 0.7039 - val_loss: 0.5577 - val_acc: 0.7201\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5803 - acc: 0.6929 - val_loss: 0.5570 - val_acc: 0.7230\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5903 - acc: 0.6864 - val_loss: 0.5649 - val_acc: 0.7172\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5879 - acc: 0.6834 - val_loss: 0.5625 - val_acc: 0.7259\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5906 - acc: 0.6871 - val_loss: 0.5599 - val_acc: 0.7201\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5794 - acc: 0.7017 - val_loss: 0.5448 - val_acc: 0.7289\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5787 - acc: 0.7053 - val_loss: 0.5452 - val_acc: 0.7405\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5790 - acc: 0.6995 - val_loss: 0.5413 - val_acc: 0.7464\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5800 - acc: 0.7068 - val_loss: 0.5549 - val_acc: 0.7376\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5778 - acc: 0.7090 - val_loss: 0.5459 - val_acc: 0.7434\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5751 - acc: 0.7104 - val_loss: 0.5566 - val_acc: 0.7289\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5823 - acc: 0.7104 - val_loss: 0.5653 - val_acc: 0.7318\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5910 - acc: 0.6988 - val_loss: 0.5717 - val_acc: 0.7172\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5885 - acc: 0.6958 - val_loss: 0.5635 - val_acc: 0.7347\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5887 - acc: 0.6944 - val_loss: 0.5505 - val_acc: 0.7201\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5791 - acc: 0.6929 - val_loss: 0.5506 - val_acc: 0.7318\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5816 - acc: 0.6937 - val_loss: 0.5512 - val_acc: 0.7230\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5816 - acc: 0.7061 - val_loss: 0.5567 - val_acc: 0.7201\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5819 - acc: 0.6973 - val_loss: 0.5727 - val_acc: 0.7201\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5757 - acc: 0.7053 - val_loss: 0.5557 - val_acc: 0.7289\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5757 - acc: 0.7075 - val_loss: 0.5587 - val_acc: 0.7259\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5804 - acc: 0.7017 - val_loss: 0.5567 - val_acc: 0.7230\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5740 - acc: 0.7075 - val_loss: 0.5737 - val_acc: 0.7055\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5765 - acc: 0.7053 - val_loss: 0.5644 - val_acc: 0.7055\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5880 - acc: 0.6951 - val_loss: 0.5746 - val_acc: 0.7055\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5860 - acc: 0.6907 - val_loss: 0.5720 - val_acc: 0.7201\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6008 - acc: 0.6988 - val_loss: 0.5818 - val_acc: 0.7201\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5974 - acc: 0.7009 - val_loss: 0.5614 - val_acc: 0.7289\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5899 - acc: 0.7053 - val_loss: 0.5628 - val_acc: 0.7289\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5877 - acc: 0.7068 - val_loss: 0.5560 - val_acc: 0.7259\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6019 - acc: 0.6827 - val_loss: 0.5840 - val_acc: 0.7114\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5986 - acc: 0.6798 - val_loss: 0.5679 - val_acc: 0.7143\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5932 - acc: 0.6827 - val_loss: 0.5610 - val_acc: 0.7114\n",
            "Epoch 182/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5947 - acc: 0.6813 - val_loss: 0.5610 - val_acc: 0.7143\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5889 - acc: 0.6791 - val_loss: 0.5600 - val_acc: 0.7143\n",
            "Epoch 184/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5937 - acc: 0.6827 - val_loss: 0.5531 - val_acc: 0.7143\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5896 - acc: 0.6827 - val_loss: 0.5601 - val_acc: 0.7143\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5961 - acc: 0.6842 - val_loss: 0.5661 - val_acc: 0.7114\n",
            "Epoch 187/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5911 - acc: 0.6820 - val_loss: 0.5562 - val_acc: 0.7114\n",
            "Epoch 188/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5887 - acc: 0.6849 - val_loss: 0.5551 - val_acc: 0.7172\n",
            "Epoch 189/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5916 - acc: 0.6820 - val_loss: 0.5611 - val_acc: 0.7114\n",
            "Epoch 190/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5910 - acc: 0.6871 - val_loss: 0.5587 - val_acc: 0.7172\n",
            "Epoch 191/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5982 - acc: 0.6805 - val_loss: 0.5596 - val_acc: 0.7143\n",
            "Epoch 192/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5819 - acc: 0.6915 - val_loss: 0.5613 - val_acc: 0.7172\n",
            "Epoch 193/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5817 - acc: 0.6900 - val_loss: 0.5541 - val_acc: 0.7172\n",
            "Epoch 194/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5883 - acc: 0.6893 - val_loss: 0.5540 - val_acc: 0.7143\n",
            "Epoch 195/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5801 - acc: 0.6915 - val_loss: 0.5479 - val_acc: 0.7259\n",
            "Epoch 196/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5863 - acc: 0.6871 - val_loss: 0.5588 - val_acc: 0.7230\n",
            "Epoch 197/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5810 - acc: 0.6966 - val_loss: 0.5578 - val_acc: 0.7259\n",
            "Epoch 198/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5873 - acc: 0.6849 - val_loss: 0.5645 - val_acc: 0.7143\n",
            "Epoch 199/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5857 - acc: 0.6893 - val_loss: 0.5659 - val_acc: 0.7143\n",
            "Epoch 200/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5863 - acc: 0.6856 - val_loss: 0.5992 - val_acc: 0.6764\n",
            "Epoch 201/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5871 - acc: 0.7031 - val_loss: 0.5728 - val_acc: 0.7085\n",
            "Epoch 202/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5813 - acc: 0.6929 - val_loss: 0.5668 - val_acc: 0.7230\n",
            "Epoch 203/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5816 - acc: 0.6878 - val_loss: 0.5604 - val_acc: 0.7114\n",
            "Epoch 204/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5857 - acc: 0.6893 - val_loss: 0.5679 - val_acc: 0.6910\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5824 - acc: 0.6900 - val_loss: 0.5766 - val_acc: 0.6880\n",
            "Epoch 206/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5838 - acc: 0.6995 - val_loss: 0.5696 - val_acc: 0.6997\n",
            "Epoch 207/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5839 - acc: 0.6958 - val_loss: 0.5726 - val_acc: 0.7055\n",
            "Epoch 208/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5843 - acc: 0.6980 - val_loss: 0.5673 - val_acc: 0.6968\n",
            "Epoch 209/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5806 - acc: 0.6988 - val_loss: 0.5633 - val_acc: 0.7026\n",
            "Epoch 210/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5828 - acc: 0.6980 - val_loss: 0.5691 - val_acc: 0.6968\n",
            "Epoch 211/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5829 - acc: 0.7097 - val_loss: 0.5685 - val_acc: 0.7085\n",
            "Epoch 212/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5771 - acc: 0.7046 - val_loss: 0.5714 - val_acc: 0.6910\n",
            "Epoch 213/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5784 - acc: 0.7039 - val_loss: 0.5607 - val_acc: 0.7085\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5756 - acc: 0.7009 - val_loss: 0.5729 - val_acc: 0.6822\n",
            "Epoch 215/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5809 - acc: 0.6937 - val_loss: 0.5710 - val_acc: 0.6910\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5757 - acc: 0.7031 - val_loss: 0.6260 - val_acc: 0.6152\n",
            "Epoch 217/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6270 - acc: 0.6047 - val_loss: 0.5953 - val_acc: 0.6997\n",
            "Epoch 218/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6079 - acc: 0.6689 - val_loss: 0.5876 - val_acc: 0.6997\n",
            "Epoch 219/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6066 - acc: 0.6689 - val_loss: 0.5833 - val_acc: 0.6997\n",
            "Epoch 220/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5989 - acc: 0.6689 - val_loss: 0.5839 - val_acc: 0.6997\n",
            "Epoch 221/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5992 - acc: 0.6689 - val_loss: 0.5840 - val_acc: 0.6997\n",
            "Epoch 222/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5955 - acc: 0.6689 - val_loss: 0.5872 - val_acc: 0.6997\n",
            "Epoch 223/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6016 - acc: 0.6696 - val_loss: 0.5927 - val_acc: 0.6997\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6130 - acc: 0.6689 - val_loss: 0.6071 - val_acc: 0.6997\n",
            "Epoch 225/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6140 - acc: 0.6689 - val_loss: 0.5841 - val_acc: 0.6997\n",
            "Epoch 226/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5976 - acc: 0.6696 - val_loss: 0.5733 - val_acc: 0.6997\n",
            "Epoch 227/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5995 - acc: 0.6696 - val_loss: 0.5805 - val_acc: 0.6997\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5943 - acc: 0.6696 - val_loss: 0.5695 - val_acc: 0.6997\n",
            "Epoch 229/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5961 - acc: 0.6667 - val_loss: 0.5658 - val_acc: 0.6997\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5941 - acc: 0.6703 - val_loss: 0.5620 - val_acc: 0.6997\n",
            "Epoch 231/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5885 - acc: 0.6725 - val_loss: 0.5679 - val_acc: 0.6997\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5807 - acc: 0.6710 - val_loss: 0.5686 - val_acc: 0.6997\n",
            "Epoch 233/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5854 - acc: 0.6834 - val_loss: 0.5701 - val_acc: 0.6939\n",
            "Epoch 234/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5837 - acc: 0.6783 - val_loss: 0.5603 - val_acc: 0.7026\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5787 - acc: 0.6900 - val_loss: 0.5610 - val_acc: 0.7055\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5835 - acc: 0.6827 - val_loss: 0.5629 - val_acc: 0.7085\n",
            "Epoch 237/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5850 - acc: 0.7039 - val_loss: 0.5779 - val_acc: 0.7114\n",
            "Epoch 238/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5900 - acc: 0.6754 - val_loss: 0.5618 - val_acc: 0.7172\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5863 - acc: 0.6769 - val_loss: 0.5838 - val_acc: 0.6793\n",
            "Epoch 240/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5868 - acc: 0.6834 - val_loss: 0.5654 - val_acc: 0.7289\n",
            "Epoch 241/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5870 - acc: 0.6871 - val_loss: 0.5551 - val_acc: 0.7172\n",
            "Epoch 242/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5816 - acc: 0.6907 - val_loss: 0.5896 - val_acc: 0.6531\n",
            "Epoch 243/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6183 - acc: 0.6689 - val_loss: 0.5862 - val_acc: 0.6997\n",
            "Epoch 244/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6045 - acc: 0.6805 - val_loss: 0.5793 - val_acc: 0.7055\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6013 - acc: 0.6798 - val_loss: 0.5746 - val_acc: 0.7026\n",
            "Epoch 246/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6049 - acc: 0.6820 - val_loss: 0.6087 - val_acc: 0.6997\n",
            "Epoch 247/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6294 - acc: 0.6689 - val_loss: 0.6019 - val_acc: 0.6997\n",
            "Epoch 248/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6343 - acc: 0.6659 - val_loss: 0.6038 - val_acc: 0.6997\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6293 - acc: 0.6689 - val_loss: 0.6029 - val_acc: 0.6997\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6267 - acc: 0.6689 - val_loss: 0.5907 - val_acc: 0.6997\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6168 - acc: 0.6689 - val_loss: 0.5781 - val_acc: 0.6997\n",
            "Epoch 252/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6096 - acc: 0.6623 - val_loss: 0.5775 - val_acc: 0.6997\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6168 - acc: 0.6601 - val_loss: 0.5762 - val_acc: 0.6997\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6034 - acc: 0.6718 - val_loss: 0.5892 - val_acc: 0.6997\n",
            "Epoch 255/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5992 - acc: 0.6667 - val_loss: 0.5752 - val_acc: 0.6997\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6028 - acc: 0.6659 - val_loss: 0.5681 - val_acc: 0.6997\n",
            "Epoch 256: early stopping\n",
            "27/27 [==============================] - 3s 38ms/step - loss: 0.5961 - acc: 0.6951\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 6s 124ms/step - loss: 0.6397 - acc: 0.6521 - val_loss: 0.6047 - val_acc: 0.6997\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6234 - acc: 0.6761 - val_loss: 0.5956 - val_acc: 0.6997\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6137 - acc: 0.6761 - val_loss: 0.5721 - val_acc: 0.6997\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6033 - acc: 0.6754 - val_loss: 0.5872 - val_acc: 0.6997\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6023 - acc: 0.6754 - val_loss: 0.6074 - val_acc: 0.6997\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6113 - acc: 0.6769 - val_loss: 0.5804 - val_acc: 0.6997\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6035 - acc: 0.6769 - val_loss: 0.5758 - val_acc: 0.6968\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5989 - acc: 0.6754 - val_loss: 0.5791 - val_acc: 0.6997\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6032 - acc: 0.6747 - val_loss: 0.5721 - val_acc: 0.6997\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6063 - acc: 0.6754 - val_loss: 0.5726 - val_acc: 0.6997\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6057 - acc: 0.6754 - val_loss: 0.5726 - val_acc: 0.6997\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6031 - acc: 0.6783 - val_loss: 0.5729 - val_acc: 0.6997\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6015 - acc: 0.6776 - val_loss: 0.5709 - val_acc: 0.6968\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5989 - acc: 0.6798 - val_loss: 0.5713 - val_acc: 0.7172\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5913 - acc: 0.6849 - val_loss: 0.5740 - val_acc: 0.6968\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5916 - acc: 0.6769 - val_loss: 0.5791 - val_acc: 0.6968\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5940 - acc: 0.6871 - val_loss: 0.5982 - val_acc: 0.6706\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5916 - acc: 0.6834 - val_loss: 0.5661 - val_acc: 0.7143\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5954 - acc: 0.6798 - val_loss: 0.5692 - val_acc: 0.7026\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5884 - acc: 0.6885 - val_loss: 0.5666 - val_acc: 0.7026\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5992 - acc: 0.6725 - val_loss: 0.5715 - val_acc: 0.6997\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5970 - acc: 0.6769 - val_loss: 0.5690 - val_acc: 0.7055\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5931 - acc: 0.6834 - val_loss: 0.5703 - val_acc: 0.7114\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5887 - acc: 0.6834 - val_loss: 0.5661 - val_acc: 0.7085\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5878 - acc: 0.6849 - val_loss: 0.5681 - val_acc: 0.7055\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5961 - acc: 0.6878 - val_loss: 0.5656 - val_acc: 0.7085\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5935 - acc: 0.6805 - val_loss: 0.5696 - val_acc: 0.7026\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.5875 - acc: 0.6915 - val_loss: 0.5651 - val_acc: 0.6997\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5879 - acc: 0.6937 - val_loss: 0.5652 - val_acc: 0.7055\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5867 - acc: 0.6922 - val_loss: 0.5666 - val_acc: 0.7085\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5918 - acc: 0.6922 - val_loss: 0.5668 - val_acc: 0.7026\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5841 - acc: 0.6958 - val_loss: 0.5704 - val_acc: 0.7085\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5865 - acc: 0.6980 - val_loss: 0.5727 - val_acc: 0.7026\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5831 - acc: 0.6995 - val_loss: 0.5632 - val_acc: 0.7172\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5807 - acc: 0.6973 - val_loss: 0.5689 - val_acc: 0.6968\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5908 - acc: 0.6878 - val_loss: 0.5837 - val_acc: 0.7085\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5863 - acc: 0.6929 - val_loss: 0.5738 - val_acc: 0.7201\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5914 - acc: 0.6944 - val_loss: 0.5782 - val_acc: 0.7085\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5846 - acc: 0.7002 - val_loss: 0.5616 - val_acc: 0.7172\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5859 - acc: 0.7017 - val_loss: 0.5557 - val_acc: 0.7318\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5965 - acc: 0.6776 - val_loss: 0.6994 - val_acc: 0.6239\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5943 - acc: 0.6885 - val_loss: 0.5716 - val_acc: 0.7055\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5871 - acc: 0.6900 - val_loss: 0.5703 - val_acc: 0.7085\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.5834 - acc: 0.7009 - val_loss: 0.5789 - val_acc: 0.7085\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5875 - acc: 0.6966 - val_loss: 0.5685 - val_acc: 0.7230\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5813 - acc: 0.7002 - val_loss: 0.5840 - val_acc: 0.6851\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5905 - acc: 0.6966 - val_loss: 0.5706 - val_acc: 0.7055\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5824 - acc: 0.6944 - val_loss: 0.5693 - val_acc: 0.7201\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5887 - acc: 0.6893 - val_loss: 0.5738 - val_acc: 0.7085\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5806 - acc: 0.7002 - val_loss: 0.5705 - val_acc: 0.7085\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5795 - acc: 0.7068 - val_loss: 0.6456 - val_acc: 0.6793\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5881 - acc: 0.6937 - val_loss: 0.5778 - val_acc: 0.6997\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5912 - acc: 0.6856 - val_loss: 0.5837 - val_acc: 0.6647\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5926 - acc: 0.6747 - val_loss: 0.5665 - val_acc: 0.6997\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5876 - acc: 0.6907 - val_loss: 0.5705 - val_acc: 0.7085\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5816 - acc: 0.7002 - val_loss: 0.5745 - val_acc: 0.6676\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5970 - acc: 0.6557 - val_loss: 0.5653 - val_acc: 0.6997\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5881 - acc: 0.6681 - val_loss: 0.5688 - val_acc: 0.6793\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5758 - acc: 0.7039 - val_loss: 0.5683 - val_acc: 0.6910\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5889 - acc: 0.6594 - val_loss: 0.5728 - val_acc: 0.6997\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5929 - acc: 0.6776 - val_loss: 0.5833 - val_acc: 0.6997\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6050 - acc: 0.6791 - val_loss: 0.5695 - val_acc: 0.6997\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5918 - acc: 0.6951 - val_loss: 0.5660 - val_acc: 0.7318\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5816 - acc: 0.7075 - val_loss: 0.5624 - val_acc: 0.7376\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5833 - acc: 0.7082 - val_loss: 0.5593 - val_acc: 0.7376\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6782 - acc: 0.5514 - val_loss: 0.6162 - val_acc: 0.6997\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6402 - acc: 0.6761 - val_loss: 0.6110 - val_acc: 0.6997\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6331 - acc: 0.6761 - val_loss: 0.6120 - val_acc: 0.6997\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6313 - acc: 0.6761 - val_loss: 0.6066 - val_acc: 0.6997\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6270 - acc: 0.6761 - val_loss: 0.6130 - val_acc: 0.6997\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6327 - acc: 0.6761 - val_loss: 0.6050 - val_acc: 0.6997\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6198 - acc: 0.6761 - val_loss: 0.5915 - val_acc: 0.6997\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6276 - acc: 0.6761 - val_loss: 0.6105 - val_acc: 0.6997\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6318 - acc: 0.6761 - val_loss: 0.6117 - val_acc: 0.6997\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6285 - acc: 0.6761 - val_loss: 0.6081 - val_acc: 0.6997\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 3s 117ms/step - loss: 0.6285 - acc: 0.6761 - val_loss: 0.6056 - val_acc: 0.6997\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6278 - acc: 0.6761 - val_loss: 0.6081 - val_acc: 0.6997\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6218 - acc: 0.6761 - val_loss: 0.5951 - val_acc: 0.6997\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6195 - acc: 0.6761 - val_loss: 0.5832 - val_acc: 0.6997\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6166 - acc: 0.6761 - val_loss: 0.5779 - val_acc: 0.6997\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6108 - acc: 0.6761 - val_loss: 0.5785 - val_acc: 0.6997\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6071 - acc: 0.6761 - val_loss: 0.5795 - val_acc: 0.6997\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6103 - acc: 0.6761 - val_loss: 0.5768 - val_acc: 0.6997\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6032 - acc: 0.6761 - val_loss: 0.5783 - val_acc: 0.6997\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6106 - acc: 0.6761 - val_loss: 0.5750 - val_acc: 0.6997\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6089 - acc: 0.6761 - val_loss: 0.5966 - val_acc: 0.6997\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6110 - acc: 0.6769 - val_loss: 0.5836 - val_acc: 0.6997\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5988 - acc: 0.6769 - val_loss: 0.5906 - val_acc: 0.6997\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6064 - acc: 0.6769 - val_loss: 0.5736 - val_acc: 0.6997\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5905 - acc: 0.6769 - val_loss: 0.5731 - val_acc: 0.6997\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5849 - acc: 0.6776 - val_loss: 0.5726 - val_acc: 0.7143\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.5805 - acc: 0.7090 - val_loss: 0.5631 - val_acc: 0.7143\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5779 - acc: 0.7133 - val_loss: 0.5705 - val_acc: 0.7114\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5758 - acc: 0.7126 - val_loss: 0.5618 - val_acc: 0.7289\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5734 - acc: 0.7170 - val_loss: 0.5723 - val_acc: 0.7114\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5730 - acc: 0.7126 - val_loss: 0.5627 - val_acc: 0.7230\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5720 - acc: 0.7170 - val_loss: 0.5724 - val_acc: 0.7085\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5708 - acc: 0.7206 - val_loss: 0.5552 - val_acc: 0.7551\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5715 - acc: 0.7236 - val_loss: 0.5625 - val_acc: 0.7347\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.5869 - acc: 0.6929 - val_loss: 0.6239 - val_acc: 0.5831\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.6070 - acc: 0.6696 - val_loss: 0.5842 - val_acc: 0.7085\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5917 - acc: 0.6791 - val_loss: 0.5668 - val_acc: 0.6997\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5860 - acc: 0.6820 - val_loss: 0.5639 - val_acc: 0.7055\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5829 - acc: 0.7009 - val_loss: 0.5742 - val_acc: 0.6968\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5825 - acc: 0.7031 - val_loss: 0.5727 - val_acc: 0.6968\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5782 - acc: 0.7053 - val_loss: 0.5619 - val_acc: 0.7230\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5861 - acc: 0.6937 - val_loss: 0.5757 - val_acc: 0.7026\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5921 - acc: 0.6820 - val_loss: 0.5736 - val_acc: 0.7085\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5941 - acc: 0.6871 - val_loss: 0.5791 - val_acc: 0.6910\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5879 - acc: 0.6915 - val_loss: 0.5758 - val_acc: 0.6939\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5783 - acc: 0.6944 - val_loss: 0.5625 - val_acc: 0.7085\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5830 - acc: 0.7061 - val_loss: 0.5628 - val_acc: 0.7259\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5912 - acc: 0.6616 - val_loss: 0.6741 - val_acc: 0.4752\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6116 - acc: 0.6462 - val_loss: 0.5679 - val_acc: 0.7085\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5878 - acc: 0.6827 - val_loss: 0.5679 - val_acc: 0.7085\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5844 - acc: 0.6798 - val_loss: 0.5668 - val_acc: 0.7143\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5825 - acc: 0.6907 - val_loss: 0.5690 - val_acc: 0.6968\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5798 - acc: 0.6900 - val_loss: 0.5651 - val_acc: 0.6997\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5824 - acc: 0.6915 - val_loss: 0.5668 - val_acc: 0.7055\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5799 - acc: 0.7024 - val_loss: 0.5745 - val_acc: 0.7172\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5801 - acc: 0.7031 - val_loss: 0.5626 - val_acc: 0.7201\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5727 - acc: 0.7126 - val_loss: 0.5741 - val_acc: 0.6764\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5752 - acc: 0.7112 - val_loss: 0.5683 - val_acc: 0.7026\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5746 - acc: 0.7039 - val_loss: 0.5656 - val_acc: 0.7143\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5737 - acc: 0.7104 - val_loss: 0.5644 - val_acc: 0.7230\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5698 - acc: 0.7126 - val_loss: 0.5721 - val_acc: 0.6968\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5796 - acc: 0.7039 - val_loss: 0.5809 - val_acc: 0.6968\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6073 - acc: 0.6798 - val_loss: 0.5870 - val_acc: 0.6997\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5964 - acc: 0.6915 - val_loss: 0.5739 - val_acc: 0.6997\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5955 - acc: 0.6849 - val_loss: 0.5755 - val_acc: 0.7055\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5887 - acc: 0.6900 - val_loss: 0.5748 - val_acc: 0.6939\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5846 - acc: 0.6849 - val_loss: 0.5878 - val_acc: 0.6939\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5898 - acc: 0.6944 - val_loss: 0.5734 - val_acc: 0.6997\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5872 - acc: 0.6900 - val_loss: 0.5767 - val_acc: 0.6939\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5819 - acc: 0.6907 - val_loss: 0.5737 - val_acc: 0.6968\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5906 - acc: 0.6922 - val_loss: 0.5774 - val_acc: 0.6968\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5789 - acc: 0.6922 - val_loss: 0.5811 - val_acc: 0.6910\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5845 - acc: 0.6900 - val_loss: 0.5700 - val_acc: 0.6997\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5874 - acc: 0.6907 - val_loss: 0.5690 - val_acc: 0.6997\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.5819 - acc: 0.6937 - val_loss: 0.5785 - val_acc: 0.6968\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5826 - acc: 0.6907 - val_loss: 0.5871 - val_acc: 0.7026\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5825 - acc: 0.6951 - val_loss: 0.5651 - val_acc: 0.6997\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5808 - acc: 0.6995 - val_loss: 0.5776 - val_acc: 0.6997\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5803 - acc: 0.6922 - val_loss: 0.5812 - val_acc: 0.7055\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5777 - acc: 0.6944 - val_loss: 0.5750 - val_acc: 0.6997\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5815 - acc: 0.6929 - val_loss: 0.5823 - val_acc: 0.7026\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5787 - acc: 0.6988 - val_loss: 0.5749 - val_acc: 0.7055\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.5786 - acc: 0.6900 - val_loss: 0.5826 - val_acc: 0.6968\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5742 - acc: 0.6951 - val_loss: 0.5691 - val_acc: 0.6997\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5800 - acc: 0.6937 - val_loss: 0.5655 - val_acc: 0.7055\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5773 - acc: 0.6922 - val_loss: 0.5674 - val_acc: 0.7026\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5693 - acc: 0.6951 - val_loss: 0.5687 - val_acc: 0.7026\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5701 - acc: 0.7002 - val_loss: 0.5763 - val_acc: 0.7085\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5704 - acc: 0.6973 - val_loss: 0.5641 - val_acc: 0.7055\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5732 - acc: 0.6966 - val_loss: 0.5623 - val_acc: 0.7114\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5809 - acc: 0.6922 - val_loss: 0.5707 - val_acc: 0.7026\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5870 - acc: 0.6907 - val_loss: 0.5674 - val_acc: 0.6997\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5818 - acc: 0.6907 - val_loss: 0.5670 - val_acc: 0.7026\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5793 - acc: 0.6937 - val_loss: 0.5811 - val_acc: 0.6939\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5769 - acc: 0.6900 - val_loss: 0.5774 - val_acc: 0.6910\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5719 - acc: 0.6937 - val_loss: 0.5763 - val_acc: 0.7143\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5695 - acc: 0.6966 - val_loss: 0.5693 - val_acc: 0.7055\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5674 - acc: 0.7090 - val_loss: 0.5603 - val_acc: 0.7114\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5772 - acc: 0.6878 - val_loss: 0.5642 - val_acc: 0.7114\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5675 - acc: 0.7017 - val_loss: 0.5629 - val_acc: 0.7085\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5744 - acc: 0.7039 - val_loss: 0.5683 - val_acc: 0.7172\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5705 - acc: 0.6988 - val_loss: 0.5804 - val_acc: 0.7055\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5597 - acc: 0.7119 - val_loss: 0.5799 - val_acc: 0.7114\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5719 - acc: 0.6988 - val_loss: 0.5788 - val_acc: 0.6910\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5681 - acc: 0.7046 - val_loss: 0.5765 - val_acc: 0.7026\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5696 - acc: 0.7068 - val_loss: 0.5868 - val_acc: 0.7055\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5601 - acc: 0.7068 - val_loss: 0.5683 - val_acc: 0.7172\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5636 - acc: 0.7039 - val_loss: 0.5748 - val_acc: 0.7114\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5771 - acc: 0.6929 - val_loss: 0.5868 - val_acc: 0.7201\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5714 - acc: 0.6980 - val_loss: 0.5780 - val_acc: 0.7055\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5732 - acc: 0.6966 - val_loss: 0.5671 - val_acc: 0.7055\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5737 - acc: 0.7017 - val_loss: 0.5800 - val_acc: 0.7230\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5698 - acc: 0.7097 - val_loss: 0.5739 - val_acc: 0.7201\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5660 - acc: 0.7119 - val_loss: 0.5929 - val_acc: 0.7230\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.5660 - acc: 0.7236 - val_loss: 0.5712 - val_acc: 0.7143\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5780 - acc: 0.6937 - val_loss: 0.5701 - val_acc: 0.7026\n",
            "Epoch 182/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5809 - acc: 0.6907 - val_loss: 0.5614 - val_acc: 0.7026\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5679 - acc: 0.6995 - val_loss: 0.5663 - val_acc: 0.7055\n",
            "Epoch 184/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5729 - acc: 0.7024 - val_loss: 0.5688 - val_acc: 0.6997\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5675 - acc: 0.7126 - val_loss: 0.5637 - val_acc: 0.7201\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5619 - acc: 0.7192 - val_loss: 0.5501 - val_acc: 0.7085\n",
            "Epoch 187/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5870 - acc: 0.6995 - val_loss: 0.5619 - val_acc: 0.7085\n",
            "Epoch 188/1000\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.5750 - acc: 0.7061 - val_loss: 0.5603 - val_acc: 0.7143\n",
            "Epoch 189/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5716 - acc: 0.7119 - val_loss: 0.5822 - val_acc: 0.6735\n",
            "Epoch 190/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5664 - acc: 0.7133 - val_loss: 0.5698 - val_acc: 0.6997\n",
            "Epoch 191/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5621 - acc: 0.7148 - val_loss: 0.5669 - val_acc: 0.6997\n",
            "Epoch 192/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5521 - acc: 0.7236 - val_loss: 0.5661 - val_acc: 0.7201\n",
            "Epoch 193/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5604 - acc: 0.7119 - val_loss: 0.5684 - val_acc: 0.7143\n",
            "Epoch 194/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5561 - acc: 0.7199 - val_loss: 0.5678 - val_acc: 0.7143\n",
            "Epoch 195/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5667 - acc: 0.7002 - val_loss: 0.5720 - val_acc: 0.7114\n",
            "Epoch 196/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5703 - acc: 0.7133 - val_loss: 0.5609 - val_acc: 0.6968\n",
            "Epoch 197/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5685 - acc: 0.7082 - val_loss: 0.5808 - val_acc: 0.7026\n",
            "Epoch 198/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5631 - acc: 0.7199 - val_loss: 0.5770 - val_acc: 0.6997\n",
            "Epoch 199/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5646 - acc: 0.7265 - val_loss: 0.5621 - val_acc: 0.7085\n",
            "Epoch 200/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5556 - acc: 0.7155 - val_loss: 0.5635 - val_acc: 0.7114\n",
            "Epoch 201/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5562 - acc: 0.7170 - val_loss: 0.5843 - val_acc: 0.6880\n",
            "Epoch 202/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5608 - acc: 0.7214 - val_loss: 0.5751 - val_acc: 0.7026\n",
            "Epoch 203/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5559 - acc: 0.7250 - val_loss: 0.5718 - val_acc: 0.7055\n",
            "Epoch 204/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5489 - acc: 0.7206 - val_loss: 0.5676 - val_acc: 0.7114\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5548 - acc: 0.7192 - val_loss: 0.5777 - val_acc: 0.6968\n",
            "Epoch 206/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5695 - acc: 0.7090 - val_loss: 0.5755 - val_acc: 0.7055\n",
            "Epoch 207/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5598 - acc: 0.7119 - val_loss: 0.5794 - val_acc: 0.6851\n",
            "Epoch 208/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5671 - acc: 0.7024 - val_loss: 0.5878 - val_acc: 0.6764\n",
            "Epoch 209/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5605 - acc: 0.7221 - val_loss: 0.5694 - val_acc: 0.7085\n",
            "Epoch 210/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5576 - acc: 0.7206 - val_loss: 0.5896 - val_acc: 0.7026\n",
            "Epoch 211/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5573 - acc: 0.7155 - val_loss: 0.5866 - val_acc: 0.7085\n",
            "Epoch 212/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5637 - acc: 0.7228 - val_loss: 0.5853 - val_acc: 0.6939\n",
            "Epoch 213/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5499 - acc: 0.7323 - val_loss: 0.5804 - val_acc: 0.7114\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5491 - acc: 0.7199 - val_loss: 0.5924 - val_acc: 0.6968\n",
            "Epoch 215/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5442 - acc: 0.7309 - val_loss: 0.5712 - val_acc: 0.7201\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5649 - acc: 0.7177 - val_loss: 0.5777 - val_acc: 0.7114\n",
            "Epoch 217/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5438 - acc: 0.7250 - val_loss: 0.5892 - val_acc: 0.6997\n",
            "Epoch 218/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5539 - acc: 0.7236 - val_loss: 0.5722 - val_acc: 0.7289\n",
            "Epoch 219/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5491 - acc: 0.7163 - val_loss: 0.5648 - val_acc: 0.7114\n",
            "Epoch 220/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5412 - acc: 0.7250 - val_loss: 0.5594 - val_acc: 0.7114\n",
            "Epoch 221/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5351 - acc: 0.7352 - val_loss: 0.5761 - val_acc: 0.7085\n",
            "Epoch 222/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5312 - acc: 0.7411 - val_loss: 0.5722 - val_acc: 0.7201\n",
            "Epoch 223/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5361 - acc: 0.7367 - val_loss: 0.5728 - val_acc: 0.7201\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5499 - acc: 0.7301 - val_loss: 0.5613 - val_acc: 0.7230\n",
            "Epoch 225/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5476 - acc: 0.7367 - val_loss: 0.5730 - val_acc: 0.7172\n",
            "Epoch 226/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5409 - acc: 0.7462 - val_loss: 0.5611 - val_acc: 0.7376\n",
            "Epoch 227/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6271 - acc: 0.6681 - val_loss: 0.5773 - val_acc: 0.7055\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5881 - acc: 0.6907 - val_loss: 0.5734 - val_acc: 0.6997\n",
            "Epoch 229/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6281 - acc: 0.6637 - val_loss: 0.5930 - val_acc: 0.6706\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6017 - acc: 0.6659 - val_loss: 0.5693 - val_acc: 0.6997\n",
            "Epoch 231/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5966 - acc: 0.6710 - val_loss: 0.5760 - val_acc: 0.6997\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5805 - acc: 0.6922 - val_loss: 0.5639 - val_acc: 0.6647\n",
            "Epoch 233/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5739 - acc: 0.7031 - val_loss: 0.5757 - val_acc: 0.6676\n",
            "Epoch 234/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5734 - acc: 0.6944 - val_loss: 0.5767 - val_acc: 0.6793\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5739 - acc: 0.6915 - val_loss: 0.5778 - val_acc: 0.6968\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5715 - acc: 0.6980 - val_loss: 0.5804 - val_acc: 0.6676\n",
            "Epoch 237/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5801 - acc: 0.6937 - val_loss: 0.5775 - val_acc: 0.6851\n",
            "Epoch 238/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5784 - acc: 0.6929 - val_loss: 0.5813 - val_acc: 0.6647\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5722 - acc: 0.7061 - val_loss: 0.5727 - val_acc: 0.6939\n",
            "Epoch 240/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5740 - acc: 0.6922 - val_loss: 0.5844 - val_acc: 0.6764\n",
            "Epoch 241/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5785 - acc: 0.6958 - val_loss: 0.5748 - val_acc: 0.6939\n",
            "Epoch 242/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5811 - acc: 0.7031 - val_loss: 0.5765 - val_acc: 0.7026\n",
            "Epoch 243/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5748 - acc: 0.7068 - val_loss: 0.5770 - val_acc: 0.7055\n",
            "Epoch 244/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5719 - acc: 0.7090 - val_loss: 0.5727 - val_acc: 0.6910\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5815 - acc: 0.6907 - val_loss: 0.5749 - val_acc: 0.7085\n",
            "Epoch 246/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5771 - acc: 0.6937 - val_loss: 0.5700 - val_acc: 0.7055\n",
            "Epoch 247/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6399 - acc: 0.6010 - val_loss: 0.6117 - val_acc: 0.6997\n",
            "Epoch 248/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6229 - acc: 0.6776 - val_loss: 0.6051 - val_acc: 0.6997\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6259 - acc: 0.6776 - val_loss: 0.6073 - val_acc: 0.6997\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6235 - acc: 0.6776 - val_loss: 0.6097 - val_acc: 0.6997\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6253 - acc: 0.6776 - val_loss: 0.6042 - val_acc: 0.6997\n",
            "Epoch 252/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6216 - acc: 0.6769 - val_loss: 0.6019 - val_acc: 0.6997\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.6211 - acc: 0.6769 - val_loss: 0.6008 - val_acc: 0.6997\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6153 - acc: 0.6776 - val_loss: 0.5980 - val_acc: 0.6997\n",
            "Epoch 255/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6137 - acc: 0.6776 - val_loss: 0.5982 - val_acc: 0.6997\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6153 - acc: 0.6783 - val_loss: 0.5964 - val_acc: 0.6997\n",
            "Epoch 257/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6092 - acc: 0.6776 - val_loss: 0.5956 - val_acc: 0.6997\n",
            "Epoch 258/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6009 - acc: 0.6776 - val_loss: 0.5753 - val_acc: 0.6997\n",
            "Epoch 259/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5911 - acc: 0.6776 - val_loss: 0.5876 - val_acc: 0.6997\n",
            "Epoch 260/1000\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.5924 - acc: 0.6776 - val_loss: 0.5726 - val_acc: 0.6997\n",
            "Epoch 261/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6126 - acc: 0.6754 - val_loss: 0.5758 - val_acc: 0.6997\n",
            "Epoch 262/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5853 - acc: 0.6769 - val_loss: 0.5677 - val_acc: 0.6997\n",
            "Epoch 263/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6162 - acc: 0.6710 - val_loss: 0.6199 - val_acc: 0.6997\n",
            "Epoch 264/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6037 - acc: 0.6776 - val_loss: 0.5867 - val_acc: 0.6997\n",
            "Epoch 265/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6099 - acc: 0.6769 - val_loss: 0.5798 - val_acc: 0.6997\n",
            "Epoch 266/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6090 - acc: 0.6769 - val_loss: 0.5921 - val_acc: 0.6997\n",
            "Epoch 267/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5993 - acc: 0.6769 - val_loss: 0.5761 - val_acc: 0.6997\n",
            "Epoch 268/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.5981 - acc: 0.6761 - val_loss: 0.5856 - val_acc: 0.6997\n",
            "Epoch 269/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6023 - acc: 0.6761 - val_loss: 0.5805 - val_acc: 0.6997\n",
            "Epoch 270/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5909 - acc: 0.6776 - val_loss: 0.5747 - val_acc: 0.6997\n",
            "Epoch 271/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5881 - acc: 0.6776 - val_loss: 0.5674 - val_acc: 0.6997\n",
            "Epoch 272/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5851 - acc: 0.6827 - val_loss: 0.5720 - val_acc: 0.6997\n",
            "Epoch 273/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5757 - acc: 0.6820 - val_loss: 0.5630 - val_acc: 0.7055\n",
            "Epoch 274/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5768 - acc: 0.6900 - val_loss: 0.5615 - val_acc: 0.7085\n",
            "Epoch 275/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5689 - acc: 0.6988 - val_loss: 0.5599 - val_acc: 0.7143\n",
            "Epoch 276/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5782 - acc: 0.7009 - val_loss: 0.5519 - val_acc: 0.7201\n",
            "Epoch 277/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5819 - acc: 0.6929 - val_loss: 0.5610 - val_acc: 0.7026\n",
            "Epoch 278/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5756 - acc: 0.7046 - val_loss: 0.5542 - val_acc: 0.7172\n",
            "Epoch 279/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5771 - acc: 0.6951 - val_loss: 0.5586 - val_acc: 0.7143\n",
            "Epoch 280/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5704 - acc: 0.7075 - val_loss: 0.5631 - val_acc: 0.6997\n",
            "Epoch 281/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5684 - acc: 0.7031 - val_loss: 0.5641 - val_acc: 0.7055\n",
            "Epoch 282/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5713 - acc: 0.6951 - val_loss: 0.5484 - val_acc: 0.7143\n",
            "Epoch 283/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5721 - acc: 0.7031 - val_loss: 0.5555 - val_acc: 0.7230\n",
            "Epoch 284/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5844 - acc: 0.6951 - val_loss: 0.5656 - val_acc: 0.7114\n",
            "Epoch 285/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5928 - acc: 0.6798 - val_loss: 0.5776 - val_acc: 0.7026\n",
            "Epoch 286/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6021 - acc: 0.6681 - val_loss: 0.5605 - val_acc: 0.6997\n",
            "Epoch 287/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5891 - acc: 0.6776 - val_loss: 0.5752 - val_acc: 0.6997\n",
            "Epoch 288/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5862 - acc: 0.6783 - val_loss: 0.5694 - val_acc: 0.7026\n",
            "Epoch 289/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5812 - acc: 0.6798 - val_loss: 0.5580 - val_acc: 0.7026\n",
            "Epoch 290/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5802 - acc: 0.6776 - val_loss: 0.5681 - val_acc: 0.6939\n",
            "Epoch 291/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5795 - acc: 0.6878 - val_loss: 0.5584 - val_acc: 0.6939\n",
            "Epoch 292/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5799 - acc: 0.6820 - val_loss: 0.5629 - val_acc: 0.6822\n",
            "Epoch 293/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5938 - acc: 0.6470 - val_loss: 0.5830 - val_acc: 0.7026\n",
            "Epoch 294/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5829 - acc: 0.6725 - val_loss: 0.5839 - val_acc: 0.7026\n",
            "Epoch 295/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5922 - acc: 0.6703 - val_loss: 0.5819 - val_acc: 0.7055\n",
            "Epoch 296/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5836 - acc: 0.6827 - val_loss: 0.5845 - val_acc: 0.7026\n",
            "Epoch 297/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5801 - acc: 0.6805 - val_loss: 0.5833 - val_acc: 0.6968\n",
            "Epoch 298/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5806 - acc: 0.6791 - val_loss: 0.5795 - val_acc: 0.7026\n",
            "Epoch 299/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5809 - acc: 0.6856 - val_loss: 0.5748 - val_acc: 0.7114\n",
            "Epoch 300/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5858 - acc: 0.6842 - val_loss: 0.5783 - val_acc: 0.7055\n",
            "Epoch 301/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6056 - acc: 0.6696 - val_loss: 0.5889 - val_acc: 0.7055\n",
            "Epoch 302/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5965 - acc: 0.6761 - val_loss: 0.5795 - val_acc: 0.6968\n",
            "Epoch 303/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5932 - acc: 0.6776 - val_loss: 0.5804 - val_acc: 0.7026\n",
            "Epoch 304/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5926 - acc: 0.6805 - val_loss: 0.5820 - val_acc: 0.6939\n",
            "Epoch 305/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5843 - acc: 0.6769 - val_loss: 0.5758 - val_acc: 0.7085\n",
            "Epoch 306/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5803 - acc: 0.6834 - val_loss: 0.5712 - val_acc: 0.7055\n",
            "Epoch 307/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5835 - acc: 0.6885 - val_loss: 0.5670 - val_acc: 0.7230\n",
            "Epoch 308/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5817 - acc: 0.6900 - val_loss: 0.5685 - val_acc: 0.7114\n",
            "Epoch 309/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5753 - acc: 0.6973 - val_loss: 0.5666 - val_acc: 0.7172\n",
            "Epoch 310/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5756 - acc: 0.6922 - val_loss: 0.5681 - val_acc: 0.7143\n",
            "Epoch 311/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5725 - acc: 0.6937 - val_loss: 0.5692 - val_acc: 0.7172\n",
            "Epoch 312/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5738 - acc: 0.6893 - val_loss: 0.5761 - val_acc: 0.6939\n",
            "Epoch 313/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5759 - acc: 0.7009 - val_loss: 0.5679 - val_acc: 0.7114\n",
            "Epoch 314/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5695 - acc: 0.6995 - val_loss: 0.5739 - val_acc: 0.7026\n",
            "Epoch 315/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5730 - acc: 0.7002 - val_loss: 0.5672 - val_acc: 0.7172\n",
            "Epoch 316/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5674 - acc: 0.7061 - val_loss: 0.5679 - val_acc: 0.7172\n",
            "Epoch 317/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5640 - acc: 0.7119 - val_loss: 0.5775 - val_acc: 0.7085\n",
            "Epoch 318/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5705 - acc: 0.7009 - val_loss: 0.5707 - val_acc: 0.7055\n",
            "Epoch 319/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5654 - acc: 0.7097 - val_loss: 0.5678 - val_acc: 0.7055\n",
            "Epoch 320/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5665 - acc: 0.7082 - val_loss: 0.5786 - val_acc: 0.6968\n",
            "Epoch 321/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5667 - acc: 0.7061 - val_loss: 0.5751 - val_acc: 0.6910\n",
            "Epoch 322/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5637 - acc: 0.7009 - val_loss: 0.5713 - val_acc: 0.6910\n",
            "Epoch 323/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5699 - acc: 0.7009 - val_loss: 0.5631 - val_acc: 0.7055\n",
            "Epoch 324/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5715 - acc: 0.6973 - val_loss: 0.5744 - val_acc: 0.6997\n",
            "Epoch 325/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5767 - acc: 0.6834 - val_loss: 0.5754 - val_acc: 0.6910\n",
            "Epoch 326/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5703 - acc: 0.6929 - val_loss: 0.5738 - val_acc: 0.7026\n",
            "Epoch 327/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5677 - acc: 0.6922 - val_loss: 0.5668 - val_acc: 0.7055\n",
            "Epoch 328/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5665 - acc: 0.6951 - val_loss: 0.5704 - val_acc: 0.7026\n",
            "Epoch 329/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5621 - acc: 0.7090 - val_loss: 0.5572 - val_acc: 0.7055\n",
            "Epoch 330/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5612 - acc: 0.6980 - val_loss: 0.5606 - val_acc: 0.7026\n",
            "Epoch 331/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5588 - acc: 0.7082 - val_loss: 0.5615 - val_acc: 0.7085\n",
            "Epoch 332/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5565 - acc: 0.7082 - val_loss: 0.5621 - val_acc: 0.6997\n",
            "Epoch 333/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.5566 - acc: 0.7039 - val_loss: 0.5640 - val_acc: 0.7114\n",
            "Epoch 334/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5555 - acc: 0.6944 - val_loss: 0.5630 - val_acc: 0.7026\n",
            "Epoch 335/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5708 - acc: 0.7097 - val_loss: 0.6228 - val_acc: 0.6356\n",
            "Epoch 336/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6273 - acc: 0.6492 - val_loss: 0.6071 - val_acc: 0.6997\n",
            "Epoch 337/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6247 - acc: 0.6761 - val_loss: 0.5925 - val_acc: 0.6997\n",
            "Epoch 338/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6271 - acc: 0.6761 - val_loss: 0.6127 - val_acc: 0.6997\n",
            "Epoch 339/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6325 - acc: 0.6761 - val_loss: 0.6016 - val_acc: 0.6997\n",
            "Epoch 340/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6277 - acc: 0.6761 - val_loss: 0.5913 - val_acc: 0.6997\n",
            "Epoch 341/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6212 - acc: 0.6761 - val_loss: 0.5960 - val_acc: 0.6997\n",
            "Epoch 342/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6382 - acc: 0.6761 - val_loss: 0.6141 - val_acc: 0.6997\n",
            "Epoch 343/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6246 - acc: 0.6761 - val_loss: 0.6011 - val_acc: 0.6997\n",
            "Epoch 344/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6217 - acc: 0.6761 - val_loss: 0.5982 - val_acc: 0.6997\n",
            "Epoch 345/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6191 - acc: 0.6761 - val_loss: 0.5930 - val_acc: 0.6997\n",
            "Epoch 346/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6223 - acc: 0.6761 - val_loss: 0.5875 - val_acc: 0.6997\n",
            "Epoch 347/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6133 - acc: 0.6761 - val_loss: 0.5944 - val_acc: 0.6997\n",
            "Epoch 348/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6094 - acc: 0.6761 - val_loss: 0.6000 - val_acc: 0.6997\n",
            "Epoch 349/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6118 - acc: 0.6761 - val_loss: 0.5951 - val_acc: 0.6997\n",
            "Epoch 350/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6171 - acc: 0.6761 - val_loss: 0.6009 - val_acc: 0.6997\n",
            "Epoch 351/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6112 - acc: 0.6761 - val_loss: 0.5892 - val_acc: 0.6997\n",
            "Epoch 352/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6120 - acc: 0.6761 - val_loss: 0.6028 - val_acc: 0.6997\n",
            "Epoch 353/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6186 - acc: 0.6761 - val_loss: 0.5840 - val_acc: 0.6997\n",
            "Epoch 354/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6107 - acc: 0.6761 - val_loss: 0.5889 - val_acc: 0.6997\n",
            "Epoch 355/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6098 - acc: 0.6761 - val_loss: 0.5832 - val_acc: 0.6997\n",
            "Epoch 356/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6020 - acc: 0.6761 - val_loss: 0.5749 - val_acc: 0.6997\n",
            "Epoch 357/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6070 - acc: 0.6761 - val_loss: 0.5789 - val_acc: 0.6997\n",
            "Epoch 358/1000\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.6086 - acc: 0.6761 - val_loss: 0.5861 - val_acc: 0.6997\n",
            "Epoch 359/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6036 - acc: 0.6761 - val_loss: 0.5724 - val_acc: 0.6997\n",
            "Epoch 360/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6042 - acc: 0.6761 - val_loss: 0.5736 - val_acc: 0.6997\n",
            "Epoch 361/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6055 - acc: 0.6761 - val_loss: 0.5823 - val_acc: 0.6997\n",
            "Epoch 362/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6039 - acc: 0.6761 - val_loss: 0.5746 - val_acc: 0.6997\n",
            "Epoch 363/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6097 - acc: 0.6761 - val_loss: 0.5758 - val_acc: 0.6997\n",
            "Epoch 364/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6057 - acc: 0.6761 - val_loss: 0.5768 - val_acc: 0.6997\n",
            "Epoch 365/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5973 - acc: 0.6761 - val_loss: 0.5731 - val_acc: 0.6997\n",
            "Epoch 366/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6070 - acc: 0.6761 - val_loss: 0.5782 - val_acc: 0.6997\n",
            "Epoch 367/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6069 - acc: 0.6761 - val_loss: 0.5795 - val_acc: 0.6997\n",
            "Epoch 368/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6092 - acc: 0.6761 - val_loss: 0.6142 - val_acc: 0.6997\n",
            "Epoch 369/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6105 - acc: 0.6761 - val_loss: 0.5729 - val_acc: 0.6997\n",
            "Epoch 370/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6213 - acc: 0.6761 - val_loss: 0.6012 - val_acc: 0.6997\n",
            "Epoch 371/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6102 - acc: 0.6761 - val_loss: 0.5828 - val_acc: 0.6997\n",
            "Epoch 372/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6052 - acc: 0.6761 - val_loss: 0.5750 - val_acc: 0.6997\n",
            "Epoch 373/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6014 - acc: 0.6761 - val_loss: 0.5724 - val_acc: 0.6997\n",
            "Epoch 374/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6032 - acc: 0.6761 - val_loss: 0.5733 - val_acc: 0.6997\n",
            "Epoch 375/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6067 - acc: 0.6761 - val_loss: 0.5753 - val_acc: 0.6997\n",
            "Epoch 376/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6025 - acc: 0.6761 - val_loss: 0.5705 - val_acc: 0.6997\n",
            "Epoch 377/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6015 - acc: 0.6761 - val_loss: 0.5854 - val_acc: 0.6997\n",
            "Epoch 378/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6047 - acc: 0.6761 - val_loss: 0.5759 - val_acc: 0.6997\n",
            "Epoch 379/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6058 - acc: 0.6761 - val_loss: 0.5884 - val_acc: 0.6997\n",
            "Epoch 380/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6009 - acc: 0.6761 - val_loss: 0.5707 - val_acc: 0.6997\n",
            "Epoch 381/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6024 - acc: 0.6761 - val_loss: 0.5731 - val_acc: 0.6997\n",
            "Epoch 382/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5985 - acc: 0.6761 - val_loss: 0.5713 - val_acc: 0.6997\n",
            "Epoch 382: early stopping\n",
            "27/27 [==============================] - 2s 35ms/step - loss: 0.5963 - acc: 0.6811\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 7s 119ms/step - loss: 0.6544 - acc: 0.6297 - val_loss: 0.6332 - val_acc: 0.6589\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6309 - acc: 0.6589 - val_loss: 0.6176 - val_acc: 0.6589\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6101 - acc: 0.6501 - val_loss: 0.6114 - val_acc: 0.6618\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6148 - acc: 0.6574 - val_loss: 0.6089 - val_acc: 0.6618\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6126 - acc: 0.6567 - val_loss: 0.6080 - val_acc: 0.6560\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6062 - acc: 0.6465 - val_loss: 0.6044 - val_acc: 0.6676\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6055 - acc: 0.6603 - val_loss: 0.6051 - val_acc: 0.6647\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6122 - acc: 0.6581 - val_loss: 0.6105 - val_acc: 0.6589\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6114 - acc: 0.6625 - val_loss: 0.6148 - val_acc: 0.6647\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6046 - acc: 0.6494 - val_loss: 0.6099 - val_acc: 0.6706\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6093 - acc: 0.6567 - val_loss: 0.6106 - val_acc: 0.6706\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6044 - acc: 0.6538 - val_loss: 0.6093 - val_acc: 0.6676\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6014 - acc: 0.6560 - val_loss: 0.6092 - val_acc: 0.6706\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6033 - acc: 0.6538 - val_loss: 0.6139 - val_acc: 0.6501\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6018 - acc: 0.6698 - val_loss: 0.6034 - val_acc: 0.6676\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6000 - acc: 0.6684 - val_loss: 0.6096 - val_acc: 0.6764\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5995 - acc: 0.6633 - val_loss: 0.6158 - val_acc: 0.6297\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6041 - acc: 0.6676 - val_loss: 0.6048 - val_acc: 0.6676\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6029 - acc: 0.6647 - val_loss: 0.6041 - val_acc: 0.6706\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6004 - acc: 0.6581 - val_loss: 0.6051 - val_acc: 0.6764\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5985 - acc: 0.6720 - val_loss: 0.6027 - val_acc: 0.6822\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6069 - acc: 0.6603 - val_loss: 0.6045 - val_acc: 0.6735\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5975 - acc: 0.6625 - val_loss: 0.6046 - val_acc: 0.6647\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5961 - acc: 0.6713 - val_loss: 0.6038 - val_acc: 0.6706\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5989 - acc: 0.6764 - val_loss: 0.6053 - val_acc: 0.6706\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5975 - acc: 0.6676 - val_loss: 0.6058 - val_acc: 0.6618\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5998 - acc: 0.6713 - val_loss: 0.6039 - val_acc: 0.6880\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6003 - acc: 0.6662 - val_loss: 0.6059 - val_acc: 0.6822\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6015 - acc: 0.6749 - val_loss: 0.6038 - val_acc: 0.6851\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6045 - acc: 0.6538 - val_loss: 0.6039 - val_acc: 0.6676\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6029 - acc: 0.6669 - val_loss: 0.6059 - val_acc: 0.6676\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5967 - acc: 0.6771 - val_loss: 0.6095 - val_acc: 0.6647\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5950 - acc: 0.6691 - val_loss: 0.6088 - val_acc: 0.6618\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5900 - acc: 0.6837 - val_loss: 0.6054 - val_acc: 0.6560\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5949 - acc: 0.6757 - val_loss: 0.6029 - val_acc: 0.6793\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5932 - acc: 0.6801 - val_loss: 0.6043 - val_acc: 0.6676\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5984 - acc: 0.6662 - val_loss: 0.6058 - val_acc: 0.6822\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5936 - acc: 0.6742 - val_loss: 0.6077 - val_acc: 0.6618\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5926 - acc: 0.6749 - val_loss: 0.6101 - val_acc: 0.6618\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5947 - acc: 0.6771 - val_loss: 0.6098 - val_acc: 0.6472\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5918 - acc: 0.6662 - val_loss: 0.6293 - val_acc: 0.6122\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5917 - acc: 0.6669 - val_loss: 0.6067 - val_acc: 0.6851\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5890 - acc: 0.6764 - val_loss: 0.6092 - val_acc: 0.6647\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5961 - acc: 0.6793 - val_loss: 0.6083 - val_acc: 0.6647\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5879 - acc: 0.6808 - val_loss: 0.6137 - val_acc: 0.6472\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5932 - acc: 0.6676 - val_loss: 0.6124 - val_acc: 0.6443\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5870 - acc: 0.6837 - val_loss: 0.6184 - val_acc: 0.6735\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5968 - acc: 0.6771 - val_loss: 0.6081 - val_acc: 0.6764\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5952 - acc: 0.6764 - val_loss: 0.6096 - val_acc: 0.6647\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5886 - acc: 0.6801 - val_loss: 0.6121 - val_acc: 0.6735\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5841 - acc: 0.6808 - val_loss: 0.6196 - val_acc: 0.6414\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5929 - acc: 0.6764 - val_loss: 0.6088 - val_acc: 0.6735\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5920 - acc: 0.6786 - val_loss: 0.6166 - val_acc: 0.6443\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5905 - acc: 0.6742 - val_loss: 0.6209 - val_acc: 0.6327\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5895 - acc: 0.6757 - val_loss: 0.6177 - val_acc: 0.6501\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5973 - acc: 0.6698 - val_loss: 0.6122 - val_acc: 0.6589\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5875 - acc: 0.6822 - val_loss: 0.6165 - val_acc: 0.6647\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5922 - acc: 0.6749 - val_loss: 0.6092 - val_acc: 0.6822\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5868 - acc: 0.6706 - val_loss: 0.6098 - val_acc: 0.6851\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5894 - acc: 0.6698 - val_loss: 0.6202 - val_acc: 0.6414\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5850 - acc: 0.6771 - val_loss: 0.6119 - val_acc: 0.6618\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5799 - acc: 0.6844 - val_loss: 0.6128 - val_acc: 0.6531\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5901 - acc: 0.6801 - val_loss: 0.6086 - val_acc: 0.6793\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5911 - acc: 0.6698 - val_loss: 0.6077 - val_acc: 0.6939\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5884 - acc: 0.6888 - val_loss: 0.6276 - val_acc: 0.6239\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5884 - acc: 0.6757 - val_loss: 0.6068 - val_acc: 0.6880\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5893 - acc: 0.6735 - val_loss: 0.6095 - val_acc: 0.6560\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5852 - acc: 0.6837 - val_loss: 0.6139 - val_acc: 0.6676\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5898 - acc: 0.6771 - val_loss: 0.6086 - val_acc: 0.6822\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5865 - acc: 0.6801 - val_loss: 0.6136 - val_acc: 0.6676\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.5860 - acc: 0.6771 - val_loss: 0.6185 - val_acc: 0.6589\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5848 - acc: 0.6822 - val_loss: 0.6301 - val_acc: 0.6443\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5839 - acc: 0.6859 - val_loss: 0.6267 - val_acc: 0.6676\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5919 - acc: 0.6779 - val_loss: 0.6353 - val_acc: 0.6268\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5850 - acc: 0.6793 - val_loss: 0.6366 - val_acc: 0.6181\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5981 - acc: 0.6749 - val_loss: 0.6124 - val_acc: 0.6589\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5909 - acc: 0.6749 - val_loss: 0.6074 - val_acc: 0.6706\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5907 - acc: 0.6764 - val_loss: 0.6099 - val_acc: 0.6647\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5837 - acc: 0.6793 - val_loss: 0.6229 - val_acc: 0.6268\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5889 - acc: 0.6830 - val_loss: 0.6118 - val_acc: 0.6764\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5866 - acc: 0.6910 - val_loss: 0.6236 - val_acc: 0.6181\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5808 - acc: 0.6925 - val_loss: 0.6273 - val_acc: 0.6356\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5807 - acc: 0.6735 - val_loss: 0.6147 - val_acc: 0.6589\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5841 - acc: 0.6822 - val_loss: 0.6167 - val_acc: 0.6589\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5932 - acc: 0.6822 - val_loss: 0.6184 - val_acc: 0.6676\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5895 - acc: 0.6749 - val_loss: 0.6149 - val_acc: 0.6647\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5985 - acc: 0.6698 - val_loss: 0.6112 - val_acc: 0.6589\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5920 - acc: 0.6771 - val_loss: 0.6125 - val_acc: 0.6560\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5877 - acc: 0.6866 - val_loss: 0.6076 - val_acc: 0.6618\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5929 - acc: 0.6749 - val_loss: 0.6132 - val_acc: 0.6589\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5888 - acc: 0.6764 - val_loss: 0.6129 - val_acc: 0.6560\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5862 - acc: 0.6903 - val_loss: 0.6132 - val_acc: 0.6589\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5851 - acc: 0.6852 - val_loss: 0.6173 - val_acc: 0.6706\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5901 - acc: 0.6742 - val_loss: 0.6175 - val_acc: 0.6647\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5862 - acc: 0.6903 - val_loss: 0.6170 - val_acc: 0.6706\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5830 - acc: 0.6910 - val_loss: 0.6143 - val_acc: 0.6851\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5803 - acc: 0.6786 - val_loss: 0.6238 - val_acc: 0.6647\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5773 - acc: 0.6822 - val_loss: 0.6311 - val_acc: 0.6560\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5902 - acc: 0.6625 - val_loss: 0.6176 - val_acc: 0.6618\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.5854 - acc: 0.6830 - val_loss: 0.6271 - val_acc: 0.6443\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5838 - acc: 0.6888 - val_loss: 0.6191 - val_acc: 0.6589\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5847 - acc: 0.6859 - val_loss: 0.6175 - val_acc: 0.6676\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5792 - acc: 0.6801 - val_loss: 0.6267 - val_acc: 0.6647\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.5757 - acc: 0.6896 - val_loss: 0.6301 - val_acc: 0.6531\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5703 - acc: 0.6947 - val_loss: 0.6311 - val_acc: 0.6414\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5826 - acc: 0.6786 - val_loss: 0.6262 - val_acc: 0.6501\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5831 - acc: 0.6801 - val_loss: 0.6231 - val_acc: 0.6501\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5729 - acc: 0.6903 - val_loss: 0.6219 - val_acc: 0.6531\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5758 - acc: 0.6837 - val_loss: 0.6186 - val_acc: 0.6647\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5848 - acc: 0.6793 - val_loss: 0.6146 - val_acc: 0.6676\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5794 - acc: 0.6822 - val_loss: 0.6216 - val_acc: 0.6618\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5711 - acc: 0.6917 - val_loss: 0.6209 - val_acc: 0.6676\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5694 - acc: 0.6881 - val_loss: 0.6244 - val_acc: 0.6735\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5759 - acc: 0.6837 - val_loss: 0.6258 - val_acc: 0.6764\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5809 - acc: 0.6896 - val_loss: 0.6234 - val_acc: 0.6472\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5769 - acc: 0.6822 - val_loss: 0.6267 - val_acc: 0.6647\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5780 - acc: 0.6808 - val_loss: 0.6206 - val_acc: 0.6735\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5806 - acc: 0.6786 - val_loss: 0.6282 - val_acc: 0.6385\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 114ms/step - loss: 0.5835 - acc: 0.6844 - val_loss: 0.6126 - val_acc: 0.6968\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5794 - acc: 0.6852 - val_loss: 0.6172 - val_acc: 0.6735\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5741 - acc: 0.6932 - val_loss: 0.6285 - val_acc: 0.6472\n",
            "Epoch 121: early stopping\n",
            "27/27 [==============================] - 2s 36ms/step - loss: 0.5902 - acc: 0.6911\n",
            "batch : 64, unit: [64, 32], dropout: 0.4, avg_accuracy: 0.6891034642855326, activation: sigmoid\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 7s 120ms/step - loss: 0.6554 - acc: 0.5106 - val_loss: 0.6198 - val_acc: 0.7026\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6345 - acc: 0.5565 - val_loss: 0.6117 - val_acc: 0.6356\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6234 - acc: 0.5806 - val_loss: 0.6253 - val_acc: 0.4344\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6302 - acc: 0.5602 - val_loss: 0.6089 - val_acc: 0.5539\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6205 - acc: 0.5711 - val_loss: 0.6060 - val_acc: 0.5802\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6213 - acc: 0.5573 - val_loss: 0.6100 - val_acc: 0.5131\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.6136 - acc: 0.5711 - val_loss: 0.5989 - val_acc: 0.5977\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6106 - acc: 0.5908 - val_loss: 0.5978 - val_acc: 0.5918\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6155 - acc: 0.5594 - val_loss: 0.6109 - val_acc: 0.4985\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6113 - acc: 0.5697 - val_loss: 0.6160 - val_acc: 0.4577\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6134 - acc: 0.5894 - val_loss: 0.6032 - val_acc: 0.5423\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6095 - acc: 0.5755 - val_loss: 0.5936 - val_acc: 0.5948\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6111 - acc: 0.5908 - val_loss: 0.5926 - val_acc: 0.5918\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6110 - acc: 0.5704 - val_loss: 0.5966 - val_acc: 0.5773\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6082 - acc: 0.5872 - val_loss: 0.5908 - val_acc: 0.6647\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6103 - acc: 0.5711 - val_loss: 0.5951 - val_acc: 0.6618\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6105 - acc: 0.5828 - val_loss: 0.5936 - val_acc: 0.6472\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6076 - acc: 0.5959 - val_loss: 0.5900 - val_acc: 0.5860\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6038 - acc: 0.6112 - val_loss: 0.6007 - val_acc: 0.5510\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6080 - acc: 0.5886 - val_loss: 0.6043 - val_acc: 0.5277\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6032 - acc: 0.5974 - val_loss: 0.5981 - val_acc: 0.5802\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6064 - acc: 0.5879 - val_loss: 0.5872 - val_acc: 0.6268\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6050 - acc: 0.5930 - val_loss: 0.5995 - val_acc: 0.5510\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6053 - acc: 0.5821 - val_loss: 0.5952 - val_acc: 0.5802\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6038 - acc: 0.6090 - val_loss: 0.6013 - val_acc: 0.5452\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6079 - acc: 0.5901 - val_loss: 0.5975 - val_acc: 0.5714\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6043 - acc: 0.5937 - val_loss: 0.5865 - val_acc: 0.6239\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6055 - acc: 0.6069 - val_loss: 0.5844 - val_acc: 0.6152\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6056 - acc: 0.6069 - val_loss: 0.5849 - val_acc: 0.6152\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6059 - acc: 0.5923 - val_loss: 0.5863 - val_acc: 0.5977\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6031 - acc: 0.6083 - val_loss: 0.5901 - val_acc: 0.5831\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6079 - acc: 0.5784 - val_loss: 0.5967 - val_acc: 0.5685\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6068 - acc: 0.5988 - val_loss: 0.5910 - val_acc: 0.5714\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6022 - acc: 0.6047 - val_loss: 0.6031 - val_acc: 0.5306\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6016 - acc: 0.6098 - val_loss: 0.6052 - val_acc: 0.5102\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6059 - acc: 0.5872 - val_loss: 0.5877 - val_acc: 0.5918\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6024 - acc: 0.6054 - val_loss: 0.5858 - val_acc: 0.5860\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6042 - acc: 0.5915 - val_loss: 0.5847 - val_acc: 0.6472\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5998 - acc: 0.5828 - val_loss: 0.5862 - val_acc: 0.5831\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6036 - acc: 0.5959 - val_loss: 0.5948 - val_acc: 0.5685\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6048 - acc: 0.6032 - val_loss: 0.5839 - val_acc: 0.6006\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6024 - acc: 0.5996 - val_loss: 0.5827 - val_acc: 0.6414\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5983 - acc: 0.5966 - val_loss: 0.5879 - val_acc: 0.5802\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6014 - acc: 0.5923 - val_loss: 0.5905 - val_acc: 0.6064\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5998 - acc: 0.6163 - val_loss: 0.5811 - val_acc: 0.6618\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5997 - acc: 0.5945 - val_loss: 0.5808 - val_acc: 0.6297\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5987 - acc: 0.6105 - val_loss: 0.5799 - val_acc: 0.5860\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6017 - acc: 0.5748 - val_loss: 0.5830 - val_acc: 0.6618\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6015 - acc: 0.5988 - val_loss: 0.5757 - val_acc: 0.6501\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6039 - acc: 0.5886 - val_loss: 0.5783 - val_acc: 0.6472\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5936 - acc: 0.6404 - val_loss: 0.5871 - val_acc: 0.7376\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6065 - acc: 0.6105 - val_loss: 0.5847 - val_acc: 0.6327\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6062 - acc: 0.5937 - val_loss: 0.5907 - val_acc: 0.5656\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5985 - acc: 0.5908 - val_loss: 0.5850 - val_acc: 0.5714\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5975 - acc: 0.5915 - val_loss: 0.5844 - val_acc: 0.6297\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5951 - acc: 0.6112 - val_loss: 0.5849 - val_acc: 0.5627\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5944 - acc: 0.6090 - val_loss: 0.5812 - val_acc: 0.6122\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.5950 - acc: 0.5988 - val_loss: 0.5858 - val_acc: 0.5656\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5955 - acc: 0.5689 - val_loss: 0.5833 - val_acc: 0.5743\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5940 - acc: 0.5930 - val_loss: 0.5952 - val_acc: 0.5073\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5991 - acc: 0.5886 - val_loss: 0.5796 - val_acc: 0.6152\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5952 - acc: 0.5966 - val_loss: 0.5825 - val_acc: 0.6443\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.5976 - acc: 0.5996 - val_loss: 0.5921 - val_acc: 0.5656\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.5964 - acc: 0.6098 - val_loss: 0.5797 - val_acc: 0.5860\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5921 - acc: 0.6251 - val_loss: 0.5790 - val_acc: 0.6239\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6193 - acc: 0.5718 - val_loss: 0.6503 - val_acc: 0.6443\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6401 - acc: 0.5886 - val_loss: 0.6228 - val_acc: 0.4636\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6407 - acc: 0.5806 - val_loss: 0.6286 - val_acc: 0.3120\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6405 - acc: 0.4522 - val_loss: 0.6205 - val_acc: 0.6560\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.6335 - acc: 0.6280 - val_loss: 0.6148 - val_acc: 0.6093\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.6247 - acc: 0.5850 - val_loss: 0.6006 - val_acc: 0.5948\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.6130 - acc: 0.5762 - val_loss: 0.5904 - val_acc: 0.5889\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6135 - acc: 0.5740 - val_loss: 0.5947 - val_acc: 0.6443\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6163 - acc: 0.5748 - val_loss: 0.5928 - val_acc: 0.5889\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6171 - acc: 0.5777 - val_loss: 0.5962 - val_acc: 0.6239\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6085 - acc: 0.6003 - val_loss: 0.5872 - val_acc: 0.6152\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6077 - acc: 0.5981 - val_loss: 0.5853 - val_acc: 0.6152\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6087 - acc: 0.6083 - val_loss: 0.6053 - val_acc: 0.5160\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6137 - acc: 0.5959 - val_loss: 0.6030 - val_acc: 0.5510\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6045 - acc: 0.6193 - val_loss: 0.5883 - val_acc: 0.5860\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6004 - acc: 0.5901 - val_loss: 0.5723 - val_acc: 0.6793\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6037 - acc: 0.6018 - val_loss: 0.5830 - val_acc: 0.6880\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5956 - acc: 0.6389 - val_loss: 0.6310 - val_acc: 0.4257\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6150 - acc: 0.5230 - val_loss: 0.5993 - val_acc: 0.6327\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6064 - acc: 0.5857 - val_loss: 0.5797 - val_acc: 0.6327\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6020 - acc: 0.5886 - val_loss: 0.5850 - val_acc: 0.7026\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5967 - acc: 0.6353 - val_loss: 0.5784 - val_acc: 0.6443\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5923 - acc: 0.6317 - val_loss: 0.5762 - val_acc: 0.6297\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5988 - acc: 0.6484 - val_loss: 0.5791 - val_acc: 0.6268\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6050 - acc: 0.5930 - val_loss: 0.6296 - val_acc: 0.4315\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6112 - acc: 0.5522 - val_loss: 0.5878 - val_acc: 0.5889\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6044 - acc: 0.5689 - val_loss: 0.5870 - val_acc: 0.5802\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6027 - acc: 0.5930 - val_loss: 0.5864 - val_acc: 0.6064\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.6024 - acc: 0.5937 - val_loss: 0.5910 - val_acc: 0.5627\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5981 - acc: 0.5828 - val_loss: 0.5849 - val_acc: 0.5831\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6048 - acc: 0.5441 - val_loss: 0.5867 - val_acc: 0.6356\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6079 - acc: 0.6090 - val_loss: 0.5933 - val_acc: 0.5598\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5951 - acc: 0.5959 - val_loss: 0.5887 - val_acc: 0.6327\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5994 - acc: 0.6069 - val_loss: 0.5785 - val_acc: 0.6239\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5977 - acc: 0.6674 - val_loss: 0.6038 - val_acc: 0.5190\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6028 - acc: 0.6076 - val_loss: 0.5937 - val_acc: 0.7551\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6038 - acc: 0.6171 - val_loss: 0.5862 - val_acc: 0.6297\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5997 - acc: 0.6732 - val_loss: 0.5827 - val_acc: 0.6152\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6015 - acc: 0.5740 - val_loss: 0.5825 - val_acc: 0.6735\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5938 - acc: 0.6426 - val_loss: 0.6404 - val_acc: 0.3848\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6523 - acc: 0.3713 - val_loss: 0.6267 - val_acc: 0.3936\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6228 - acc: 0.5259 - val_loss: 0.6219 - val_acc: 0.4927\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6296 - acc: 0.5179 - val_loss: 0.6167 - val_acc: 0.5948\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.6261 - acc: 0.5923 - val_loss: 0.6103 - val_acc: 0.6210\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6201 - acc: 0.5894 - val_loss: 0.6069 - val_acc: 0.5743\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6121 - acc: 0.5697 - val_loss: 0.5953 - val_acc: 0.6181\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6108 - acc: 0.5660 - val_loss: 0.5952 - val_acc: 0.5860\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6060 - acc: 0.5616 - val_loss: 0.5959 - val_acc: 0.5860\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6039 - acc: 0.5864 - val_loss: 0.6059 - val_acc: 0.5102\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.6072 - acc: 0.5492 - val_loss: 0.5955 - val_acc: 0.5977\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6050 - acc: 0.5624 - val_loss: 0.5943 - val_acc: 0.5889\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.6034 - acc: 0.5660 - val_loss: 0.5989 - val_acc: 0.5598\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6059 - acc: 0.5755 - val_loss: 0.6042 - val_acc: 0.5364\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6044 - acc: 0.5704 - val_loss: 0.5943 - val_acc: 0.5802\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6017 - acc: 0.5872 - val_loss: 0.5948 - val_acc: 0.5743\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5995 - acc: 0.5675 - val_loss: 0.5935 - val_acc: 0.6006\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6063 - acc: 0.5901 - val_loss: 0.5975 - val_acc: 0.5656\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6021 - acc: 0.5886 - val_loss: 0.5932 - val_acc: 0.5743\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6018 - acc: 0.5682 - val_loss: 0.5969 - val_acc: 0.5802\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6022 - acc: 0.5726 - val_loss: 0.5927 - val_acc: 0.5918\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5997 - acc: 0.5981 - val_loss: 0.5905 - val_acc: 0.6210\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6005 - acc: 0.6061 - val_loss: 0.5910 - val_acc: 0.5889\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5976 - acc: 0.6120 - val_loss: 0.6071 - val_acc: 0.5452\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6071 - acc: 0.6134 - val_loss: 0.5954 - val_acc: 0.5627\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6014 - acc: 0.5689 - val_loss: 0.5974 - val_acc: 0.5364\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5977 - acc: 0.5835 - val_loss: 0.5906 - val_acc: 0.5481\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6004 - acc: 0.5894 - val_loss: 0.5926 - val_acc: 0.5743\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6014 - acc: 0.6076 - val_loss: 0.5987 - val_acc: 0.5335\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5976 - acc: 0.5828 - val_loss: 0.5890 - val_acc: 0.6122\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5951 - acc: 0.5966 - val_loss: 0.5842 - val_acc: 0.5948\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5943 - acc: 0.6025 - val_loss: 0.5935 - val_acc: 0.5364\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5932 - acc: 0.5937 - val_loss: 0.6094 - val_acc: 0.7026\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6073 - acc: 0.5828 - val_loss: 0.5961 - val_acc: 0.5364\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5917 - acc: 0.6200 - val_loss: 0.5861 - val_acc: 0.5860\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.6023 - acc: 0.5594 - val_loss: 0.5879 - val_acc: 0.6181\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6342 - acc: 0.4012 - val_loss: 0.6392 - val_acc: 0.3061\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6405 - acc: 0.4092 - val_loss: 0.6335 - val_acc: 0.3761\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6423 - acc: 0.4865 - val_loss: 0.6326 - val_acc: 0.6997\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6401 - acc: 0.5106 - val_loss: 0.6302 - val_acc: 0.6997\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6417 - acc: 0.5332 - val_loss: 0.6311 - val_acc: 0.6997\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6400 - acc: 0.5004 - val_loss: 0.6311 - val_acc: 0.3353\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6407 - acc: 0.5244 - val_loss: 0.6302 - val_acc: 0.6997\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6403 - acc: 0.5456 - val_loss: 0.6302 - val_acc: 0.6414\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6396 - acc: 0.5179 - val_loss: 0.6298 - val_acc: 0.6997\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6388 - acc: 0.5937 - val_loss: 0.6302 - val_acc: 0.3236\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6384 - acc: 0.4427 - val_loss: 0.6292 - val_acc: 0.6385\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6381 - acc: 0.5616 - val_loss: 0.6272 - val_acc: 0.6443\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.6386 - acc: 0.6441 - val_loss: 0.6276 - val_acc: 0.5073\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6388 - acc: 0.4478 - val_loss: 0.6268 - val_acc: 0.5802\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6354 - acc: 0.6251 - val_loss: 0.6222 - val_acc: 0.5977\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6306 - acc: 0.5682 - val_loss: 0.6152 - val_acc: 0.6327\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6264 - acc: 0.6018 - val_loss: 0.6132 - val_acc: 0.6356\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6355 - acc: 0.4778 - val_loss: 0.6261 - val_acc: 0.4023\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6304 - acc: 0.4814 - val_loss: 0.6329 - val_acc: 0.3178\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6375 - acc: 0.4143 - val_loss: 0.6263 - val_acc: 0.5481\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6375 - acc: 0.6054 - val_loss: 0.6243 - val_acc: 0.6997\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6324 - acc: 0.6229 - val_loss: 0.6196 - val_acc: 0.6268\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6266 - acc: 0.5828 - val_loss: 0.6051 - val_acc: 0.5918\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6232 - acc: 0.5631 - val_loss: 0.6294 - val_acc: 0.3703\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6284 - acc: 0.4763 - val_loss: 0.6089 - val_acc: 0.6122\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6201 - acc: 0.5842 - val_loss: 0.6006 - val_acc: 0.5656\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6151 - acc: 0.5383 - val_loss: 0.5962 - val_acc: 0.5948\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6170 - acc: 0.5485 - val_loss: 0.6205 - val_acc: 0.3907\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.6172 - acc: 0.5704 - val_loss: 0.5981 - val_acc: 0.5743\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6099 - acc: 0.5602 - val_loss: 0.5889 - val_acc: 0.6006\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6096 - acc: 0.5821 - val_loss: 0.5905 - val_acc: 0.6093\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6089 - acc: 0.5762 - val_loss: 0.5895 - val_acc: 0.6006\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6029 - acc: 0.6032 - val_loss: 0.5919 - val_acc: 0.5743\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6022 - acc: 0.5894 - val_loss: 0.5847 - val_acc: 0.6210\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6046 - acc: 0.6076 - val_loss: 0.5961 - val_acc: 0.5889\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6891 - acc: 0.6163 - val_loss: 0.6275 - val_acc: 0.3032\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6485 - acc: 0.3742 - val_loss: 0.6359 - val_acc: 0.3032\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6448 - acc: 0.4719 - val_loss: 0.6261 - val_acc: 0.6968\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6412 - acc: 0.5624 - val_loss: 0.6253 - val_acc: 0.6997\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6427 - acc: 0.5449 - val_loss: 0.6260 - val_acc: 0.6968\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6413 - acc: 0.5791 - val_loss: 0.6276 - val_acc: 0.6997\n",
            "Epoch 181: early stopping\n",
            "27/27 [==============================] - 2s 36ms/step - loss: 0.6171 - acc: 0.7056\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 7s 125ms/step - loss: 0.6417 - acc: 0.5215 - val_loss: 0.6256 - val_acc: 0.6589\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6263 - acc: 0.5886 - val_loss: 0.6115 - val_acc: 0.5656\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6238 - acc: 0.5346 - val_loss: 0.6126 - val_acc: 0.5219\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6200 - acc: 0.5106 - val_loss: 0.6099 - val_acc: 0.5598\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6218 - acc: 0.5748 - val_loss: 0.6157 - val_acc: 0.5073\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6166 - acc: 0.5609 - val_loss: 0.6132 - val_acc: 0.4810\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6204 - acc: 0.5055 - val_loss: 0.6229 - val_acc: 0.3936\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6199 - acc: 0.5419 - val_loss: 0.6092 - val_acc: 0.6501\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6201 - acc: 0.5835 - val_loss: 0.6060 - val_acc: 0.5598\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6178 - acc: 0.5456 - val_loss: 0.6019 - val_acc: 0.5831\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6159 - acc: 0.5383 - val_loss: 0.6029 - val_acc: 0.5860\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6149 - acc: 0.5543 - val_loss: 0.6066 - val_acc: 0.5219\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6123 - acc: 0.6069 - val_loss: 0.6037 - val_acc: 0.5219\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6168 - acc: 0.5616 - val_loss: 0.6005 - val_acc: 0.6152\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6103 - acc: 0.5522 - val_loss: 0.5991 - val_acc: 0.5656\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6104 - acc: 0.5383 - val_loss: 0.5921 - val_acc: 0.6152\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6117 - acc: 0.5398 - val_loss: 0.5911 - val_acc: 0.6064\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6088 - acc: 0.5718 - val_loss: 0.5928 - val_acc: 0.6385\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6148 - acc: 0.6083 - val_loss: 0.6046 - val_acc: 0.6239\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6090 - acc: 0.5616 - val_loss: 0.5945 - val_acc: 0.5948\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6134 - acc: 0.5507 - val_loss: 0.5991 - val_acc: 0.5773\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6137 - acc: 0.5762 - val_loss: 0.6056 - val_acc: 0.4898\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6113 - acc: 0.5492 - val_loss: 0.5898 - val_acc: 0.6064\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6057 - acc: 0.5573 - val_loss: 0.5872 - val_acc: 0.5831\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6113 - acc: 0.5594 - val_loss: 0.6002 - val_acc: 0.6997\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6153 - acc: 0.6258 - val_loss: 0.6050 - val_acc: 0.5394\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6112 - acc: 0.5376 - val_loss: 0.5995 - val_acc: 0.5714\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6083 - acc: 0.5463 - val_loss: 0.5944 - val_acc: 0.5918\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6063 - acc: 0.5638 - val_loss: 0.5895 - val_acc: 0.6327\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6070 - acc: 0.5726 - val_loss: 0.5885 - val_acc: 0.5714\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6039 - acc: 0.5813 - val_loss: 0.5950 - val_acc: 0.5131\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6047 - acc: 0.5777 - val_loss: 0.5856 - val_acc: 0.6210\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6040 - acc: 0.6076 - val_loss: 0.5947 - val_acc: 0.6764\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6058 - acc: 0.5930 - val_loss: 0.5936 - val_acc: 0.5802\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6016 - acc: 0.5609 - val_loss: 0.5859 - val_acc: 0.5831\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5998 - acc: 0.5937 - val_loss: 0.5843 - val_acc: 0.6385\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5992 - acc: 0.5966 - val_loss: 0.5922 - val_acc: 0.5335\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6007 - acc: 0.5879 - val_loss: 0.5870 - val_acc: 0.5656\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5980 - acc: 0.5974 - val_loss: 0.6014 - val_acc: 0.5102\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6077 - acc: 0.6163 - val_loss: 0.5920 - val_acc: 0.5423\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6002 - acc: 0.5733 - val_loss: 0.5816 - val_acc: 0.6356\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5972 - acc: 0.5842 - val_loss: 0.5865 - val_acc: 0.6327\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6005 - acc: 0.6098 - val_loss: 0.5896 - val_acc: 0.5452\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5969 - acc: 0.5937 - val_loss: 0.5798 - val_acc: 0.6385\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6004 - acc: 0.5959 - val_loss: 0.6050 - val_acc: 0.6501\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6024 - acc: 0.6047 - val_loss: 0.5877 - val_acc: 0.6239\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6039 - acc: 0.5974 - val_loss: 0.5868 - val_acc: 0.6327\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5931 - acc: 0.6003 - val_loss: 0.5817 - val_acc: 0.6064\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5920 - acc: 0.6061 - val_loss: 0.5895 - val_acc: 0.5394\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5922 - acc: 0.5966 - val_loss: 0.5983 - val_acc: 0.6122\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6038 - acc: 0.5718 - val_loss: 0.5876 - val_acc: 0.6356\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6002 - acc: 0.6185 - val_loss: 0.5839 - val_acc: 0.6181\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5949 - acc: 0.5806 - val_loss: 0.5770 - val_acc: 0.6589\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5944 - acc: 0.6163 - val_loss: 0.5773 - val_acc: 0.6443\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6407 - acc: 0.5405 - val_loss: 0.6108 - val_acc: 0.4140\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6127 - acc: 0.6149 - val_loss: 0.6055 - val_acc: 0.5860\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6130 - acc: 0.5419 - val_loss: 0.6009 - val_acc: 0.5627\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6070 - acc: 0.5653 - val_loss: 0.5981 - val_acc: 0.5685\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6067 - acc: 0.5332 - val_loss: 0.5905 - val_acc: 0.6064\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6047 - acc: 0.5857 - val_loss: 0.5916 - val_acc: 0.5569\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5993 - acc: 0.5740 - val_loss: 0.5816 - val_acc: 0.6356\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6000 - acc: 0.5930 - val_loss: 0.5804 - val_acc: 0.6472\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5990 - acc: 0.5996 - val_loss: 0.5829 - val_acc: 0.6122\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5986 - acc: 0.6098 - val_loss: 0.5808 - val_acc: 0.6297\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5954 - acc: 0.6171 - val_loss: 0.5779 - val_acc: 0.6560\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5940 - acc: 0.6265 - val_loss: 0.5830 - val_acc: 0.6064\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5918 - acc: 0.6309 - val_loss: 0.5793 - val_acc: 0.6997\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5944 - acc: 0.6258 - val_loss: 0.5795 - val_acc: 0.6152\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5926 - acc: 0.6149 - val_loss: 0.5767 - val_acc: 0.6472\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5951 - acc: 0.6441 - val_loss: 0.5890 - val_acc: 0.7085\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5986 - acc: 0.6397 - val_loss: 0.5842 - val_acc: 0.5394\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5942 - acc: 0.5988 - val_loss: 0.5786 - val_acc: 0.6064\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5845 - acc: 0.6309 - val_loss: 0.5761 - val_acc: 0.6268\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5926 - acc: 0.5937 - val_loss: 0.5813 - val_acc: 0.5714\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5906 - acc: 0.6258 - val_loss: 0.5889 - val_acc: 0.5860\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5955 - acc: 0.6462 - val_loss: 0.5839 - val_acc: 0.6006\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5901 - acc: 0.6382 - val_loss: 0.5784 - val_acc: 0.6122\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5808 - acc: 0.6265 - val_loss: 0.5824 - val_acc: 0.6093\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5854 - acc: 0.6193 - val_loss: 0.5807 - val_acc: 0.6385\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5860 - acc: 0.6324 - val_loss: 0.5816 - val_acc: 0.6414\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5886 - acc: 0.6273 - val_loss: 0.5790 - val_acc: 0.6589\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.5909 - acc: 0.6251 - val_loss: 0.5875 - val_acc: 0.5481\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5863 - acc: 0.6309 - val_loss: 0.5840 - val_acc: 0.6093\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5894 - acc: 0.6258 - val_loss: 0.5806 - val_acc: 0.6122\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5865 - acc: 0.6090 - val_loss: 0.5836 - val_acc: 0.5948\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5847 - acc: 0.6171 - val_loss: 0.5799 - val_acc: 0.6589\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5798 - acc: 0.6543 - val_loss: 0.5790 - val_acc: 0.6647\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5788 - acc: 0.6338 - val_loss: 0.5797 - val_acc: 0.6968\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5810 - acc: 0.6397 - val_loss: 0.5808 - val_acc: 0.6064\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5769 - acc: 0.6674 - val_loss: 0.5799 - val_acc: 0.6472\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5795 - acc: 0.6317 - val_loss: 0.5770 - val_acc: 0.6356\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5839 - acc: 0.6324 - val_loss: 0.5782 - val_acc: 0.6297\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5797 - acc: 0.6375 - val_loss: 0.5756 - val_acc: 0.6152\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5759 - acc: 0.6069 - val_loss: 0.5763 - val_acc: 0.6385\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5732 - acc: 0.6287 - val_loss: 0.5749 - val_acc: 0.6647\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5810 - acc: 0.6535 - val_loss: 0.5774 - val_acc: 0.6764\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5697 - acc: 0.6353 - val_loss: 0.5782 - val_acc: 0.6414\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5700 - acc: 0.6280 - val_loss: 0.5777 - val_acc: 0.6531\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5731 - acc: 0.6382 - val_loss: 0.5879 - val_acc: 0.6764\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5762 - acc: 0.6586 - val_loss: 0.5759 - val_acc: 0.6560\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5762 - acc: 0.6061 - val_loss: 0.5833 - val_acc: 0.6268\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5700 - acc: 0.6258 - val_loss: 0.5785 - val_acc: 0.6676\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5695 - acc: 0.6331 - val_loss: 0.5846 - val_acc: 0.6472\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5836 - acc: 0.6280 - val_loss: 0.5913 - val_acc: 0.5306\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5891 - acc: 0.5842 - val_loss: 0.5844 - val_acc: 0.6152\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5812 - acc: 0.6265 - val_loss: 0.5865 - val_acc: 0.6764\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5804 - acc: 0.6193 - val_loss: 0.5823 - val_acc: 0.6414\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5760 - acc: 0.6214 - val_loss: 0.5945 - val_acc: 0.5831\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5764 - acc: 0.6185 - val_loss: 0.5890 - val_acc: 0.6268\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5728 - acc: 0.6368 - val_loss: 0.5834 - val_acc: 0.6560\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5692 - acc: 0.6433 - val_loss: 0.5841 - val_acc: 0.6501\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5658 - acc: 0.6521 - val_loss: 0.5909 - val_acc: 0.6618\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5688 - acc: 0.6565 - val_loss: 0.5874 - val_acc: 0.6006\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5646 - acc: 0.6324 - val_loss: 0.5894 - val_acc: 0.6735\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5700 - acc: 0.6492 - val_loss: 0.5913 - val_acc: 0.6735\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5687 - acc: 0.6273 - val_loss: 0.5799 - val_acc: 0.6560\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5597 - acc: 0.6513 - val_loss: 0.5771 - val_acc: 0.6356\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5592 - acc: 0.6360 - val_loss: 0.5777 - val_acc: 0.6297\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5604 - acc: 0.6411 - val_loss: 0.5870 - val_acc: 0.6589\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5586 - acc: 0.6513 - val_loss: 0.5797 - val_acc: 0.6181\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5522 - acc: 0.6579 - val_loss: 0.5867 - val_acc: 0.5918\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5583 - acc: 0.6368 - val_loss: 0.5846 - val_acc: 0.6414\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5763 - acc: 0.6455 - val_loss: 0.6066 - val_acc: 0.5394\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5730 - acc: 0.6156 - val_loss: 0.5807 - val_acc: 0.6064\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5709 - acc: 0.6411 - val_loss: 0.6130 - val_acc: 0.6851\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5995 - acc: 0.5930 - val_loss: 0.5847 - val_acc: 0.6064\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5835 - acc: 0.6280 - val_loss: 0.5781 - val_acc: 0.6239\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5747 - acc: 0.6200 - val_loss: 0.5764 - val_acc: 0.6327\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5706 - acc: 0.6061 - val_loss: 0.5808 - val_acc: 0.6297\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5625 - acc: 0.6389 - val_loss: 0.5980 - val_acc: 0.6793\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5722 - acc: 0.6455 - val_loss: 0.5857 - val_acc: 0.6501\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5610 - acc: 0.6105 - val_loss: 0.5824 - val_acc: 0.6035\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5558 - acc: 0.6222 - val_loss: 0.5816 - val_acc: 0.6501\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5538 - acc: 0.6616 - val_loss: 0.5841 - val_acc: 0.6122\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5515 - acc: 0.6404 - val_loss: 0.5863 - val_acc: 0.5831\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5540 - acc: 0.6557 - val_loss: 0.5879 - val_acc: 0.6531\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5555 - acc: 0.6557 - val_loss: 0.5932 - val_acc: 0.5423\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5553 - acc: 0.6353 - val_loss: 0.5965 - val_acc: 0.5394\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5478 - acc: 0.6550 - val_loss: 0.5864 - val_acc: 0.6297\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5637 - acc: 0.6222 - val_loss: 0.5849 - val_acc: 0.6531\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5532 - acc: 0.6360 - val_loss: 0.5874 - val_acc: 0.5860\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5493 - acc: 0.6667 - val_loss: 0.5983 - val_acc: 0.5948\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5728 - acc: 0.6193 - val_loss: 0.5873 - val_acc: 0.6676\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5594 - acc: 0.6557 - val_loss: 0.5842 - val_acc: 0.6152\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5572 - acc: 0.6389 - val_loss: 0.5851 - val_acc: 0.5948\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5515 - acc: 0.6550 - val_loss: 0.5903 - val_acc: 0.5685\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5505 - acc: 0.6499 - val_loss: 0.5977 - val_acc: 0.6006\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5526 - acc: 0.6236 - val_loss: 0.5978 - val_acc: 0.6035\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5511 - acc: 0.6747 - val_loss: 0.5962 - val_acc: 0.5918\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5438 - acc: 0.6375 - val_loss: 0.6008 - val_acc: 0.5598\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5475 - acc: 0.6441 - val_loss: 0.5932 - val_acc: 0.6210\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5429 - acc: 0.6667 - val_loss: 0.5884 - val_acc: 0.6035\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5420 - acc: 0.6513 - val_loss: 0.5960 - val_acc: 0.6152\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5485 - acc: 0.6506 - val_loss: 0.6049 - val_acc: 0.6152\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5441 - acc: 0.6689 - val_loss: 0.6131 - val_acc: 0.6093\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5509 - acc: 0.6411 - val_loss: 0.6018 - val_acc: 0.5627\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5499 - acc: 0.6608 - val_loss: 0.6016 - val_acc: 0.5481\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5520 - acc: 0.6214 - val_loss: 0.6144 - val_acc: 0.5510\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5567 - acc: 0.6295 - val_loss: 0.5805 - val_acc: 0.6385\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5465 - acc: 0.6543 - val_loss: 0.5936 - val_acc: 0.6472\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5403 - acc: 0.6608 - val_loss: 0.5884 - val_acc: 0.5977\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5448 - acc: 0.6419 - val_loss: 0.5777 - val_acc: 0.6501\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5370 - acc: 0.6667 - val_loss: 0.5858 - val_acc: 0.6210\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5353 - acc: 0.6747 - val_loss: 0.6203 - val_acc: 0.5627\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5372 - acc: 0.6477 - val_loss: 0.5781 - val_acc: 0.6122\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5352 - acc: 0.6586 - val_loss: 0.5907 - val_acc: 0.6327\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5360 - acc: 0.6477 - val_loss: 0.5769 - val_acc: 0.6414\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5376 - acc: 0.6798 - val_loss: 0.5845 - val_acc: 0.6472\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5403 - acc: 0.6331 - val_loss: 0.6025 - val_acc: 0.5889\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5482 - acc: 0.6864 - val_loss: 0.5878 - val_acc: 0.5860\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5293 - acc: 0.6608 - val_loss: 0.5973 - val_acc: 0.5714\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5380 - acc: 0.6557 - val_loss: 0.5948 - val_acc: 0.6006\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5734 - acc: 0.6433 - val_loss: 0.5786 - val_acc: 0.6006\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5543 - acc: 0.6273 - val_loss: 0.5648 - val_acc: 0.6560\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5526 - acc: 0.6579 - val_loss: 0.5671 - val_acc: 0.6122\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5430 - acc: 0.6448 - val_loss: 0.5704 - val_acc: 0.6268\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5409 - acc: 0.6579 - val_loss: 0.5718 - val_acc: 0.6501\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5463 - acc: 0.6813 - val_loss: 0.5992 - val_acc: 0.5539\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5415 - acc: 0.6594 - val_loss: 0.5755 - val_acc: 0.6239\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5391 - acc: 0.6849 - val_loss: 0.5788 - val_acc: 0.6356\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5298 - acc: 0.6718 - val_loss: 0.5965 - val_acc: 0.6064\n",
            "Epoch 182/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5409 - acc: 0.6769 - val_loss: 0.5770 - val_acc: 0.6618\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5360 - acc: 0.6783 - val_loss: 0.5724 - val_acc: 0.6735\n",
            "Epoch 184/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5374 - acc: 0.6616 - val_loss: 0.5694 - val_acc: 0.6327\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5286 - acc: 0.6579 - val_loss: 0.5657 - val_acc: 0.6764\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5250 - acc: 0.6937 - val_loss: 0.5770 - val_acc: 0.6210\n",
            "Epoch 187/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5222 - acc: 0.6856 - val_loss: 0.5854 - val_acc: 0.5918\n",
            "Epoch 188/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5465 - acc: 0.6849 - val_loss: 0.5922 - val_acc: 0.5714\n",
            "Epoch 189/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5348 - acc: 0.6565 - val_loss: 0.5823 - val_acc: 0.6356\n",
            "Epoch 190/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5326 - acc: 0.6674 - val_loss: 0.5810 - val_acc: 0.6152\n",
            "Epoch 191/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5474 - acc: 0.6397 - val_loss: 0.5858 - val_acc: 0.5918\n",
            "Epoch 192/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5336 - acc: 0.6565 - val_loss: 0.5804 - val_acc: 0.6589\n",
            "Epoch 193/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5228 - acc: 0.6805 - val_loss: 0.5754 - val_acc: 0.6443\n",
            "Epoch 194/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5140 - acc: 0.6842 - val_loss: 0.5951 - val_acc: 0.5889\n",
            "Epoch 195/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5202 - acc: 0.6718 - val_loss: 0.6047 - val_acc: 0.5918\n",
            "Epoch 196/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5164 - acc: 0.6813 - val_loss: 0.5841 - val_acc: 0.6064\n",
            "Epoch 197/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5194 - acc: 0.6922 - val_loss: 0.5802 - val_acc: 0.6385\n",
            "Epoch 198/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5157 - acc: 0.6725 - val_loss: 0.5993 - val_acc: 0.6006\n",
            "Epoch 199/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5185 - acc: 0.6608 - val_loss: 0.5835 - val_acc: 0.6006\n",
            "Epoch 200/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5138 - acc: 0.6667 - val_loss: 0.5839 - val_acc: 0.6210\n",
            "Epoch 201/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5074 - acc: 0.6856 - val_loss: 0.5882 - val_acc: 0.6239\n",
            "Epoch 202/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5129 - acc: 0.6630 - val_loss: 0.5705 - val_acc: 0.6122\n",
            "Epoch 203/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5117 - acc: 0.6689 - val_loss: 0.5799 - val_acc: 0.6093\n",
            "Epoch 204/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5141 - acc: 0.6645 - val_loss: 0.5799 - val_acc: 0.6152\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5102 - acc: 0.6973 - val_loss: 0.5824 - val_acc: 0.6210\n",
            "Epoch 206/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5109 - acc: 0.6645 - val_loss: 0.5949 - val_acc: 0.6181\n",
            "Epoch 207/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5116 - acc: 0.6798 - val_loss: 0.5874 - val_acc: 0.6210\n",
            "Epoch 208/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5155 - acc: 0.6448 - val_loss: 0.5736 - val_acc: 0.6764\n",
            "Epoch 209/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5197 - acc: 0.6966 - val_loss: 0.5721 - val_acc: 0.6327\n",
            "Epoch 210/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5429 - acc: 0.6689 - val_loss: 0.5937 - val_acc: 0.6297\n",
            "Epoch 211/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5248 - acc: 0.6834 - val_loss: 0.5609 - val_acc: 0.6327\n",
            "Epoch 212/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5154 - acc: 0.6849 - val_loss: 0.5627 - val_acc: 0.6910\n",
            "Epoch 213/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5167 - acc: 0.7002 - val_loss: 0.5542 - val_acc: 0.6385\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5027 - acc: 0.6754 - val_loss: 0.5660 - val_acc: 0.6297\n",
            "Epoch 215/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5114 - acc: 0.6871 - val_loss: 0.5713 - val_acc: 0.6327\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5035 - acc: 0.6958 - val_loss: 0.5884 - val_acc: 0.5977\n",
            "Epoch 217/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5210 - acc: 0.6718 - val_loss: 0.5842 - val_acc: 0.5948\n",
            "Epoch 218/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5093 - acc: 0.6652 - val_loss: 0.6018 - val_acc: 0.6501\n",
            "Epoch 219/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5506 - acc: 0.6404 - val_loss: 0.5918 - val_acc: 0.6210\n",
            "Epoch 220/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5217 - acc: 0.6579 - val_loss: 0.5780 - val_acc: 0.6210\n",
            "Epoch 221/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5535 - acc: 0.6499 - val_loss: 0.5755 - val_acc: 0.6472\n",
            "Epoch 222/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5392 - acc: 0.6747 - val_loss: 0.5616 - val_acc: 0.6268\n",
            "Epoch 223/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5264 - acc: 0.6616 - val_loss: 0.5758 - val_acc: 0.6239\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5178 - acc: 0.6703 - val_loss: 0.5713 - val_acc: 0.6297\n",
            "Epoch 225/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5148 - acc: 0.6608 - val_loss: 0.5855 - val_acc: 0.6210\n",
            "Epoch 226/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5060 - acc: 0.6710 - val_loss: 0.5891 - val_acc: 0.6181\n",
            "Epoch 227/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5051 - acc: 0.6900 - val_loss: 0.5832 - val_acc: 0.6006\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5120 - acc: 0.6586 - val_loss: 0.5756 - val_acc: 0.6385\n",
            "Epoch 229/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5961 - acc: 0.5697 - val_loss: 0.6194 - val_acc: 0.4752\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6174 - acc: 0.5026 - val_loss: 0.6075 - val_acc: 0.5627\n",
            "Epoch 231/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6191 - acc: 0.5303 - val_loss: 0.6070 - val_acc: 0.5277\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6229 - acc: 0.4661 - val_loss: 0.6099 - val_acc: 0.4927\n",
            "Epoch 233/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6113 - acc: 0.5412 - val_loss: 0.6044 - val_acc: 0.5481\n",
            "Epoch 234/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6108 - acc: 0.5383 - val_loss: 0.6067 - val_acc: 0.5131\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6125 - acc: 0.5281 - val_loss: 0.6031 - val_acc: 0.5452\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6080 - acc: 0.5449 - val_loss: 0.6036 - val_acc: 0.5335\n",
            "Epoch 237/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6063 - acc: 0.5543 - val_loss: 0.6007 - val_acc: 0.5598\n",
            "Epoch 238/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6106 - acc: 0.5361 - val_loss: 0.5999 - val_acc: 0.5569\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6042 - acc: 0.5543 - val_loss: 0.6044 - val_acc: 0.5306\n",
            "Epoch 240/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.6083 - acc: 0.5295 - val_loss: 0.5975 - val_acc: 0.5685\n",
            "Epoch 241/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6062 - acc: 0.5536 - val_loss: 0.6016 - val_acc: 0.5335\n",
            "Epoch 242/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6063 - acc: 0.5398 - val_loss: 0.5965 - val_acc: 0.5685\n",
            "Epoch 243/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6027 - acc: 0.5799 - val_loss: 0.6006 - val_acc: 0.5423\n",
            "Epoch 244/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6045 - acc: 0.5478 - val_loss: 0.5954 - val_acc: 0.5656\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6063 - acc: 0.5675 - val_loss: 0.5991 - val_acc: 0.5335\n",
            "Epoch 246/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6036 - acc: 0.5573 - val_loss: 0.5907 - val_acc: 0.6152\n",
            "Epoch 247/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5971 - acc: 0.5580 - val_loss: 0.5906 - val_acc: 0.5860\n",
            "Epoch 248/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5956 - acc: 0.5828 - val_loss: 0.5925 - val_acc: 0.5539\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5961 - acc: 0.5602 - val_loss: 0.5918 - val_acc: 0.5394\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5946 - acc: 0.5653 - val_loss: 0.5800 - val_acc: 0.6443\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5958 - acc: 0.5616 - val_loss: 0.5814 - val_acc: 0.6414\n",
            "Epoch 252/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5882 - acc: 0.6098 - val_loss: 0.5881 - val_acc: 0.5598\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5897 - acc: 0.5835 - val_loss: 0.5799 - val_acc: 0.6006\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5902 - acc: 0.5755 - val_loss: 0.5787 - val_acc: 0.5948\n",
            "Epoch 255/1000\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.5884 - acc: 0.5842 - val_loss: 0.5792 - val_acc: 0.5977\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5866 - acc: 0.6010 - val_loss: 0.5854 - val_acc: 0.5598\n",
            "Epoch 257/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5833 - acc: 0.6032 - val_loss: 0.5802 - val_acc: 0.5860\n",
            "Epoch 258/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5839 - acc: 0.5835 - val_loss: 0.5813 - val_acc: 0.6414\n",
            "Epoch 259/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5810 - acc: 0.6018 - val_loss: 0.5865 - val_acc: 0.5248\n",
            "Epoch 260/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5794 - acc: 0.6025 - val_loss: 0.5798 - val_acc: 0.6093\n",
            "Epoch 261/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5734 - acc: 0.6047 - val_loss: 0.5822 - val_acc: 0.5394\n",
            "Epoch 262/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5809 - acc: 0.6098 - val_loss: 0.5819 - val_acc: 0.5394\n",
            "Epoch 263/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5726 - acc: 0.5966 - val_loss: 0.5813 - val_acc: 0.5685\n",
            "Epoch 264/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5664 - acc: 0.6127 - val_loss: 0.5877 - val_acc: 0.6006\n",
            "Epoch 265/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5894 - acc: 0.5981 - val_loss: 0.5787 - val_acc: 0.6706\n",
            "Epoch 266/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5650 - acc: 0.6338 - val_loss: 0.5750 - val_acc: 0.6152\n",
            "Epoch 267/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5660 - acc: 0.6142 - val_loss: 0.5801 - val_acc: 0.6064\n",
            "Epoch 268/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5596 - acc: 0.6251 - val_loss: 0.5800 - val_acc: 0.6676\n",
            "Epoch 269/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5677 - acc: 0.6156 - val_loss: 0.5753 - val_acc: 0.6152\n",
            "Epoch 270/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5669 - acc: 0.6513 - val_loss: 0.5824 - val_acc: 0.6735\n",
            "Epoch 271/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5624 - acc: 0.6236 - val_loss: 0.5811 - val_acc: 0.6268\n",
            "Epoch 272/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5557 - acc: 0.6557 - val_loss: 0.5784 - val_acc: 0.6560\n",
            "Epoch 273/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5529 - acc: 0.6375 - val_loss: 0.5845 - val_acc: 0.6181\n",
            "Epoch 274/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5559 - acc: 0.6411 - val_loss: 0.5727 - val_acc: 0.6472\n",
            "Epoch 275/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5535 - acc: 0.6513 - val_loss: 0.5785 - val_acc: 0.6327\n",
            "Epoch 276/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5557 - acc: 0.6433 - val_loss: 0.5752 - val_acc: 0.6676\n",
            "Epoch 277/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5545 - acc: 0.6419 - val_loss: 0.5921 - val_acc: 0.6181\n",
            "Epoch 278/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5561 - acc: 0.6273 - val_loss: 0.5744 - val_acc: 0.6268\n",
            "Epoch 279/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5516 - acc: 0.6499 - val_loss: 0.5882 - val_acc: 0.6152\n",
            "Epoch 280/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5537 - acc: 0.6375 - val_loss: 0.5697 - val_acc: 0.6764\n",
            "Epoch 281/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5451 - acc: 0.6499 - val_loss: 0.5758 - val_acc: 0.6152\n",
            "Epoch 282/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5500 - acc: 0.6513 - val_loss: 0.5802 - val_acc: 0.6764\n",
            "Epoch 283/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5448 - acc: 0.6616 - val_loss: 0.5810 - val_acc: 0.6851\n",
            "Epoch 284/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5476 - acc: 0.6338 - val_loss: 0.5817 - val_acc: 0.6501\n",
            "Epoch 285/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5429 - acc: 0.6586 - val_loss: 0.5941 - val_acc: 0.6356\n",
            "Epoch 286/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5498 - acc: 0.6776 - val_loss: 0.5695 - val_acc: 0.6793\n",
            "Epoch 287/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5429 - acc: 0.6557 - val_loss: 0.5677 - val_acc: 0.6851\n",
            "Epoch 288/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5557 - acc: 0.6689 - val_loss: 0.5746 - val_acc: 0.6064\n",
            "Epoch 289/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5410 - acc: 0.6710 - val_loss: 0.5723 - val_acc: 0.6122\n",
            "Epoch 290/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5490 - acc: 0.6499 - val_loss: 0.5663 - val_acc: 0.6531\n",
            "Epoch 291/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5334 - acc: 0.6740 - val_loss: 0.5630 - val_acc: 0.6618\n",
            "Epoch 292/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5328 - acc: 0.6689 - val_loss: 0.5670 - val_acc: 0.6560\n",
            "Epoch 293/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5420 - acc: 0.6630 - val_loss: 0.5749 - val_acc: 0.6239\n",
            "Epoch 294/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5407 - acc: 0.6732 - val_loss: 0.5911 - val_acc: 0.5539\n",
            "Epoch 295/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5393 - acc: 0.6528 - val_loss: 0.5700 - val_acc: 0.6356\n",
            "Epoch 296/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5363 - acc: 0.6433 - val_loss: 0.5711 - val_acc: 0.6560\n",
            "Epoch 297/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5492 - acc: 0.6477 - val_loss: 0.5786 - val_acc: 0.6676\n",
            "Epoch 298/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5329 - acc: 0.6754 - val_loss: 0.5701 - val_acc: 0.6560\n",
            "Epoch 299/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5301 - acc: 0.6820 - val_loss: 0.5874 - val_acc: 0.6035\n",
            "Epoch 300/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5324 - acc: 0.6747 - val_loss: 0.5848 - val_acc: 0.6618\n",
            "Epoch 301/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5315 - acc: 0.6769 - val_loss: 0.5692 - val_acc: 0.6414\n",
            "Epoch 302/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5283 - acc: 0.6761 - val_loss: 0.5725 - val_acc: 0.6356\n",
            "Epoch 303/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5330 - acc: 0.6681 - val_loss: 0.5666 - val_acc: 0.6501\n",
            "Epoch 304/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5295 - acc: 0.6645 - val_loss: 0.5677 - val_acc: 0.6793\n",
            "Epoch 305/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5280 - acc: 0.6813 - val_loss: 0.5610 - val_acc: 0.6356\n",
            "Epoch 306/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5175 - acc: 0.6842 - val_loss: 0.5798 - val_acc: 0.6356\n",
            "Epoch 307/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5185 - acc: 0.6740 - val_loss: 0.5592 - val_acc: 0.6560\n",
            "Epoch 308/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5142 - acc: 0.6703 - val_loss: 0.5765 - val_acc: 0.6385\n",
            "Epoch 309/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5218 - acc: 0.6732 - val_loss: 0.5740 - val_acc: 0.6414\n",
            "Epoch 310/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5191 - acc: 0.6718 - val_loss: 0.5873 - val_acc: 0.6268\n",
            "Epoch 311/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5208 - acc: 0.6718 - val_loss: 0.5654 - val_acc: 0.6472\n",
            "Epoch 312/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5189 - acc: 0.6769 - val_loss: 0.5533 - val_acc: 0.6764\n",
            "Epoch 313/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5354 - acc: 0.6915 - val_loss: 0.5835 - val_acc: 0.6910\n",
            "Epoch 314/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5353 - acc: 0.6594 - val_loss: 0.5655 - val_acc: 0.6560\n",
            "Epoch 315/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5191 - acc: 0.6710 - val_loss: 0.5590 - val_acc: 0.6647\n",
            "Epoch 316/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5273 - acc: 0.6725 - val_loss: 0.5594 - val_acc: 0.6560\n",
            "Epoch 317/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5182 - acc: 0.6732 - val_loss: 0.5656 - val_acc: 0.6472\n",
            "Epoch 318/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5172 - acc: 0.6674 - val_loss: 0.5811 - val_acc: 0.6210\n",
            "Epoch 319/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5329 - acc: 0.6492 - val_loss: 0.5594 - val_acc: 0.6443\n",
            "Epoch 320/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5170 - acc: 0.6769 - val_loss: 0.5574 - val_acc: 0.6676\n",
            "Epoch 321/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5131 - acc: 0.6791 - val_loss: 0.5572 - val_acc: 0.6414\n",
            "Epoch 322/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5117 - acc: 0.6885 - val_loss: 0.5715 - val_acc: 0.6064\n",
            "Epoch 323/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5256 - acc: 0.6521 - val_loss: 0.5791 - val_acc: 0.6210\n",
            "Epoch 324/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5360 - acc: 0.6681 - val_loss: 0.5575 - val_acc: 0.6385\n",
            "Epoch 325/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5201 - acc: 0.6586 - val_loss: 0.5674 - val_acc: 0.6501\n",
            "Epoch 326/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5093 - acc: 0.6725 - val_loss: 0.5697 - val_acc: 0.6152\n",
            "Epoch 327/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5007 - acc: 0.6958 - val_loss: 0.5612 - val_acc: 0.6676\n",
            "Epoch 328/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5144 - acc: 0.6827 - val_loss: 0.5605 - val_acc: 0.6706\n",
            "Epoch 329/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5121 - acc: 0.6842 - val_loss: 0.5728 - val_acc: 0.6414\n",
            "Epoch 330/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5215 - acc: 0.6900 - val_loss: 0.5595 - val_acc: 0.6735\n",
            "Epoch 331/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5241 - acc: 0.6820 - val_loss: 0.5744 - val_acc: 0.7114\n",
            "Epoch 332/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5364 - acc: 0.6732 - val_loss: 0.5591 - val_acc: 0.6531\n",
            "Epoch 333/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5333 - acc: 0.6995 - val_loss: 0.5801 - val_acc: 0.6472\n",
            "Epoch 334/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5382 - acc: 0.6689 - val_loss: 0.5701 - val_acc: 0.6064\n",
            "Epoch 335/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5364 - acc: 0.6791 - val_loss: 0.5771 - val_acc: 0.6064\n",
            "Epoch 336/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5541 - acc: 0.6214 - val_loss: 0.5778 - val_acc: 0.5918\n",
            "Epoch 337/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5214 - acc: 0.6608 - val_loss: 0.5743 - val_acc: 0.6297\n",
            "Epoch 338/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5348 - acc: 0.6389 - val_loss: 0.5770 - val_acc: 0.6268\n",
            "Epoch 339/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5395 - acc: 0.6659 - val_loss: 0.5693 - val_acc: 0.6443\n",
            "Epoch 340/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5129 - acc: 0.6776 - val_loss: 0.5693 - val_acc: 0.6414\n",
            "Epoch 341/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5323 - acc: 0.6703 - val_loss: 0.5751 - val_acc: 0.6006\n",
            "Epoch 342/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5279 - acc: 0.6565 - val_loss: 0.5605 - val_acc: 0.6822\n",
            "Epoch 343/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5256 - acc: 0.7053 - val_loss: 0.5668 - val_acc: 0.6472\n",
            "Epoch 344/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5248 - acc: 0.6637 - val_loss: 0.5849 - val_acc: 0.6356\n",
            "Epoch 345/1000\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.5201 - acc: 0.6827 - val_loss: 0.5709 - val_acc: 0.6064\n",
            "Epoch 346/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5300 - acc: 0.6513 - val_loss: 0.5819 - val_acc: 0.6093\n",
            "Epoch 347/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5291 - acc: 0.6470 - val_loss: 0.5748 - val_acc: 0.6035\n",
            "Epoch 348/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5190 - acc: 0.6740 - val_loss: 0.5689 - val_acc: 0.6414\n",
            "Epoch 349/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5197 - acc: 0.6630 - val_loss: 0.5768 - val_acc: 0.6385\n",
            "Epoch 350/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5187 - acc: 0.6710 - val_loss: 0.5823 - val_acc: 0.6297\n",
            "Epoch 351/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5170 - acc: 0.6586 - val_loss: 0.5651 - val_acc: 0.6735\n",
            "Epoch 352/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5151 - acc: 0.6849 - val_loss: 0.5586 - val_acc: 0.6735\n",
            "Epoch 353/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5404 - acc: 0.6572 - val_loss: 0.5726 - val_acc: 0.7026\n",
            "Epoch 354/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5685 - acc: 0.6659 - val_loss: 0.5711 - val_acc: 0.6997\n",
            "Epoch 355/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5671 - acc: 0.6783 - val_loss: 0.5576 - val_acc: 0.6764\n",
            "Epoch 356/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5479 - acc: 0.6725 - val_loss: 0.5512 - val_acc: 0.7143\n",
            "Epoch 357/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5627 - acc: 0.6732 - val_loss: 0.5607 - val_acc: 0.6676\n",
            "Epoch 358/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5407 - acc: 0.6834 - val_loss: 0.5793 - val_acc: 0.6560\n",
            "Epoch 359/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5401 - acc: 0.6623 - val_loss: 0.5619 - val_acc: 0.6910\n",
            "Epoch 360/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5266 - acc: 0.6725 - val_loss: 0.5648 - val_acc: 0.6997\n",
            "Epoch 361/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5367 - acc: 0.6813 - val_loss: 0.5546 - val_acc: 0.6385\n",
            "Epoch 362/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5294 - acc: 0.6725 - val_loss: 0.5696 - val_acc: 0.6968\n",
            "Epoch 363/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5380 - acc: 0.6871 - val_loss: 0.5845 - val_acc: 0.6939\n",
            "Epoch 364/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5411 - acc: 0.6557 - val_loss: 0.5785 - val_acc: 0.6327\n",
            "Epoch 365/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5318 - acc: 0.6922 - val_loss: 0.5759 - val_acc: 0.6385\n",
            "Epoch 366/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5245 - acc: 0.6703 - val_loss: 0.5642 - val_acc: 0.6589\n",
            "Epoch 367/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5239 - acc: 0.6769 - val_loss: 0.5734 - val_acc: 0.6618\n",
            "Epoch 368/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5244 - acc: 0.6747 - val_loss: 0.5587 - val_acc: 0.6939\n",
            "Epoch 369/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5260 - acc: 0.6754 - val_loss: 0.5817 - val_acc: 0.6501\n",
            "Epoch 370/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5410 - acc: 0.6389 - val_loss: 0.5630 - val_acc: 0.6093\n",
            "Epoch 371/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5327 - acc: 0.6915 - val_loss: 0.5685 - val_acc: 0.6210\n",
            "Epoch 372/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5193 - acc: 0.6915 - val_loss: 0.5640 - val_acc: 0.6851\n",
            "Epoch 373/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5320 - acc: 0.6893 - val_loss: 0.5597 - val_acc: 0.6560\n",
            "Epoch 374/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5380 - acc: 0.6681 - val_loss: 0.5591 - val_acc: 0.6327\n",
            "Epoch 375/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5278 - acc: 0.6776 - val_loss: 0.5604 - val_acc: 0.6880\n",
            "Epoch 376/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5147 - acc: 0.6871 - val_loss: 0.5484 - val_acc: 0.6880\n",
            "Epoch 377/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5175 - acc: 0.6769 - val_loss: 0.5548 - val_acc: 0.6793\n",
            "Epoch 378/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5180 - acc: 0.6681 - val_loss: 0.5618 - val_acc: 0.7143\n",
            "Epoch 379/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5170 - acc: 0.6703 - val_loss: 0.5765 - val_acc: 0.6939\n",
            "Epoch 380/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5145 - acc: 0.6966 - val_loss: 0.5576 - val_acc: 0.6152\n",
            "Epoch 381/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5135 - acc: 0.6740 - val_loss: 0.5636 - val_acc: 0.6706\n",
            "Epoch 382/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5104 - acc: 0.6652 - val_loss: 0.5549 - val_acc: 0.6297\n",
            "Epoch 383/1000\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.5197 - acc: 0.6856 - val_loss: 0.5622 - val_acc: 0.5860\n",
            "Epoch 384/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5166 - acc: 0.6667 - val_loss: 0.5621 - val_acc: 0.6501\n",
            "Epoch 385/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5182 - acc: 0.6725 - val_loss: 0.5689 - val_acc: 0.6501\n",
            "Epoch 386/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5190 - acc: 0.6958 - val_loss: 0.5836 - val_acc: 0.6968\n",
            "Epoch 387/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5286 - acc: 0.6630 - val_loss: 0.5768 - val_acc: 0.6006\n",
            "Epoch 388/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5155 - acc: 0.6740 - val_loss: 0.5665 - val_acc: 0.6443\n",
            "Epoch 389/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5085 - acc: 0.6951 - val_loss: 0.6103 - val_acc: 0.6297\n",
            "Epoch 390/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5057 - acc: 0.6783 - val_loss: 0.5687 - val_acc: 0.6793\n",
            "Epoch 391/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5036 - acc: 0.6907 - val_loss: 0.5777 - val_acc: 0.6618\n",
            "Epoch 392/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5038 - acc: 0.6732 - val_loss: 0.5763 - val_acc: 0.6356\n",
            "Epoch 393/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.4998 - acc: 0.6915 - val_loss: 0.5921 - val_acc: 0.6297\n",
            "Epoch 394/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5067 - acc: 0.7061 - val_loss: 0.5850 - val_acc: 0.6501\n",
            "Epoch 395/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5106 - acc: 0.6900 - val_loss: 0.5863 - val_acc: 0.6560\n",
            "Epoch 396/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5349 - acc: 0.6922 - val_loss: 0.5732 - val_acc: 0.7055\n",
            "Epoch 397/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5645 - acc: 0.6842 - val_loss: 0.6508 - val_acc: 0.5948\n",
            "Epoch 398/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5620 - acc: 0.6937 - val_loss: 0.5781 - val_acc: 0.6064\n",
            "Epoch 399/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5355 - acc: 0.6703 - val_loss: 0.5688 - val_acc: 0.6764\n",
            "Epoch 400/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5155 - acc: 0.6929 - val_loss: 0.5555 - val_acc: 0.6822\n",
            "Epoch 401/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5087 - acc: 0.6966 - val_loss: 0.5780 - val_acc: 0.6385\n",
            "Epoch 402/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5115 - acc: 0.6988 - val_loss: 0.5770 - val_acc: 0.6764\n",
            "Epoch 403/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5139 - acc: 0.6820 - val_loss: 0.5633 - val_acc: 0.6443\n",
            "Epoch 404/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5183 - acc: 0.6929 - val_loss: 0.5718 - val_acc: 0.6356\n",
            "Epoch 405/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5131 - acc: 0.6885 - val_loss: 0.5969 - val_acc: 0.6472\n",
            "Epoch 406/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5934 - acc: 0.6069 - val_loss: 0.6249 - val_acc: 0.5860\n",
            "Epoch 407/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.7250 - acc: 0.5748 - val_loss: 0.6395 - val_acc: 0.3003\n",
            "Epoch 408/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6363 - acc: 0.4391 - val_loss: 0.6273 - val_acc: 0.3411\n",
            "Epoch 409/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6342 - acc: 0.4945 - val_loss: 0.6276 - val_acc: 0.3090\n",
            "Epoch 410/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6319 - acc: 0.5120 - val_loss: 0.6274 - val_acc: 0.3265\n",
            "Epoch 411/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6327 - acc: 0.4894 - val_loss: 0.6269 - val_acc: 0.4636\n",
            "Epoch 412/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.6357 - acc: 0.5463 - val_loss: 0.6257 - val_acc: 0.7026\n",
            "Epoch 413/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6323 - acc: 0.5748 - val_loss: 0.6261 - val_acc: 0.6997\n",
            "Epoch 414/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6293 - acc: 0.5565 - val_loss: 0.6263 - val_acc: 0.5102\n",
            "Epoch 415/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6307 - acc: 0.5427 - val_loss: 0.6252 - val_acc: 0.6560\n",
            "Epoch 416/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6309 - acc: 0.5281 - val_loss: 0.6249 - val_acc: 0.5977\n",
            "Epoch 417/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6296 - acc: 0.5259 - val_loss: 0.6245 - val_acc: 0.5131\n",
            "Epoch 418/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6283 - acc: 0.4909 - val_loss: 0.6209 - val_acc: 0.5335\n",
            "Epoch 419/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6272 - acc: 0.5383 - val_loss: 0.6165 - val_acc: 0.4898\n",
            "Epoch 420/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6253 - acc: 0.4887 - val_loss: 0.6112 - val_acc: 0.6122\n",
            "Epoch 421/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6230 - acc: 0.5427 - val_loss: 0.6156 - val_acc: 0.4636\n",
            "Epoch 422/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6260 - acc: 0.5208 - val_loss: 0.6167 - val_acc: 0.4665\n",
            "Epoch 423/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6254 - acc: 0.6003 - val_loss: 0.6212 - val_acc: 0.3907\n",
            "Epoch 424/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6204 - acc: 0.5587 - val_loss: 0.6063 - val_acc: 0.5190\n",
            "Epoch 425/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6197 - acc: 0.5113 - val_loss: 0.6109 - val_acc: 0.4840\n",
            "Epoch 426/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6206 - acc: 0.5419 - val_loss: 0.5996 - val_acc: 0.6122\n",
            "Epoch 427/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6215 - acc: 0.5580 - val_loss: 0.6120 - val_acc: 0.4898\n",
            "Epoch 428/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6225 - acc: 0.5062 - val_loss: 0.6042 - val_acc: 0.5918\n",
            "Epoch 429/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6202 - acc: 0.5368 - val_loss: 0.6007 - val_acc: 0.5656\n",
            "Epoch 430/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6171 - acc: 0.5463 - val_loss: 0.5954 - val_acc: 0.7085\n",
            "Epoch 431/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6652 - acc: 0.6637 - val_loss: 0.6269 - val_acc: 0.6997\n",
            "Epoch 432/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6335 - acc: 0.5733 - val_loss: 0.6274 - val_acc: 0.3061\n",
            "Epoch 433/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6312 - acc: 0.4690 - val_loss: 0.6280 - val_acc: 0.3003\n",
            "Epoch 434/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6320 - acc: 0.4515 - val_loss: 0.6277 - val_acc: 0.3032\n",
            "Epoch 435/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.6327 - acc: 0.4391 - val_loss: 0.6277 - val_acc: 0.3032\n",
            "Epoch 436/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.6328 - acc: 0.4814 - val_loss: 0.6272 - val_acc: 0.5627\n",
            "Epoch 437/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6323 - acc: 0.5106 - val_loss: 0.6271 - val_acc: 0.6239\n",
            "Epoch 438/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6320 - acc: 0.5040 - val_loss: 0.6273 - val_acc: 0.3586\n",
            "Epoch 439/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6307 - acc: 0.4967 - val_loss: 0.6272 - val_acc: 0.4344\n",
            "Epoch 440/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6315 - acc: 0.5135 - val_loss: 0.6271 - val_acc: 0.4781\n",
            "Epoch 441/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6320 - acc: 0.4923 - val_loss: 0.6271 - val_acc: 0.4606\n",
            "Epoch 442/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6323 - acc: 0.4705 - val_loss: 0.6272 - val_acc: 0.4227\n",
            "Epoch 443/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.6311 - acc: 0.4974 - val_loss: 0.6272 - val_acc: 0.3644\n",
            "Epoch 444/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6321 - acc: 0.5288 - val_loss: 0.6268 - val_acc: 0.6443\n",
            "Epoch 445/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6314 - acc: 0.5193 - val_loss: 0.6270 - val_acc: 0.4636\n",
            "Epoch 446/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6316 - acc: 0.5004 - val_loss: 0.6275 - val_acc: 0.3061\n",
            "Epoch 447/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6322 - acc: 0.4756 - val_loss: 0.6269 - val_acc: 0.5743\n",
            "Epoch 448/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6323 - acc: 0.4865 - val_loss: 0.6272 - val_acc: 0.3703\n",
            "Epoch 449/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6324 - acc: 0.5047 - val_loss: 0.6266 - val_acc: 0.6735\n",
            "Epoch 450/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.6312 - acc: 0.5573 - val_loss: 0.6265 - val_acc: 0.6939\n",
            "Epoch 451/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6316 - acc: 0.5507 - val_loss: 0.6266 - val_acc: 0.6239\n",
            "Epoch 452/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6306 - acc: 0.5171 - val_loss: 0.6266 - val_acc: 0.6356\n",
            "Epoch 453/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6313 - acc: 0.5470 - val_loss: 0.6263 - val_acc: 0.6997\n",
            "Epoch 454/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6319 - acc: 0.5733 - val_loss: 0.6262 - val_acc: 0.6997\n",
            "Epoch 455/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6297 - acc: 0.5974 - val_loss: 0.6262 - val_acc: 0.6939\n",
            "Epoch 456/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6311 - acc: 0.5047 - val_loss: 0.6266 - val_acc: 0.4840\n",
            "Epoch 457/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6318 - acc: 0.4748 - val_loss: 0.6270 - val_acc: 0.3353\n",
            "Epoch 458/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6317 - acc: 0.4909 - val_loss: 0.6264 - val_acc: 0.5773\n",
            "Epoch 459/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6311 - acc: 0.5150 - val_loss: 0.6266 - val_acc: 0.4548\n",
            "Epoch 460/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6312 - acc: 0.5069 - val_loss: 0.6265 - val_acc: 0.4723\n",
            "Epoch 461/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6310 - acc: 0.5500 - val_loss: 0.6260 - val_acc: 0.5773\n",
            "Epoch 462/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6297 - acc: 0.5806 - val_loss: 0.6255 - val_acc: 0.6443\n",
            "Epoch 463/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6300 - acc: 0.5755 - val_loss: 0.6259 - val_acc: 0.5481\n",
            "Epoch 464/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6302 - acc: 0.4836 - val_loss: 0.6260 - val_acc: 0.4169\n",
            "Epoch 465/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6309 - acc: 0.5346 - val_loss: 0.6248 - val_acc: 0.6152\n",
            "Epoch 466/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6314 - acc: 0.5966 - val_loss: 0.6245 - val_acc: 0.6501\n",
            "Epoch 467/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6311 - acc: 0.5135 - val_loss: 0.6251 - val_acc: 0.5627\n",
            "Epoch 468/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6301 - acc: 0.5507 - val_loss: 0.6244 - val_acc: 0.6006\n",
            "Epoch 469/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6308 - acc: 0.5894 - val_loss: 0.6233 - val_acc: 0.6297\n",
            "Epoch 470/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6311 - acc: 0.5449 - val_loss: 0.6241 - val_acc: 0.5510\n",
            "Epoch 471/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6285 - acc: 0.5850 - val_loss: 0.6224 - val_acc: 0.5423\n",
            "Epoch 472/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.6266 - acc: 0.5711 - val_loss: 0.6183 - val_acc: 0.6181\n",
            "Epoch 473/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6278 - acc: 0.5434 - val_loss: 0.6144 - val_acc: 0.6210\n",
            "Epoch 474/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6245 - acc: 0.5580 - val_loss: 0.6243 - val_acc: 0.3703\n",
            "Epoch 475/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6220 - acc: 0.5449 - val_loss: 0.6120 - val_acc: 0.5190\n",
            "Epoch 476/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6245 - acc: 0.5536 - val_loss: 0.6089 - val_acc: 0.6210\n",
            "Epoch 476: early stopping\n",
            "27/27 [==============================] - 2s 35ms/step - loss: 0.5788 - acc: 0.6834\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 7s 119ms/step - loss: 0.6478 - acc: 0.4551 - val_loss: 0.6335 - val_acc: 0.5131\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6307 - acc: 0.5866 - val_loss: 0.6283 - val_acc: 0.4869\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6303 - acc: 0.5376 - val_loss: 0.6225 - val_acc: 0.5394\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6156 - acc: 0.5646 - val_loss: 0.6209 - val_acc: 0.5394\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6127 - acc: 0.5551 - val_loss: 0.6276 - val_acc: 0.6122\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.6167 - acc: 0.5632 - val_loss: 0.6159 - val_acc: 0.5656\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6109 - acc: 0.5661 - val_loss: 0.6154 - val_acc: 0.5656\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6069 - acc: 0.5727 - val_loss: 0.6169 - val_acc: 0.6210\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6107 - acc: 0.5858 - val_loss: 0.6165 - val_acc: 0.5977\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6133 - acc: 0.5727 - val_loss: 0.6165 - val_acc: 0.5598\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6076 - acc: 0.5632 - val_loss: 0.6142 - val_acc: 0.5918\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6095 - acc: 0.5909 - val_loss: 0.6128 - val_acc: 0.5918\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6067 - acc: 0.5829 - val_loss: 0.6164 - val_acc: 0.5569\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6063 - acc: 0.5807 - val_loss: 0.6140 - val_acc: 0.5802\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6130 - acc: 0.5800 - val_loss: 0.6151 - val_acc: 0.6064\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6071 - acc: 0.5720 - val_loss: 0.6151 - val_acc: 0.5714\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6048 - acc: 0.5698 - val_loss: 0.6222 - val_acc: 0.4927\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6034 - acc: 0.5720 - val_loss: 0.6128 - val_acc: 0.5860\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6037 - acc: 0.5909 - val_loss: 0.6140 - val_acc: 0.5889\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.6067 - acc: 0.5895 - val_loss: 0.6147 - val_acc: 0.5918\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6013 - acc: 0.5705 - val_loss: 0.6160 - val_acc: 0.5539\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6048 - acc: 0.5851 - val_loss: 0.6166 - val_acc: 0.5452\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6034 - acc: 0.5961 - val_loss: 0.6140 - val_acc: 0.6122\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6063 - acc: 0.5734 - val_loss: 0.6210 - val_acc: 0.6472\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6049 - acc: 0.5968 - val_loss: 0.6159 - val_acc: 0.5773\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5992 - acc: 0.5595 - val_loss: 0.6216 - val_acc: 0.6093\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.6050 - acc: 0.5654 - val_loss: 0.6128 - val_acc: 0.6035\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5975 - acc: 0.5698 - val_loss: 0.6136 - val_acc: 0.5860\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5954 - acc: 0.5785 - val_loss: 0.6258 - val_acc: 0.5160\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5979 - acc: 0.5873 - val_loss: 0.6125 - val_acc: 0.5831\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5984 - acc: 0.5763 - val_loss: 0.6098 - val_acc: 0.5860\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5977 - acc: 0.6026 - val_loss: 0.6270 - val_acc: 0.4956\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6046 - acc: 0.5778 - val_loss: 0.6171 - val_acc: 0.5627\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5977 - acc: 0.5734 - val_loss: 0.6133 - val_acc: 0.6035\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.6042 - acc: 0.6012 - val_loss: 0.6181 - val_acc: 0.5802\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5994 - acc: 0.5756 - val_loss: 0.6157 - val_acc: 0.5598\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5961 - acc: 0.5844 - val_loss: 0.6135 - val_acc: 0.5627\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5937 - acc: 0.5909 - val_loss: 0.6167 - val_acc: 0.5627\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5977 - acc: 0.5668 - val_loss: 0.6115 - val_acc: 0.5656\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5963 - acc: 0.5961 - val_loss: 0.6120 - val_acc: 0.5948\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6011 - acc: 0.5778 - val_loss: 0.6090 - val_acc: 0.5714\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.6006 - acc: 0.5778 - val_loss: 0.6170 - val_acc: 0.6210\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5906 - acc: 0.6012 - val_loss: 0.6463 - val_acc: 0.4869\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6067 - acc: 0.5829 - val_loss: 0.6171 - val_acc: 0.5656\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5998 - acc: 0.5676 - val_loss: 0.6142 - val_acc: 0.5714\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6012 - acc: 0.5763 - val_loss: 0.6261 - val_acc: 0.4752\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5961 - acc: 0.5632 - val_loss: 0.6134 - val_acc: 0.5860\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5946 - acc: 0.5515 - val_loss: 0.6187 - val_acc: 0.5394\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.6000 - acc: 0.5785 - val_loss: 0.6249 - val_acc: 0.4752\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5968 - acc: 0.5866 - val_loss: 0.6105 - val_acc: 0.5569\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5931 - acc: 0.5771 - val_loss: 0.6127 - val_acc: 0.6122\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5941 - acc: 0.6012 - val_loss: 0.6119 - val_acc: 0.5918\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5959 - acc: 0.6012 - val_loss: 0.6190 - val_acc: 0.5394\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5997 - acc: 0.5500 - val_loss: 0.6191 - val_acc: 0.5889\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5998 - acc: 0.5690 - val_loss: 0.6149 - val_acc: 0.5277\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5945 - acc: 0.5953 - val_loss: 0.6047 - val_acc: 0.6356\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5890 - acc: 0.6581 - val_loss: 0.6279 - val_acc: 0.4985\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5924 - acc: 0.6508 - val_loss: 0.6262 - val_acc: 0.6735\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.6213 - acc: 0.5844 - val_loss: 0.6215 - val_acc: 0.6239\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6052 - acc: 0.5749 - val_loss: 0.6178 - val_acc: 0.5481\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6053 - acc: 0.5478 - val_loss: 0.6170 - val_acc: 0.5539\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5961 - acc: 0.6472 - val_loss: 0.6219 - val_acc: 0.5802\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5957 - acc: 0.5968 - val_loss: 0.6359 - val_acc: 0.4810\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6043 - acc: 0.6136 - val_loss: 0.6171 - val_acc: 0.5773\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5988 - acc: 0.5661 - val_loss: 0.6161 - val_acc: 0.5627\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5882 - acc: 0.5873 - val_loss: 0.6197 - val_acc: 0.6501\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.6025 - acc: 0.5997 - val_loss: 0.6200 - val_acc: 0.5423\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6064 - acc: 0.5902 - val_loss: 0.6200 - val_acc: 0.5364\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6054 - acc: 0.5720 - val_loss: 0.6227 - val_acc: 0.5598\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6011 - acc: 0.5617 - val_loss: 0.6238 - val_acc: 0.6006\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5952 - acc: 0.5771 - val_loss: 0.6190 - val_acc: 0.5569\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5980 - acc: 0.5632 - val_loss: 0.6226 - val_acc: 0.5948\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.6015 - acc: 0.5581 - val_loss: 0.6177 - val_acc: 0.6181\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.6006 - acc: 0.5873 - val_loss: 0.6179 - val_acc: 0.5685\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5983 - acc: 0.5917 - val_loss: 0.6143 - val_acc: 0.5860\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5949 - acc: 0.5741 - val_loss: 0.6153 - val_acc: 0.5977\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5953 - acc: 0.5814 - val_loss: 0.6167 - val_acc: 0.5773\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5949 - acc: 0.5741 - val_loss: 0.6147 - val_acc: 0.5685\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5892 - acc: 0.5778 - val_loss: 0.6202 - val_acc: 0.5452\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5927 - acc: 0.5895 - val_loss: 0.6147 - val_acc: 0.5889\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5919 - acc: 0.5676 - val_loss: 0.6124 - val_acc: 0.6035\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5924 - acc: 0.5712 - val_loss: 0.6186 - val_acc: 0.5743\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5946 - acc: 0.6070 - val_loss: 0.6148 - val_acc: 0.5598\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5916 - acc: 0.5793 - val_loss: 0.6162 - val_acc: 0.5889\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5957 - acc: 0.5544 - val_loss: 0.6137 - val_acc: 0.6064\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5855 - acc: 0.6209 - val_loss: 0.6155 - val_acc: 0.6006\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5952 - acc: 0.6129 - val_loss: 0.6203 - val_acc: 0.4840\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.6029 - acc: 0.5690 - val_loss: 0.6213 - val_acc: 0.5131\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5926 - acc: 0.5690 - val_loss: 0.6164 - val_acc: 0.5773\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5877 - acc: 0.5712 - val_loss: 0.6124 - val_acc: 0.6035\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5891 - acc: 0.5741 - val_loss: 0.6116 - val_acc: 0.5889\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5898 - acc: 0.6034 - val_loss: 0.6137 - val_acc: 0.5481\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5902 - acc: 0.5822 - val_loss: 0.6114 - val_acc: 0.6064\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5850 - acc: 0.5880 - val_loss: 0.6073 - val_acc: 0.5860\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5885 - acc: 0.5836 - val_loss: 0.6122 - val_acc: 0.5773\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5859 - acc: 0.6048 - val_loss: 0.6099 - val_acc: 0.6006\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5845 - acc: 0.6070 - val_loss: 0.6156 - val_acc: 0.6297\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5906 - acc: 0.6070 - val_loss: 0.6090 - val_acc: 0.6210\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5885 - acc: 0.6077 - val_loss: 0.6102 - val_acc: 0.6064\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5877 - acc: 0.5982 - val_loss: 0.6088 - val_acc: 0.6006\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5869 - acc: 0.6056 - val_loss: 0.6124 - val_acc: 0.6414\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5975 - acc: 0.5961 - val_loss: 0.6165 - val_acc: 0.5685\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5893 - acc: 0.5997 - val_loss: 0.6222 - val_acc: 0.6443\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5988 - acc: 0.5982 - val_loss: 0.6130 - val_acc: 0.6006\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5903 - acc: 0.5931 - val_loss: 0.6118 - val_acc: 0.5831\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5847 - acc: 0.6004 - val_loss: 0.6161 - val_acc: 0.5802\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5891 - acc: 0.5939 - val_loss: 0.6191 - val_acc: 0.5481\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5818 - acc: 0.6063 - val_loss: 0.6209 - val_acc: 0.6385\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6003 - acc: 0.5822 - val_loss: 0.6214 - val_acc: 0.5802\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5889 - acc: 0.5654 - val_loss: 0.6210 - val_acc: 0.5948\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5873 - acc: 0.5858 - val_loss: 0.6217 - val_acc: 0.6035\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5858 - acc: 0.6041 - val_loss: 0.6192 - val_acc: 0.5889\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5877 - acc: 0.6107 - val_loss: 0.6239 - val_acc: 0.5656\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5863 - acc: 0.6333 - val_loss: 0.6207 - val_acc: 0.5918\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5955 - acc: 0.5939 - val_loss: 0.6163 - val_acc: 0.5627\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5893 - acc: 0.5785 - val_loss: 0.6092 - val_acc: 0.5714\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5840 - acc: 0.5800 - val_loss: 0.6108 - val_acc: 0.5889\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 2s 99ms/step - loss: 0.5792 - acc: 0.6224 - val_loss: 0.6320 - val_acc: 0.5889\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5938 - acc: 0.6121 - val_loss: 0.6140 - val_acc: 0.5656\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5838 - acc: 0.5990 - val_loss: 0.6176 - val_acc: 0.6472\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5891 - acc: 0.6406 - val_loss: 0.6127 - val_acc: 0.5773\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5817 - acc: 0.5975 - val_loss: 0.6321 - val_acc: 0.5977\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6006 - acc: 0.5829 - val_loss: 0.6115 - val_acc: 0.5948\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5959 - acc: 0.5895 - val_loss: 0.6114 - val_acc: 0.5977\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5942 - acc: 0.5917 - val_loss: 0.6183 - val_acc: 0.5860\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5931 - acc: 0.5683 - val_loss: 0.6148 - val_acc: 0.5802\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5859 - acc: 0.5909 - val_loss: 0.6159 - val_acc: 0.5860\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5838 - acc: 0.6048 - val_loss: 0.6124 - val_acc: 0.5918\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5848 - acc: 0.5982 - val_loss: 0.6176 - val_acc: 0.5802\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5944 - acc: 0.5785 - val_loss: 0.6211 - val_acc: 0.5423\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5866 - acc: 0.6114 - val_loss: 0.6138 - val_acc: 0.5977\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5830 - acc: 0.6121 - val_loss: 0.6122 - val_acc: 0.6064\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5822 - acc: 0.6070 - val_loss: 0.6200 - val_acc: 0.5685\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5817 - acc: 0.6362 - val_loss: 0.6206 - val_acc: 0.5481\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5872 - acc: 0.5990 - val_loss: 0.6180 - val_acc: 0.5598\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5850 - acc: 0.5822 - val_loss: 0.6114 - val_acc: 0.5918\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5834 - acc: 0.6260 - val_loss: 0.6156 - val_acc: 0.5598\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5810 - acc: 0.5793 - val_loss: 0.6137 - val_acc: 0.6006\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5750 - acc: 0.6129 - val_loss: 0.6269 - val_acc: 0.5569\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 0.6005 - acc: 0.5902 - val_loss: 0.6179 - val_acc: 0.5656\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5968 - acc: 0.5646 - val_loss: 0.6198 - val_acc: 0.5831\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5906 - acc: 0.5756 - val_loss: 0.6106 - val_acc: 0.5773\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5870 - acc: 0.5953 - val_loss: 0.6175 - val_acc: 0.5860\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5908 - acc: 0.6209 - val_loss: 0.6244 - val_acc: 0.5918\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5955 - acc: 0.6231 - val_loss: 0.6181 - val_acc: 0.6006\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5903 - acc: 0.5953 - val_loss: 0.6238 - val_acc: 0.5627\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5896 - acc: 0.6004 - val_loss: 0.6208 - val_acc: 0.5860\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5851 - acc: 0.6107 - val_loss: 0.6208 - val_acc: 0.6006\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5909 - acc: 0.6041 - val_loss: 0.6224 - val_acc: 0.5598\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5913 - acc: 0.6150 - val_loss: 0.6120 - val_acc: 0.5889\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5871 - acc: 0.5975 - val_loss: 0.6204 - val_acc: 0.5743\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5867 - acc: 0.6077 - val_loss: 0.6502 - val_acc: 0.5918\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5923 - acc: 0.6399 - val_loss: 0.6261 - val_acc: 0.6647\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5988 - acc: 0.6150 - val_loss: 0.6195 - val_acc: 0.5510\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5824 - acc: 0.5603 - val_loss: 0.6188 - val_acc: 0.6239\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5886 - acc: 0.5851 - val_loss: 0.6222 - val_acc: 0.5598\n",
            "Epoch 156: early stopping\n",
            "27/27 [==============================] - 2s 35ms/step - loss: 0.6056 - acc: 0.7156\n",
            "batch : 64, unit: [64, 32], dropout: 0.4, avg_accuracy: 0.7015454769134521, activation: softmax\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 6s 137ms/step - loss: 0.6335 - acc: 0.6681 - val_loss: 0.5979 - val_acc: 0.6997\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6132 - acc: 0.6637 - val_loss: 0.5920 - val_acc: 0.6968\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6092 - acc: 0.6667 - val_loss: 0.5778 - val_acc: 0.7055\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6054 - acc: 0.6616 - val_loss: 0.5792 - val_acc: 0.7055\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6032 - acc: 0.6754 - val_loss: 0.5706 - val_acc: 0.6997\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6013 - acc: 0.6630 - val_loss: 0.5705 - val_acc: 0.7114\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5930 - acc: 0.6725 - val_loss: 0.6227 - val_acc: 0.6589\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6104 - acc: 0.6608 - val_loss: 0.5712 - val_acc: 0.7114\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5941 - acc: 0.6732 - val_loss: 0.5803 - val_acc: 0.7055\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6009 - acc: 0.6791 - val_loss: 0.5731 - val_acc: 0.6997\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5923 - acc: 0.6747 - val_loss: 0.5706 - val_acc: 0.7085\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5933 - acc: 0.6667 - val_loss: 0.5744 - val_acc: 0.7114\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.5940 - acc: 0.6732 - val_loss: 0.5619 - val_acc: 0.7114\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5999 - acc: 0.6645 - val_loss: 0.5625 - val_acc: 0.7114\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5915 - acc: 0.6740 - val_loss: 0.5622 - val_acc: 0.6997\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.5945 - acc: 0.6783 - val_loss: 0.5647 - val_acc: 0.7259\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5954 - acc: 0.6681 - val_loss: 0.5776 - val_acc: 0.7259\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5937 - acc: 0.6725 - val_loss: 0.6129 - val_acc: 0.6764\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.6024 - acc: 0.6616 - val_loss: 0.5752 - val_acc: 0.7026\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5961 - acc: 0.6776 - val_loss: 0.5629 - val_acc: 0.7026\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5946 - acc: 0.6798 - val_loss: 0.5588 - val_acc: 0.7055\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5966 - acc: 0.6718 - val_loss: 0.5621 - val_acc: 0.7026\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6015 - acc: 0.6543 - val_loss: 0.5732 - val_acc: 0.6997\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.5955 - acc: 0.6689 - val_loss: 0.5709 - val_acc: 0.7055\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5954 - acc: 0.6710 - val_loss: 0.5855 - val_acc: 0.7172\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5891 - acc: 0.6827 - val_loss: 0.5583 - val_acc: 0.7114\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5928 - acc: 0.6849 - val_loss: 0.5760 - val_acc: 0.7055\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5924 - acc: 0.6747 - val_loss: 0.5660 - val_acc: 0.7085\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5944 - acc: 0.6754 - val_loss: 0.5594 - val_acc: 0.7026\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5881 - acc: 0.6769 - val_loss: 0.5644 - val_acc: 0.7143\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5892 - acc: 0.6813 - val_loss: 0.5655 - val_acc: 0.7259\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.6073 - acc: 0.6783 - val_loss: 0.6021 - val_acc: 0.6997\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6175 - acc: 0.6550 - val_loss: 0.5841 - val_acc: 0.6997\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6078 - acc: 0.6696 - val_loss: 0.5953 - val_acc: 0.6560\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6148 - acc: 0.6667 - val_loss: 0.5823 - val_acc: 0.6997\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6002 - acc: 0.6718 - val_loss: 0.5784 - val_acc: 0.7055\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.6007 - acc: 0.6696 - val_loss: 0.5712 - val_acc: 0.6997\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.6022 - acc: 0.6718 - val_loss: 0.5665 - val_acc: 0.6997\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5915 - acc: 0.6696 - val_loss: 0.5942 - val_acc: 0.6735\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5962 - acc: 0.6703 - val_loss: 0.5548 - val_acc: 0.7201\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5943 - acc: 0.6900 - val_loss: 0.5867 - val_acc: 0.6939\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5986 - acc: 0.6616 - val_loss: 0.5725 - val_acc: 0.7055\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5986 - acc: 0.6798 - val_loss: 0.5753 - val_acc: 0.7143\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5944 - acc: 0.6740 - val_loss: 0.5534 - val_acc: 0.7114\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6005 - acc: 0.6856 - val_loss: 0.5629 - val_acc: 0.7172\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5860 - acc: 0.6827 - val_loss: 0.5576 - val_acc: 0.7085\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5926 - acc: 0.6543 - val_loss: 0.5638 - val_acc: 0.7055\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5891 - acc: 0.6740 - val_loss: 0.5621 - val_acc: 0.7143\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5911 - acc: 0.6798 - val_loss: 0.5597 - val_acc: 0.7143\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5926 - acc: 0.6878 - val_loss: 0.5612 - val_acc: 0.7114\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5923 - acc: 0.6732 - val_loss: 0.5598 - val_acc: 0.7085\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5837 - acc: 0.6856 - val_loss: 0.5605 - val_acc: 0.7026\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5904 - acc: 0.6827 - val_loss: 0.5654 - val_acc: 0.6997\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5883 - acc: 0.6732 - val_loss: 0.5536 - val_acc: 0.7085\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.5868 - acc: 0.6813 - val_loss: 0.5576 - val_acc: 0.6997\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6020 - acc: 0.6791 - val_loss: 0.5828 - val_acc: 0.6997\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.6022 - acc: 0.6740 - val_loss: 0.5648 - val_acc: 0.7172\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5943 - acc: 0.6878 - val_loss: 0.5570 - val_acc: 0.7143\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5891 - acc: 0.6798 - val_loss: 0.5529 - val_acc: 0.7289\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5928 - acc: 0.6761 - val_loss: 0.5894 - val_acc: 0.6647\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5819 - acc: 0.6718 - val_loss: 0.5878 - val_acc: 0.6997\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.6094 - acc: 0.6769 - val_loss: 0.5728 - val_acc: 0.7143\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5883 - acc: 0.6907 - val_loss: 0.5657 - val_acc: 0.6968\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5912 - acc: 0.6849 - val_loss: 0.5750 - val_acc: 0.6997\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5954 - acc: 0.6659 - val_loss: 0.5728 - val_acc: 0.7172\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5949 - acc: 0.6820 - val_loss: 0.5712 - val_acc: 0.7055\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5859 - acc: 0.6973 - val_loss: 0.5651 - val_acc: 0.7201\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5914 - acc: 0.6783 - val_loss: 0.5618 - val_acc: 0.7347\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.5902 - acc: 0.6878 - val_loss: 0.5798 - val_acc: 0.7318\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.5859 - acc: 0.6864 - val_loss: 0.5700 - val_acc: 0.6997\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5926 - acc: 0.6718 - val_loss: 0.5702 - val_acc: 0.7085\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5884 - acc: 0.6761 - val_loss: 0.5707 - val_acc: 0.7230\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.5920 - acc: 0.6725 - val_loss: 0.5830 - val_acc: 0.6939\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 2s 92ms/step - loss: 0.5889 - acc: 0.6798 - val_loss: 0.5699 - val_acc: 0.7026\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5828 - acc: 0.6900 - val_loss: 0.5673 - val_acc: 0.7289\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5887 - acc: 0.6754 - val_loss: 0.5676 - val_acc: 0.6997\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 2s 102ms/step - loss: 0.5984 - acc: 0.6681 - val_loss: 0.5650 - val_acc: 0.7026\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5892 - acc: 0.6813 - val_loss: 0.5667 - val_acc: 0.7172\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5866 - acc: 0.6813 - val_loss: 0.5665 - val_acc: 0.7172\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5888 - acc: 0.6732 - val_loss: 0.5597 - val_acc: 0.7259\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5923 - acc: 0.6740 - val_loss: 0.5641 - val_acc: 0.7259\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6038 - acc: 0.6740 - val_loss: 0.5634 - val_acc: 0.7143\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6017 - acc: 0.6710 - val_loss: 0.5815 - val_acc: 0.7055\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5931 - acc: 0.6732 - val_loss: 0.5717 - val_acc: 0.7085\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5871 - acc: 0.6856 - val_loss: 0.5608 - val_acc: 0.6997\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.5885 - acc: 0.6776 - val_loss: 0.5822 - val_acc: 0.6939\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.5925 - acc: 0.6805 - val_loss: 0.5621 - val_acc: 0.7143\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5855 - acc: 0.6885 - val_loss: 0.5591 - val_acc: 0.7172\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.5908 - acc: 0.6681 - val_loss: 0.5588 - val_acc: 0.7114\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5862 - acc: 0.6849 - val_loss: 0.5824 - val_acc: 0.7026\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.5919 - acc: 0.6871 - val_loss: 0.5631 - val_acc: 0.7201\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.5865 - acc: 0.6791 - val_loss: 0.5651 - val_acc: 0.7201\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5864 - acc: 0.6834 - val_loss: 0.5575 - val_acc: 0.7172\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5859 - acc: 0.6754 - val_loss: 0.5570 - val_acc: 0.7085\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.5831 - acc: 0.6856 - val_loss: 0.5555 - val_acc: 0.7201\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5861 - acc: 0.6871 - val_loss: 0.5563 - val_acc: 0.7289\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5851 - acc: 0.6791 - val_loss: 0.5644 - val_acc: 0.7172\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 0.5830 - acc: 0.6966 - val_loss: 0.5443 - val_acc: 0.7405\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.5835 - acc: 0.6915 - val_loss: 0.5511 - val_acc: 0.7405\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 0.5773 - acc: 0.6915 - val_loss: 0.5959 - val_acc: 0.6589\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.5923 - acc: 0.6667 - val_loss: 0.5497 - val_acc: 0.7289\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5881 - acc: 0.6747 - val_loss: 0.5651 - val_acc: 0.7114\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 2s 80ms/step - loss: 0.5882 - acc: 0.6915 - val_loss: 0.5567 - val_acc: 0.7230\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.5818 - acc: 0.6871 - val_loss: 0.5568 - val_acc: 0.7230\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.5880 - acc: 0.6798 - val_loss: 0.5630 - val_acc: 0.6997\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5839 - acc: 0.6761 - val_loss: 0.5560 - val_acc: 0.7085\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 0.5845 - acc: 0.6864 - val_loss: 0.5577 - val_acc: 0.7114\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5949 - acc: 0.6907 - val_loss: 0.5613 - val_acc: 0.7114\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 2s 89ms/step - loss: 0.6282 - acc: 0.6441 - val_loss: 0.5829 - val_acc: 0.6968\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 0.6037 - acc: 0.6667 - val_loss: 0.5795 - val_acc: 0.7114\n",
            "Epoch 111/1000\n",
            " 9/22 [===========>..................] - ETA: 0s - loss: 0.5945 - acc: 0.6684"
          ]
        }
      ],
      "source": [
        "#cross validation\n",
        "X_train, X_test, Y_train, Y_test = splitData(x,y)\n",
        "x_split, y_split = splitDataCrossVal(X_train, Y_train)\n",
        "print(len(x_split))\n",
        "\n",
        "f = open('/content/drive/MyDrive/23_1_인지프/models/performance.txt', 'a')\n",
        "batchs = [128, 64]\n",
        "units = [[64, 32]]\n",
        "dropouts = [0.4, 0.2]\n",
        "epochs = [1000]\n",
        "activations = ['sigmoid', 'softmax']\n",
        "class_names = ['GRU']\n",
        "\n",
        "for class_name in class_names:\n",
        "  for batch in batchs:\n",
        "    for epoch in epochs:\n",
        "      for unit in units:\n",
        "        for dropout in dropouts:\n",
        "          for output_unit, activation in enumerate(activations):\n",
        "            accuracy_cross_val = []\n",
        "            for i in range(len(x_split)):\n",
        "              x_train, x_test, y_train, y_test = cvsplitData(x_split, y_split, i)\n",
        "              x_train = pad_sequences(x_train, dtype='float32')\n",
        "              x_test = pad_sequences(x_test, dtype='float32')\n",
        "              x_train = np.nan_to_num(x_train, nan=0)\n",
        "              x_test = np.nan_to_num(x_test, nan=0)\n",
        "              if (output_unit+1)==1:\n",
        "                y_train = np.array([i[0] for i in y_train])\n",
        "                y_test = np.array([i[0] for i in y_test])\n",
        "              model,es,mc = makeModel(class_name, unit, dropout, output_unit+1, activation)\n",
        "              history=model.fit(x_train, y_train, epochs=epoch, batch_size=batch, validation_split=0.2, callbacks=[es, mc])\n",
        "              model=load_model('best_model.h5')\n",
        "              loss, accuracy = model.evaluate(x_test, y_test)\n",
        "              accuracy_cross_val.append(accuracy)\n",
        "            print(\"########################################################\")\n",
        "            print(\"class_name: {}, batch: {}, unit: {}, dropout: {}, avg_accuracy: {}, activation: {}\".format(class_name, batch, unit, dropout, sum(accuracy_cross_val)/len(accuracy_cross_val), activation))\n",
        "            print(\"########################################################\")\n",
        "            f.write(\"class_name: {}, batch: {}, unit: {}, dropout: {}, avg_accuracy: {}, activation: {}\\n\".format(class_name, batch, unit, dropout, sum(accuracy_cross_val)/len(accuracy_cross_val), activation))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cv library -> 사용 안 함"
      ],
      "metadata": {
        "id": "cjpltSb0Bfk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from sklearn.model_selection import cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "batch = 32\n",
        "epoch = 2000\n",
        "X_train, X_test, Y_train, Y_test = splitData(x,y)\n",
        "\n",
        "#model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(32, input_shape=(1248,6), return_sequences=False))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True)\n",
        "model = KerasClassifier(build_fn=create_model, epochs=epoch, batch_size = batch, validation_split=0.2, callbacks=[es, mc])\n",
        "score = cross_val_score(model, X_train, Y_train, cv=3)\n",
        "print('cv score: ', score)\n",
        "print('cv avg: ', score.mean())'''"
      ],
      "metadata": {
        "id": "Z1zQIIFkBikg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ae898f-63af-4fd8-b440-5e22779a5efb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-81fb119dfedf>:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=epoch, batch_size = batch, validation_split=0.2, callbacks=[es, mc])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# best model with full data"
      ],
      "metadata": {
        "id": "2NNokEjQGwcT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1ggUcnKi0vYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe073f9-71d9-4cca-d1d1-fd07721baa6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "17/17 [==============================] - 4s 95ms/step - loss: 0.6408 - acc: 0.6625 - val_loss: 0.6375 - val_acc: 0.6654\n",
            "Epoch 2/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.6368 - acc: 0.6732 - val_loss: 0.6295 - val_acc: 0.6654\n",
            "Epoch 3/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.6261 - acc: 0.6732 - val_loss: 0.6260 - val_acc: 0.6654\n",
            "Epoch 4/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.6214 - acc: 0.6732 - val_loss: 0.6214 - val_acc: 0.6654\n",
            "Epoch 5/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6152 - acc: 0.6727 - val_loss: 0.6148 - val_acc: 0.6654\n",
            "Epoch 6/2000\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.6049 - acc: 0.6707 - val_loss: 0.6187 - val_acc: 0.6576\n",
            "Epoch 7/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6020 - acc: 0.6741 - val_loss: 0.6148 - val_acc: 0.6634\n",
            "Epoch 8/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6064 - acc: 0.6683 - val_loss: 0.6152 - val_acc: 0.6654\n",
            "Epoch 9/2000\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.6022 - acc: 0.6712 - val_loss: 0.6171 - val_acc: 0.6654\n",
            "Epoch 10/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6023 - acc: 0.6780 - val_loss: 0.6170 - val_acc: 0.6634\n",
            "Epoch 11/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5997 - acc: 0.6741 - val_loss: 0.6134 - val_acc: 0.6654\n",
            "Epoch 12/2000\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.5994 - acc: 0.6727 - val_loss: 0.6145 - val_acc: 0.6654\n",
            "Epoch 13/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6025 - acc: 0.6712 - val_loss: 0.6195 - val_acc: 0.6654\n",
            "Epoch 14/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6060 - acc: 0.6746 - val_loss: 0.6119 - val_acc: 0.6654\n",
            "Epoch 15/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5997 - acc: 0.6732 - val_loss: 0.6140 - val_acc: 0.6654\n",
            "Epoch 16/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6025 - acc: 0.6722 - val_loss: 0.6139 - val_acc: 0.6654\n",
            "Epoch 17/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5993 - acc: 0.6746 - val_loss: 0.6139 - val_acc: 0.6654\n",
            "Epoch 18/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6040 - acc: 0.6717 - val_loss: 0.6135 - val_acc: 0.6654\n",
            "Epoch 19/2000\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.6007 - acc: 0.6736 - val_loss: 0.6157 - val_acc: 0.6654\n",
            "Epoch 20/2000\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.6044 - acc: 0.6736 - val_loss: 0.6116 - val_acc: 0.6654\n",
            "Epoch 21/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.6010 - acc: 0.6732 - val_loss: 0.6162 - val_acc: 0.6634\n",
            "Epoch 22/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.6023 - acc: 0.6746 - val_loss: 0.6111 - val_acc: 0.6654\n",
            "Epoch 23/2000\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.5944 - acc: 0.6766 - val_loss: 0.6123 - val_acc: 0.6654\n",
            "Epoch 24/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5979 - acc: 0.6736 - val_loss: 0.6137 - val_acc: 0.6654\n",
            "Epoch 25/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5963 - acc: 0.6736 - val_loss: 0.6159 - val_acc: 0.6654\n",
            "Epoch 26/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.6021 - acc: 0.6770 - val_loss: 0.6181 - val_acc: 0.6654\n",
            "Epoch 27/2000\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.5981 - acc: 0.6712 - val_loss: 0.6160 - val_acc: 0.6654\n",
            "Epoch 28/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.6037 - acc: 0.6722 - val_loss: 0.6121 - val_acc: 0.6654\n",
            "Epoch 29/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5990 - acc: 0.6736 - val_loss: 0.6134 - val_acc: 0.6654\n",
            "Epoch 30/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6074 - acc: 0.6727 - val_loss: 0.6120 - val_acc: 0.6654\n",
            "Epoch 31/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5993 - acc: 0.6736 - val_loss: 0.6125 - val_acc: 0.6654\n",
            "Epoch 32/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5936 - acc: 0.6736 - val_loss: 0.6121 - val_acc: 0.6654\n",
            "Epoch 33/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5982 - acc: 0.6824 - val_loss: 0.6118 - val_acc: 0.6673\n",
            "Epoch 34/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5945 - acc: 0.6697 - val_loss: 0.6097 - val_acc: 0.6751\n",
            "Epoch 35/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5974 - acc: 0.6756 - val_loss: 0.6094 - val_acc: 0.6673\n",
            "Epoch 36/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5942 - acc: 0.6746 - val_loss: 0.6105 - val_acc: 0.6732\n",
            "Epoch 37/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.6055 - acc: 0.6722 - val_loss: 0.6119 - val_acc: 0.6654\n",
            "Epoch 38/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.5971 - acc: 0.6736 - val_loss: 0.6095 - val_acc: 0.6654\n",
            "Epoch 39/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.5933 - acc: 0.6761 - val_loss: 0.6135 - val_acc: 0.6732\n",
            "Epoch 40/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.5987 - acc: 0.6766 - val_loss: 0.6091 - val_acc: 0.6712\n",
            "Epoch 41/2000\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.5941 - acc: 0.6834 - val_loss: 0.6090 - val_acc: 0.6751\n",
            "Epoch 42/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5929 - acc: 0.6824 - val_loss: 0.6084 - val_acc: 0.6790\n",
            "Epoch 43/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5916 - acc: 0.6770 - val_loss: 0.6138 - val_acc: 0.6654\n",
            "Epoch 44/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5955 - acc: 0.6770 - val_loss: 0.6101 - val_acc: 0.6809\n",
            "Epoch 45/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5949 - acc: 0.6775 - val_loss: 0.6034 - val_acc: 0.6946\n",
            "Epoch 46/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5929 - acc: 0.6814 - val_loss: 0.6072 - val_acc: 0.6693\n",
            "Epoch 47/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5986 - acc: 0.6785 - val_loss: 0.6083 - val_acc: 0.6751\n",
            "Epoch 48/2000\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.5934 - acc: 0.6804 - val_loss: 0.6064 - val_acc: 0.6770\n",
            "Epoch 49/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5939 - acc: 0.6780 - val_loss: 0.6074 - val_acc: 0.6770\n",
            "Epoch 50/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5941 - acc: 0.6848 - val_loss: 0.6065 - val_acc: 0.6790\n",
            "Epoch 51/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5973 - acc: 0.6717 - val_loss: 0.6081 - val_acc: 0.6693\n",
            "Epoch 52/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5947 - acc: 0.6814 - val_loss: 0.6030 - val_acc: 0.6790\n",
            "Epoch 53/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5909 - acc: 0.6858 - val_loss: 0.6064 - val_acc: 0.6693\n",
            "Epoch 54/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5923 - acc: 0.6848 - val_loss: 0.6013 - val_acc: 0.6809\n",
            "Epoch 55/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5933 - acc: 0.6814 - val_loss: 0.6054 - val_acc: 0.6751\n",
            "Epoch 56/2000\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.5918 - acc: 0.6707 - val_loss: 0.6027 - val_acc: 0.6868\n",
            "Epoch 57/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5955 - acc: 0.6843 - val_loss: 0.6067 - val_acc: 0.6887\n",
            "Epoch 58/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5874 - acc: 0.6955 - val_loss: 0.5954 - val_acc: 0.6946\n",
            "Epoch 59/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5965 - acc: 0.6639 - val_loss: 0.6063 - val_acc: 0.6654\n",
            "Epoch 60/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5932 - acc: 0.6761 - val_loss: 0.6054 - val_acc: 0.6732\n",
            "Epoch 61/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5891 - acc: 0.6882 - val_loss: 0.6015 - val_acc: 0.6887\n",
            "Epoch 62/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5921 - acc: 0.6853 - val_loss: 0.6017 - val_acc: 0.6965\n",
            "Epoch 63/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5894 - acc: 0.6877 - val_loss: 0.6000 - val_acc: 0.6887\n",
            "Epoch 64/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5869 - acc: 0.6911 - val_loss: 0.6098 - val_acc: 0.6712\n",
            "Epoch 65/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5946 - acc: 0.6853 - val_loss: 0.5963 - val_acc: 0.7121\n",
            "Epoch 66/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5892 - acc: 0.6931 - val_loss: 0.5955 - val_acc: 0.7004\n",
            "Epoch 67/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5893 - acc: 0.7135 - val_loss: 0.6078 - val_acc: 0.6887\n",
            "Epoch 68/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6115 - acc: 0.6736 - val_loss: 0.6141 - val_acc: 0.6654\n",
            "Epoch 69/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6045 - acc: 0.6736 - val_loss: 0.6126 - val_acc: 0.6654\n",
            "Epoch 70/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6016 - acc: 0.6732 - val_loss: 0.6123 - val_acc: 0.6654\n",
            "Epoch 71/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.6049 - acc: 0.6741 - val_loss: 0.6090 - val_acc: 0.6654\n",
            "Epoch 72/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6022 - acc: 0.6741 - val_loss: 0.6062 - val_acc: 0.6654\n",
            "Epoch 73/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5939 - acc: 0.6756 - val_loss: 0.6093 - val_acc: 0.6751\n",
            "Epoch 74/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5966 - acc: 0.6824 - val_loss: 0.6043 - val_acc: 0.6751\n",
            "Epoch 75/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5923 - acc: 0.6839 - val_loss: 0.6020 - val_acc: 0.6848\n",
            "Epoch 76/2000\n",
            "17/17 [==============================] - 1s 59ms/step - loss: 0.5889 - acc: 0.6950 - val_loss: 0.5963 - val_acc: 0.7179\n",
            "Epoch 77/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5877 - acc: 0.6868 - val_loss: 0.5909 - val_acc: 0.7160\n",
            "Epoch 78/2000\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.5898 - acc: 0.6960 - val_loss: 0.5906 - val_acc: 0.7082\n",
            "Epoch 79/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5874 - acc: 0.6980 - val_loss: 0.6237 - val_acc: 0.6673\n",
            "Epoch 80/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.6014 - acc: 0.6746 - val_loss: 0.6130 - val_acc: 0.6673\n",
            "Epoch 81/2000\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.5999 - acc: 0.6770 - val_loss: 0.6103 - val_acc: 0.6654\n",
            "Epoch 82/2000\n",
            "17/17 [==============================] - 1s 60ms/step - loss: 0.5968 - acc: 0.6732 - val_loss: 0.6093 - val_acc: 0.6654\n",
            "Epoch 83/2000\n",
            "17/17 [==============================] - 1s 59ms/step - loss: 0.6006 - acc: 0.6722 - val_loss: 0.6107 - val_acc: 0.6654\n",
            "Epoch 84/2000\n",
            "17/17 [==============================] - 2s 87ms/step - loss: 0.5967 - acc: 0.6717 - val_loss: 0.6110 - val_acc: 0.6673\n",
            "Epoch 85/2000\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.5934 - acc: 0.6741 - val_loss: 0.6121 - val_acc: 0.6673\n",
            "Epoch 86/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5980 - acc: 0.6775 - val_loss: 0.6140 - val_acc: 0.6673\n",
            "Epoch 87/2000\n",
            "17/17 [==============================] - 1s 86ms/step - loss: 0.5892 - acc: 0.6756 - val_loss: 0.6085 - val_acc: 0.6673\n",
            "Epoch 88/2000\n",
            "17/17 [==============================] - 1s 65ms/step - loss: 0.5949 - acc: 0.6746 - val_loss: 0.6131 - val_acc: 0.6693\n",
            "Epoch 89/2000\n",
            "17/17 [==============================] - 1s 79ms/step - loss: 0.5935 - acc: 0.6800 - val_loss: 0.6114 - val_acc: 0.6673\n",
            "Epoch 90/2000\n",
            "17/17 [==============================] - 2s 104ms/step - loss: 0.5989 - acc: 0.6800 - val_loss: 0.6046 - val_acc: 0.6829\n",
            "Epoch 91/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5811 - acc: 0.6950 - val_loss: 0.6004 - val_acc: 0.6790\n",
            "Epoch 92/2000\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.5856 - acc: 0.6970 - val_loss: 0.5870 - val_acc: 0.7121\n",
            "Epoch 93/2000\n",
            "17/17 [==============================] - 1s 58ms/step - loss: 0.5804 - acc: 0.7091 - val_loss: 0.5879 - val_acc: 0.7101\n",
            "Epoch 94/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.6021 - acc: 0.6741 - val_loss: 0.6123 - val_acc: 0.6654\n",
            "Epoch 95/2000\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.6028 - acc: 0.6717 - val_loss: 0.6123 - val_acc: 0.6654\n",
            "Epoch 96/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5968 - acc: 0.6741 - val_loss: 0.6120 - val_acc: 0.6654\n",
            "Epoch 97/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5953 - acc: 0.6732 - val_loss: 0.6134 - val_acc: 0.6654\n",
            "Epoch 98/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5959 - acc: 0.6761 - val_loss: 0.6159 - val_acc: 0.6654\n",
            "Epoch 99/2000\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.6003 - acc: 0.6746 - val_loss: 0.6107 - val_acc: 0.6654\n",
            "Epoch 100/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5942 - acc: 0.6732 - val_loss: 0.6093 - val_acc: 0.6654\n",
            "Epoch 101/2000\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.5919 - acc: 0.6741 - val_loss: 0.6130 - val_acc: 0.6654\n",
            "Epoch 102/2000\n",
            "17/17 [==============================] - 1s 61ms/step - loss: 0.5933 - acc: 0.6732 - val_loss: 0.6106 - val_acc: 0.6654\n",
            "Epoch 103/2000\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.5937 - acc: 0.6761 - val_loss: 0.6125 - val_acc: 0.6654\n",
            "Epoch 104/2000\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 0.5940 - acc: 0.6756 - val_loss: 0.6119 - val_acc: 0.6654\n",
            "Epoch 105/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5926 - acc: 0.6766 - val_loss: 0.6115 - val_acc: 0.6654\n",
            "Epoch 106/2000\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.5909 - acc: 0.6732 - val_loss: 0.6086 - val_acc: 0.6654\n",
            "Epoch 107/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5943 - acc: 0.6741 - val_loss: 0.6113 - val_acc: 0.6654\n",
            "Epoch 108/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5935 - acc: 0.6766 - val_loss: 0.6128 - val_acc: 0.6654\n",
            "Epoch 109/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5919 - acc: 0.6770 - val_loss: 0.6098 - val_acc: 0.6654\n",
            "Epoch 110/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.6017 - acc: 0.6751 - val_loss: 0.6049 - val_acc: 0.6732\n",
            "Epoch 111/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5952 - acc: 0.6795 - val_loss: 0.5989 - val_acc: 0.6868\n",
            "Epoch 112/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5954 - acc: 0.6916 - val_loss: 0.6293 - val_acc: 0.6595\n",
            "Epoch 113/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5990 - acc: 0.6741 - val_loss: 0.6040 - val_acc: 0.6654\n",
            "Epoch 114/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5925 - acc: 0.6770 - val_loss: 0.6042 - val_acc: 0.6654\n",
            "Epoch 115/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5937 - acc: 0.6790 - val_loss: 0.6033 - val_acc: 0.6654\n",
            "Epoch 116/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5897 - acc: 0.6770 - val_loss: 0.6005 - val_acc: 0.6732\n",
            "Epoch 117/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5926 - acc: 0.6868 - val_loss: 0.5951 - val_acc: 0.7004\n",
            "Epoch 118/2000\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.5895 - acc: 0.6882 - val_loss: 0.5995 - val_acc: 0.6809\n",
            "Epoch 119/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5834 - acc: 0.6921 - val_loss: 0.5976 - val_acc: 0.6965\n",
            "Epoch 120/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5797 - acc: 0.7062 - val_loss: 0.6001 - val_acc: 0.6809\n",
            "Epoch 121/2000\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.5916 - acc: 0.6916 - val_loss: 0.6003 - val_acc: 0.6907\n",
            "Epoch 122/2000\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.5843 - acc: 0.7077 - val_loss: 0.5802 - val_acc: 0.7023\n",
            "Epoch 123/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5745 - acc: 0.7189 - val_loss: 0.5776 - val_acc: 0.7179\n",
            "Epoch 124/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.5797 - acc: 0.7106 - val_loss: 0.6042 - val_acc: 0.6809\n",
            "Epoch 125/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6052 - acc: 0.6756 - val_loss: 0.6095 - val_acc: 0.6654\n",
            "Epoch 126/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5958 - acc: 0.6751 - val_loss: 0.6071 - val_acc: 0.6673\n",
            "Epoch 127/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5928 - acc: 0.6785 - val_loss: 0.6056 - val_acc: 0.6770\n",
            "Epoch 128/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5877 - acc: 0.6984 - val_loss: 0.6009 - val_acc: 0.7101\n",
            "Epoch 129/2000\n",
            "17/17 [==============================] - 1s 42ms/step - loss: 0.5833 - acc: 0.6984 - val_loss: 0.5945 - val_acc: 0.6984\n",
            "Epoch 130/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5804 - acc: 0.6960 - val_loss: 0.5886 - val_acc: 0.7023\n",
            "Epoch 131/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.5853 - acc: 0.6936 - val_loss: 0.5972 - val_acc: 0.6829\n",
            "Epoch 132/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5839 - acc: 0.6970 - val_loss: 0.5932 - val_acc: 0.6907\n",
            "Epoch 133/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6606 - acc: 0.5798 - val_loss: 0.6235 - val_acc: 0.6615\n",
            "Epoch 134/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6274 - acc: 0.6751 - val_loss: 0.6226 - val_acc: 0.6654\n",
            "Epoch 135/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.6138 - acc: 0.6693 - val_loss: 0.6217 - val_acc: 0.6595\n",
            "Epoch 136/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6035 - acc: 0.6688 - val_loss: 0.6088 - val_acc: 0.6595\n",
            "Epoch 137/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6031 - acc: 0.6702 - val_loss: 0.6107 - val_acc: 0.6595\n",
            "Epoch 138/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5991 - acc: 0.6751 - val_loss: 0.6061 - val_acc: 0.6595\n",
            "Epoch 139/2000\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.5978 - acc: 0.6702 - val_loss: 0.6034 - val_acc: 0.6595\n",
            "Epoch 140/2000\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5987 - acc: 0.6736 - val_loss: 0.6010 - val_acc: 0.6615\n",
            "Epoch 141/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.6009 - acc: 0.6722 - val_loss: 0.6128 - val_acc: 0.6634\n",
            "Epoch 142/2000\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5966 - acc: 0.6678 - val_loss: 0.6006 - val_acc: 0.6615\n",
            "Epoch 143/2000\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.5918 - acc: 0.6766 - val_loss: 0.6049 - val_acc: 0.6634\n",
            "Epoch 144/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5908 - acc: 0.6780 - val_loss: 0.6123 - val_acc: 0.6712\n",
            "Epoch 145/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5981 - acc: 0.6848 - val_loss: 0.5942 - val_acc: 0.6829\n",
            "Epoch 146/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5884 - acc: 0.6848 - val_loss: 0.5926 - val_acc: 0.6848\n",
            "Epoch 147/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5881 - acc: 0.6955 - val_loss: 0.5934 - val_acc: 0.6868\n",
            "Epoch 148/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5839 - acc: 0.6887 - val_loss: 0.5846 - val_acc: 0.6926\n",
            "Epoch 149/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5833 - acc: 0.6882 - val_loss: 0.5883 - val_acc: 0.6984\n",
            "Epoch 150/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5862 - acc: 0.6902 - val_loss: 0.5838 - val_acc: 0.7004\n",
            "Epoch 151/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5868 - acc: 0.6887 - val_loss: 0.5896 - val_acc: 0.6926\n",
            "Epoch 152/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5899 - acc: 0.6911 - val_loss: 0.5995 - val_acc: 0.6829\n",
            "Epoch 153/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5860 - acc: 0.6955 - val_loss: 0.5880 - val_acc: 0.6984\n",
            "Epoch 154/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5764 - acc: 0.7048 - val_loss: 0.5827 - val_acc: 0.7023\n",
            "Epoch 155/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5827 - acc: 0.6965 - val_loss: 0.5807 - val_acc: 0.7004\n",
            "Epoch 156/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5895 - acc: 0.6649 - val_loss: 0.6077 - val_acc: 0.6440\n",
            "Epoch 157/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5898 - acc: 0.6527 - val_loss: 0.6117 - val_acc: 0.6907\n",
            "Epoch 158/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.6013 - acc: 0.6853 - val_loss: 0.5961 - val_acc: 0.6887\n",
            "Epoch 159/2000\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.5901 - acc: 0.6950 - val_loss: 0.5924 - val_acc: 0.6848\n",
            "Epoch 160/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5915 - acc: 0.6911 - val_loss: 0.5909 - val_acc: 0.6965\n",
            "Epoch 161/2000\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.5878 - acc: 0.6926 - val_loss: 0.5890 - val_acc: 0.6868\n",
            "Epoch 162/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5834 - acc: 0.6902 - val_loss: 0.5847 - val_acc: 0.6965\n",
            "Epoch 163/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5846 - acc: 0.6916 - val_loss: 0.5902 - val_acc: 0.6887\n",
            "Epoch 164/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5858 - acc: 0.6921 - val_loss: 0.5874 - val_acc: 0.7023\n",
            "Epoch 165/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5808 - acc: 0.7053 - val_loss: 0.5875 - val_acc: 0.6984\n",
            "Epoch 166/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5844 - acc: 0.7018 - val_loss: 0.6105 - val_acc: 0.6576\n",
            "Epoch 167/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.6015 - acc: 0.6401 - val_loss: 0.6113 - val_acc: 0.6381\n",
            "Epoch 168/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5959 - acc: 0.6668 - val_loss: 0.6083 - val_acc: 0.6518\n",
            "Epoch 169/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5894 - acc: 0.6732 - val_loss: 0.6051 - val_acc: 0.6537\n",
            "Epoch 170/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5954 - acc: 0.6707 - val_loss: 0.6133 - val_acc: 0.6537\n",
            "Epoch 171/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5950 - acc: 0.6595 - val_loss: 0.6085 - val_acc: 0.6440\n",
            "Epoch 172/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5943 - acc: 0.6625 - val_loss: 0.6104 - val_acc: 0.6537\n",
            "Epoch 173/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5942 - acc: 0.6693 - val_loss: 0.6101 - val_acc: 0.6440\n",
            "Epoch 174/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5936 - acc: 0.6663 - val_loss: 0.6091 - val_acc: 0.6556\n",
            "Epoch 175/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5883 - acc: 0.6712 - val_loss: 0.6082 - val_acc: 0.6518\n",
            "Epoch 176/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5994 - acc: 0.6649 - val_loss: 0.6157 - val_acc: 0.6576\n",
            "Epoch 177/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.5936 - acc: 0.6707 - val_loss: 0.6147 - val_acc: 0.6576\n",
            "Epoch 178/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.6002 - acc: 0.6727 - val_loss: 0.6152 - val_acc: 0.6615\n",
            "Epoch 179/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5914 - acc: 0.6766 - val_loss: 0.6095 - val_acc: 0.6576\n",
            "Epoch 180/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5935 - acc: 0.6722 - val_loss: 0.6112 - val_acc: 0.6556\n",
            "Epoch 181/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5940 - acc: 0.6736 - val_loss: 0.6124 - val_acc: 0.6576\n",
            "Epoch 182/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5912 - acc: 0.6678 - val_loss: 0.6060 - val_acc: 0.6615\n",
            "Epoch 183/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5895 - acc: 0.6722 - val_loss: 0.6060 - val_acc: 0.6576\n",
            "Epoch 184/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5878 - acc: 0.6663 - val_loss: 0.6023 - val_acc: 0.6576\n",
            "Epoch 185/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5929 - acc: 0.6688 - val_loss: 0.5996 - val_acc: 0.6595\n",
            "Epoch 186/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5899 - acc: 0.6663 - val_loss: 0.6012 - val_acc: 0.6518\n",
            "Epoch 187/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5953 - acc: 0.6639 - val_loss: 0.6144 - val_acc: 0.6479\n",
            "Epoch 188/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5944 - acc: 0.6673 - val_loss: 0.6081 - val_acc: 0.6556\n",
            "Epoch 189/2000\n",
            "17/17 [==============================] - 1s 38ms/step - loss: 0.6086 - acc: 0.6736 - val_loss: 0.6220 - val_acc: 0.6615\n",
            "Epoch 190/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.6071 - acc: 0.6751 - val_loss: 0.6138 - val_acc: 0.6654\n",
            "Epoch 191/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.6020 - acc: 0.6732 - val_loss: 0.6081 - val_acc: 0.6654\n",
            "Epoch 192/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5889 - acc: 0.6741 - val_loss: 0.6082 - val_acc: 0.6615\n",
            "Epoch 193/2000\n",
            "17/17 [==============================] - 1s 44ms/step - loss: 0.5880 - acc: 0.6722 - val_loss: 0.6054 - val_acc: 0.6537\n",
            "Epoch 194/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5837 - acc: 0.6785 - val_loss: 0.6063 - val_acc: 0.6615\n",
            "Epoch 195/2000\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.5839 - acc: 0.6746 - val_loss: 0.6097 - val_acc: 0.6537\n",
            "Epoch 196/2000\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.5881 - acc: 0.6717 - val_loss: 0.6093 - val_acc: 0.6498\n",
            "Epoch 197/2000\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.5869 - acc: 0.6697 - val_loss: 0.6080 - val_acc: 0.6576\n",
            "Epoch 198/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.5912 - acc: 0.6741 - val_loss: 0.6086 - val_acc: 0.6556\n",
            "Epoch 199/2000\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5964 - acc: 0.6717 - val_loss: 0.6071 - val_acc: 0.6479\n",
            "Epoch 200/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5894 - acc: 0.6722 - val_loss: 0.6108 - val_acc: 0.6576\n",
            "Epoch 201/2000\n",
            "17/17 [==============================] - 1s 41ms/step - loss: 0.5885 - acc: 0.6707 - val_loss: 0.6103 - val_acc: 0.6576\n",
            "Epoch 202/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5919 - acc: 0.6712 - val_loss: 0.6087 - val_acc: 0.6556\n",
            "Epoch 203/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5907 - acc: 0.6736 - val_loss: 0.6113 - val_acc: 0.6556\n",
            "Epoch 204/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5887 - acc: 0.6659 - val_loss: 0.6041 - val_acc: 0.6595\n",
            "Epoch 205/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5893 - acc: 0.6707 - val_loss: 0.6052 - val_acc: 0.6595\n",
            "Epoch 206/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5905 - acc: 0.6668 - val_loss: 0.6095 - val_acc: 0.6654\n",
            "Epoch 207/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5909 - acc: 0.6746 - val_loss: 0.6131 - val_acc: 0.6654\n",
            "Epoch 208/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5935 - acc: 0.6741 - val_loss: 0.6117 - val_acc: 0.6654\n",
            "Epoch 209/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5917 - acc: 0.6702 - val_loss: 0.6156 - val_acc: 0.6634\n",
            "Epoch 210/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6062 - acc: 0.6746 - val_loss: 0.6104 - val_acc: 0.6654\n",
            "Epoch 211/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6093 - acc: 0.6722 - val_loss: 0.6100 - val_acc: 0.6654\n",
            "Epoch 212/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6041 - acc: 0.6736 - val_loss: 0.6131 - val_acc: 0.6654\n",
            "Epoch 213/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.6058 - acc: 0.6688 - val_loss: 0.6149 - val_acc: 0.6654\n",
            "Epoch 214/2000\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.6022 - acc: 0.6727 - val_loss: 0.6165 - val_acc: 0.6654\n",
            "Epoch 215/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.6065 - acc: 0.6697 - val_loss: 0.6169 - val_acc: 0.6654\n",
            "Epoch 216/2000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.5987 - acc: 0.6717 - val_loss: 0.6130 - val_acc: 0.6654\n",
            "Epoch 217/2000\n",
            "17/17 [==============================] - 1s 59ms/step - loss: 0.5968 - acc: 0.6722 - val_loss: 0.6117 - val_acc: 0.6654\n",
            "Epoch 218/2000\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.5909 - acc: 0.6732 - val_loss: 0.6070 - val_acc: 0.6654\n",
            "Epoch 219/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5947 - acc: 0.6707 - val_loss: 0.6133 - val_acc: 0.6634\n",
            "Epoch 220/2000\n",
            "17/17 [==============================] - 1s 40ms/step - loss: 0.5950 - acc: 0.6746 - val_loss: 0.6070 - val_acc: 0.6615\n",
            "Epoch 221/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5924 - acc: 0.6843 - val_loss: 0.6082 - val_acc: 0.6615\n",
            "Epoch 222/2000\n",
            "17/17 [==============================] - 1s 43ms/step - loss: 0.5931 - acc: 0.6683 - val_loss: 0.6070 - val_acc: 0.6634\n",
            "Epoch 223/2000\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.5910 - acc: 0.6722 - val_loss: 0.6057 - val_acc: 0.6654\n",
            "Epoch 223: early stopping\n",
            "21/21 [==============================] - 1s 14ms/step - loss: 0.5834 - acc: 0.6967\n"
          ]
        }
      ],
      "source": [
        "unit = 32\n",
        "batch = 32\n",
        "dropout = 0.4\n",
        "epoch = 2000\n",
        "model,es,mc = makeModel(unit, dropout)\n",
        "history=model.fit(X_train, Y_train, epochs=epoch, batch_size=batch, validation_split=0.2, callbacks=[es, mc])\n",
        "model=load_model('best_model.h5')\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(' acc: ', accuracy, 'loss: ', loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qc79y32Aa_dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "40c5b604-6907-4f23-f90d-bfe017623694"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = range(1, len(history.history['acc']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LxdgNix_ov-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1df8ac56-222f-4252-8e73-053f700dd45b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = range(1, len(history.history['acc']) + 1)\n",
        "plt.plot(epochs, history.history['acc'])\n",
        "plt.plot(epochs, history.history['val_acc'])\n",
        "plt.title('model acc')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "cjpltSb0Bfk5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}